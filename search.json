[
  {
    "objectID": "posts/2022-09-08-2wk-1.html",
    "href": "posts/2022-09-08-2wk-1.html",
    "title": "DL2022",
    "section": "",
    "text": "Overview - 이미지자료분석(복습)\n\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zcq1v38u87lMmD47ujarOZ\n\n\n\n\n\nfrom fastai.vision.all import * \n\n\n\n\n(1) 데이터의 정리\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfnames = get_image_files(path)\n\n\nf = lambda fname: 'cat' if fname[0].isupper() else 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    f, # f대신 (lambda fname: 'cat' if fname[0].isupper() else 'dog') 를 넣어도 가능\n    item_tfms=Resize(224))\n\n(2) lrnr 오브젝트 생성\n\nlrnr = cnn_learner(dls,resnet34,metrics=error_rate)\n\n(3) lrnr.학습()\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.152362\n      0.015960\n      0.004060\n      00:08\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.066467\n      0.028969\n      0.008119\n      00:10\n    \n  \n\n\n\n\nfine_tune()은 모든 가중치를 학습하는 것이 아니라 일부만 학습하는 것임.\nfine_tune()이외이 방법으로 학습할 수도 있음.\n\n(4) lrnr.예측()\n(방법1) lrnr.predict() 함수를 이용\n\nlrnr.predict('2022-09-06-hani03.jpg') # 방법1-1\n#lrnr.predict(PILImage.create('2022-09-06-hani03.jpg')) # 방법1-2\n#lrnr.predict(path.ls()[0]) # 방법1-3\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([0.2726, 0.7274]))\n\n\n(방법2) lrnr.model(X) 를 이용: X의 shape이 (?,3,224,224)의 형태의 텐서이어야함\n\nX,y = dls.one_batch() # 방법2\nlrnr.model(X[0:1]) \n\nTensorBase([[-3.8654,  2.9234]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n\n\n- overview\n\ndls 오브젝트 생성\nlrnr 오브젝트 생성\nlrnr.학습()\nlrnr.예측()\n\n- 비교\n\n\n\n\n\n\n\n\n\n\n회귀분석(R)\n이미지분석(CNN)\n추천시스템\n\n\n\n\n1단계\ndata.frame()\nImageDataLoaders.from_name_func()\nCollabDataLoaders.from_df()\n\n\n2단계\nNone\ncnn_learner()\ncollab_learner()\n\n\n3단계\nlm(y~x1+x2,df)\nlrnr.fine_tune(1)\nlrnr.fit()\n\n\n4단계\npredict(ob,newdf)\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\n\n\n\n\n\n\n아래의 함수들이 정의된 위치를 찾아보고 경로를 제출하라. - ImageDataLoaders.from_name_func - cnn_learner - lrnr.fine_tune - lrnr.predict\n단, 여기에서 lrnr는 cnn_learner()로부터 생성된 오브젝트 이다.\n제출예시\nImageDataLoaders.from_name_func - ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/vision/data.py"
  },
  {
    "objectID": "posts/2022-09-06-1wk-2.html",
    "href": "posts/2022-09-06-1wk-2.html",
    "title": "DL2022",
    "section": "",
    "text": "Overview - 이미지자료분석\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-w4djJcMLe2Jgfuj5V14NPi\n\n\n\n\n\nfrom fastai.vision.all import * \n\n\n\n\n\npath = untar_data(URLs.PETS)/'images'\n# URLs.PETS: 스트링 -> 주소가 저장되어 있음.. -> 주소로 들어가보니 어떠한 압축파일이 자동으로 다운 받아짐, 이게 데이터 \n# untar_data: (1) URLs.PETS에 저장된 주소로 찾아가서 (2) 압축을 풀어서 (3) 어떠한 폴더에 저장, 그 폴더의 위치는 path 에 저장 \n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:10<00:00]\n    \n    \n\n\n\npath # 여기에 그림이 있다는 말이지?? \n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\n# \n# 탐색... 여러파일들이 있기는함.. \n# Abyssinian_1.jpg 를 보고싶다면? \nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg')\n\n\n\n\n\n# \n# Abyssinian_100.jpg 를 보고싶다면? \nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg')\n\n\n\n\n- 그림을 확인 할 수 있는건 좋은데 이렇게 확인하니까 조금 귀찮음..\n\n_lst = ['/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg','/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg']\n\n\n_lst[0]\n\n'/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg'\n\n\n\nPILImage.create(_lst[0])\n\n\n\n\n\nfiles= get_image_files(path)\nfiles\n\n(#7390) [Path('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_173.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_192.jpg')...]\n\n\n\nfiles[0]\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg')\n\n\n\n#PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/english_setter_59.jpg')\nPILImage.create(files[0])\n\n\n\n\n\nprint(files[2])\nPILImage.create(files[2])\n\n/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg\n\n\n\n\n\n\nprint(files[3])\nPILImage.create(files[3])\n\n/root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg\n\n\n\n\n\n\nprint(files[4])\nPILImage.create(files[4])\n\n/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg\n\n\n\n\n\n\nprint(files[5])\nPILImage.create(files[5])\n\n/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg\n\n\n\n\n\n\nprint(files[6])\nPILImage.create(files[6])\n\n/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg\n\n\n\n\n\n\nprint(files[7])\nPILImage.create(files[7])\n\n/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg\n\n\n\n\n\n\nprint(files[8])\nPILImage.create(files[8])\n\n/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg\n\n\n\n\n\n\n# \n# 특1: 대문자이면 고양이, 소문자이면 강아지그림이다!! (천재적인 저장방식)\n# 특2: 이미지크기가 서로 다르다..\n\n\ndef label_func(fname):\n  if fname[0].isupper():\n    return 'cat'\n  else:\n    return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224))\n# path 경로에서 \n# files 에 해당하는 파일들을 불러와서 X를 만들고 \n# item_tfms 에 정의된 방식으로 X를 변환하여 저장한다. 그리고 \n# label_func: \"파일이름\" -> \"라벨\", 에 저장된 함수내용을 바탕으로 y를 만들어 저장한다. \n# 이 모든것이 저장된 자료는 변수 dls에 저장한다. \n\n\ndls.show_batch(max_n=16)\n\n\n\n\n\n\n\n\n# 우리의 1차 목표: 이미지 -> 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n# cnn_learner 라는 함수를 이용해서 1차목표와 2차목표를 달성할 \"썸띵(Object)\"을 만들것임. \n## 오브젝트란? 정보와 함수를 동시에 가지는 어떠한 집합체 \n# - 오브젝트.명사이름: 이것 통채로 하나의 변수처럼 쓸 수 있음. \n# - 오브젝트.동사이름: 이것 통채로 하나의 함수처럼 쓸 수 있음. (이때 함수의 첫번째 입력은 명시하지 않아도 오브젝트 그 자체가 된다)\n\n## clafr에 필요한 명사(=정보) <-- 우리가 넣어줘야하는 것들이 대부분\n# (1) 모델정보: 클래시파이어로 누구를 뽑을것인가 (유명한 모델이 무엇인가? 잘 맞추는 모델이 무엇인가)\n# (2) 데이터: 데이터를 줘야함 \n# (3) 평가기준표: 채점을 할 지표 \n## clafr에 필요한 동사(=함수) <-- 이미 구현이 되어있음.. \n# (1) 학습 \n# (2) 결과를 판단\n# (3) 예측 \n\nclsfr = cnn_learner(dls,resnet34,metrics=error_rate)\n# clsfr 라는 오브젝트를 만들건데.. \n# 그 오브젝트의 재료로 dls (데이터), resnet34 (데이터를 분석할 모형이름), metrics (모형의 성능을 평가할 기준) 를 넣음. \n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\nclsfr.fine_tune(1) # 학습을 하는 함수\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.189062\n      0.012517\n      0.006089\n      01:01\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.051309\n      0.010439\n      0.003383\n      00:57\n    \n  \n\n\n\n\n\n\n\nfiles[0] # 강아지 \n\nPath('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg')\n\n\n\nclsfr.predict(files[0])\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([6.8846e-07, 1.0000e+00]))\n\n\n\nfiles[7] # 고양이\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg')\n\n\n\nclsfr.predict(files[7])\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterpreter = Interpretation.from_learner(clsfr) # 오답을 분석하는 오브젝트를 만듬.. 재료는 클래시파이어! \n\n\n\n\n\n\n\n\n\ninterpreter.plot_top_losses(16) # 오답을 분석하는 오브젝트는 가장 오류가 높은 이미지를 정렬하여 보여주는 기능이 있음..\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclsfr.predict(files[7])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.predict('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg')\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.predict(PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nPILImage.create('2022-09-06-cat1.png')\n\n\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-cat1.png'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.5662e-10]))\n\n\n\nPILImage.create('2022-09-06-cat2.jpeg')\n\n\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-cat2.jpeg'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([0.9809, 0.0191]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani01.jpeg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([3.2573e-10, 1.0000e+00]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani02.jpeg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([7.0723e-07, 1.0000e+00]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani03.jpg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([0.1814, 0.8186]))\n\n\n\n\n\n- 인터넷에 존재하는 개 혹은 고양이 이미지를 임의로 하나 불러온뒤 clsfr에 넣어보고 결과를 관찰하라. 관찰결과를 스크린샷하여 제출하라. - 숙제를 위한 예시코드\n# https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg <-- 인터넷의 이미지 주소\nimg=PILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\nclsfr.predict(img)\n- 숙제 못하겠으면 카톡으로 물어보세요! 답 알려드립니다.\n- 숙제는 간단하게 편한 형식으로 제출하세요. (저는 스크린샷 선호해요..) pdf나 hwp로 만드실 필요 없습니다."
  },
  {
    "objectID": "posts/2022-09-20-3wk-2.html",
    "href": "posts/2022-09-20-3wk-2.html",
    "title": "DL2022",
    "section": "",
    "text": "딥러닝의 기초 - 회귀분석(1)–선형모형,손실함수,경사하강법\n\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n- 강의노트가 약간 수정되었습니다 (loss.backward()의 계산결과 검증에서 편미분의 간단한 구현을 통한 검증이 추가되었습니다)\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-xQuhazVVLGdKZp2Vo-2A2L\n\n\n\n\n\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n\n\n- 회귀분석 \\(\\to\\) 로지스틱 \\(\\to\\) 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN)\n- 강의계획서\n\n\n\n- 넘파이 문법이 약하다면? (reshape, concatenate, stack)\n\nreshape: 아래 링크의 넘파이공부 2단계 reshape 참고\n\nhttps://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html\n\nconcatenate, stack: 아래 링크의 넘파이공부 4단계 참고\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html\n\n\n\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)\n\n\n\n\n\ntorch.manual_seed(43052)\nones= torch.ones(100)\nx,_ = torch.randn(100).sort()\nX = torch.stack([ones,x]).T # torch.stack([ones,x],axis=1)\nW = torch.tensor([2.5,4])\nϵ = torch.randn(100)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')\n\n\n\n\n\n\n\n- 파란점만 주어졌을때, 주황색 점선을 추정하는것. 좀 더 정확하게 말하면 given data로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 더 쉽게 말하면 아래의 그림을 보고 적당한 추세선을 찾는것이다.\n\nplt.plot(x,y,'o')\n\n\n\n\n- 시도: \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단.\n\nplt.plot(x,y,'o')\nplt.plot(x,-5+10*x,'--')\n\n\n\n\n\n\\(\\hat{y}_i=-5 +10 x_i\\) 와 같이 \\(y_i\\)의 값을 적합시키겠다는 의미\n\n- 벡터표현으로 주황색점선을 계산\n\nWhat = torch.tensor([-5.0,10.0])\n\n\nX.shape\n\ntorch.Size([100, 2])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'--')\n\n\n\n\n\n\n\n- 이론적으로 추론 <- 회귀분석시간에 배운것\n- 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법) <- 우리가 오늘 파이토치로 실습해볼 내용.\n- 전략: 아래와 같은 3단계 전략을 취한다.\n\nstage1: 아무 점선이나 그어본다..\nstage2: stage1에서 그은 점선보다 더 좋은 점선으로 바꾼다.\nstage3: stage1 - 2 를 반복한다.\n\n\n\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\nWhat = torch.tensor([-5.0,10.0],requires_grad=True)\nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\n처음에는 ${}=\n\\[\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n$ 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거\n\n\n\n\n\n\n\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터를 학습 하라 = 손실함수를 최소화 하라”\n- 우리의 무기: 경사하강법, 벡터미분\n\n\n\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) <– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) <– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- $수정값 원래값 - 기울어진크기(=미분계수) $\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n\nloss.backward() \n\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\nWhat,What.grad\n\n(tensor([-5., 10.], requires_grad=True), tensor([-1342.2522,  1188.9305]))\n\n\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2522,  1188.9308], grad_fn=<AddBackward0>)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad))\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')\nplt.plot(x,X@Wafter,'--')\n\n\n\n\n\n\n\n\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) #\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() \n    What.data = What.data-alpha * What.grad\n    What.grad=None\n\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\n\n\n\n\n\n\n\n\n\n\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811716079712, 7.861191749572754],\n [-1.649186372756958, 7.101552963256836],\n [-0.9060714244842529, 6.49347448348999],\n [-0.29667872190475464, 6.006272315979004],\n [0.2027742564678192, 5.615575313568115],\n [0.6119104623794556, 5.302003860473633],\n [0.9469034075737, 5.0501298904418945],\n [1.2210698127746582, 4.847658157348633],\n [1.4453644752502441, 4.684779644012451],\n [1.6287914514541626, 4.553659915924072],\n [1.7787461280822754, 4.448036193847656],\n [1.9012980461120605, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nplt.plot(loss_history)\n\n\n\n\n\n\n\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 <- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7ffa9199ce90>\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7ffa78c2ba10>\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n\n\n- 학습률(\\(\\alpha\\))를 조정하며 실습해보고 스크린샷 제출"
  },
  {
    "objectID": "posts/2022-09-13-2wk-2.html",
    "href": "posts/2022-09-13-2wk-2.html",
    "title": "DL2022",
    "section": "",
    "text": "Overview - 추천시스템, 텍스트분석\n\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zJbe5FztJPSqicA2ZLwDgh\n\n\n\n\n\nfrom fastai.collab import * ## 추천시스템\nfrom fastai.text.all import * ## 텍스트분석 \n\n\nimport pandas as pd\n\n\n\n\n- 비교\n\n\n\n\n\n\n\n\n\n\n\n이미지분석(CNN)\n추천시스템\n텍스트분석\nGAN\n\n\n\n\n1단계\nImageDataLoaders\nCollabDataLoaders\nTextDataLoaders\nDataBlock -> dls\n\n\n2단계\ncnn_learner()\ncollab_learner()\nlanguage_model_learner()\nGANLearner.wgan()\n\n\n3단계\nlrnr.fine_tune(1)\nlrnr.fit()\nlrnr.fit()\nlrnr.fit()\n\n\n4단계\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\nlrnr.predict()\n\n\n\n\n\n\n\n\n\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n  \n    \n      \n      커피1\n      커피2\n      커피3\n      커피4\n      커피5\n      커피6\n      커피7\n      커피8\n      커피9\n      커피10\n      홍차1\n      홍차2\n      홍차3\n      홍차4\n      홍차5\n      홍차6\n      홍차7\n      홍차8\n      홍차9\n      홍차10\n    \n  \n  \n    \n      0\n      4.149209\n      NaN\n      NaN\n      4.078139\n      4.033415\n      4.071871\n      NaN\n      NaN\n      NaN\n      NaN\n      1.142659\n      1.109452\n      NaN\n      0.603118\n      1.084308\n      NaN\n      0.906524\n      NaN\n      NaN\n      0.903826\n    \n    \n      1\n      4.031811\n      NaN\n      NaN\n      3.822704\n      NaN\n      NaN\n      NaN\n      4.071410\n      3.996206\n      NaN\n      NaN\n      0.839565\n      1.011315\n      NaN\n      1.120552\n      0.911340\n      NaN\n      0.860954\n      0.871482\n      NaN\n    \n    \n      2\n      4.082178\n      4.196436\n      NaN\n      3.956876\n      NaN\n      NaN\n      NaN\n      4.450931\n      3.972090\n      NaN\n      NaN\n      NaN\n      NaN\n      0.983838\n      NaN\n      0.918576\n      1.206796\n      0.913116\n      NaN\n      0.956194\n    \n    \n      3\n      NaN\n      4.000621\n      3.895570\n      NaN\n      3.838781\n      3.967183\n      NaN\n      NaN\n      NaN\n      4.105741\n      1.147554\n      NaN\n      1.346860\n      NaN\n      0.614099\n      1.297301\n      NaN\n      NaN\n      NaN\n      1.147545\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      3.888208\n      NaN\n      3.970330\n      3.979490\n      NaN\n      4.010982\n      NaN\n      0.920995\n      1.081111\n      0.999345\n      NaN\n      1.195183\n      NaN\n      0.818332\n      1.236331\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.511905\n      1.066144\n      NaN\n      1.315430\n      NaN\n      1.285778\n      NaN\n      0.678400\n      1.023020\n      0.886803\n      NaN\n      4.055996\n      NaN\n      NaN\n      4.156489\n      4.127622\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      96\n      NaN\n      1.035022\n      NaN\n      1.085834\n      NaN\n      0.812558\n      NaN\n      1.074543\n      NaN\n      0.852806\n      3.894772\n      NaN\n      4.071385\n      3.935935\n      NaN\n      NaN\n      3.989815\n      NaN\n      NaN\n      4.267142\n    \n    \n      97\n      NaN\n      1.115511\n      NaN\n      1.101395\n      0.878614\n      NaN\n      NaN\n      NaN\n      1.329319\n      NaN\n      4.125190\n      NaN\n      4.354638\n      3.811209\n      4.144648\n      NaN\n      NaN\n      4.116915\n      3.887823\n      NaN\n    \n    \n      98\n      NaN\n      0.850794\n      NaN\n      NaN\n      0.927884\n      0.669895\n      NaN\n      NaN\n      0.665429\n      1.387329\n      NaN\n      NaN\n      4.329404\n      4.111706\n      3.960197\n      NaN\n      NaN\n      NaN\n      3.725288\n      4.122072\n    \n    \n      99\n      NaN\n      NaN\n      1.413968\n      0.838720\n      NaN\n      NaN\n      1.094826\n      0.987888\n      NaN\n      1.177387\n      3.957383\n      4.136731\n      NaN\n      4.026915\n      NaN\n      NaN\n      4.164773\n      4.104276\n      NaN\n      NaN\n    \n  \n\n100 rows × 20 columns\n\n\n\n\nrow0 - row49 에 해당하는 유저는 커피를 선호\nrow50 - row99 에 해당하는 유저는 홍차를 선호\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      0\n      1\n      15\n      1.084308\n      홍차5\n    \n    \n      1\n      1\n      1\n      4.149209\n      커피1\n    \n    \n      2\n      1\n      11\n      1.142659\n      홍차1\n    \n    \n      3\n      1\n      5\n      4.033415\n      커피5\n    \n    \n      4\n      1\n      4\n      4.078139\n      커피4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      100\n      18\n      4.104276\n      홍차8\n    \n    \n      996\n      100\n      17\n      4.164773\n      홍차7\n    \n    \n      997\n      100\n      14\n      4.026915\n      홍차4\n    \n    \n      998\n      100\n      4\n      0.838720\n      커피4\n    \n    \n      999\n      100\n      7\n      1.094826\n      커피7\n    \n  \n\n1000 rows × 4 columns\n\n\n\n\n컴퓨터는 이러한 형태를 더 분석하기 좋아한다.\n\n\ndf.item.unique(),df.user.unique()\n# 유저는 1~100 으로 아이템은 1~20으로 번호가 매겨져 있음 \n\n(array([15,  1, 11,  5,  4, 14,  6, 20, 12, 17,  8,  9, 13, 19, 18, 16,  2,\n         3, 10,  7]),\n array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100]))\n\n\n\ndls=CollabDataLoaders.from_df(df)\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n    \n  \n  \n    \n      0\n      2\n      1\n      4.031811\n    \n    \n      1\n      40\n      19\n      1.015886\n    \n    \n      2\n      39\n      20\n      0.853394\n    \n    \n      3\n      58\n      8\n      0.854745\n    \n    \n      4\n      38\n      6\n      4.055263\n    \n    \n      5\n      45\n      17\n      0.608018\n    \n    \n      6\n      59\n      14\n      3.986921\n    \n    \n      7\n      6\n      12\n      0.833454\n    \n    \n      8\n      98\n      13\n      4.354638\n    \n    \n      9\n      74\n      12\n      4.199568\n    \n  \n\n\n\n\nX,y= dls.one_batch()\n\n\nX[0],y[0]\n\n(tensor([64, 15]), tensor([4.1146]))\n\n\n\n64번 유저가 15번 아이템을 먹었을때 평점을 4.1146 주었음\n\n\n\n\n\nlrnr = collab_learner(dls,y_range=(0,5)) # y_range는 평점의 범위\n\n\n\n\n\nlrnr.fit(10) # 총 30번 정도 해야 적합이 잘된다. \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.044790\n      0.064825\n      00:00\n    \n    \n      1\n      0.042065\n      0.059010\n      00:00\n    \n    \n      2\n      0.039907\n      0.055658\n      00:00\n    \n    \n      3\n      0.038412\n      0.053847\n      00:00\n    \n    \n      4\n      0.037186\n      0.052595\n      00:00\n    \n    \n      5\n      0.036020\n      0.052121\n      00:00\n    \n    \n      6\n      0.035041\n      0.051959\n      00:00\n    \n    \n      7\n      0.034370\n      0.051995\n      00:00\n    \n    \n      8\n      0.033759\n      0.052022\n      00:00\n    \n    \n      9\n      0.033237\n      0.052229\n      00:00\n    \n  \n\n\n\n\n\n\n- 하나의 배치 전체를 예측\n\nyhat=lrnr.model(X.to(\"cuda:0\"))\nyhat\n\ntensor([4.0162, 0.9041, 4.0706, 0.9730, 0.9861, 1.1032, 4.0559, 4.0745, 3.9329,\n        4.0195, 3.9139, 4.0732, 3.8666, 3.9556, 0.9634, 1.0055, 0.9944, 3.9826,\n        4.0456, 0.9961, 0.9438, 0.9291, 4.0212, 1.0700, 4.0543, 4.0441, 4.0918,\n        0.9850, 1.0140, 4.1212, 4.0628, 3.9923, 4.0395, 0.9331, 3.9581, 3.9999,\n        1.1152, 3.9131, 4.0565, 3.9264, 3.9619, 0.9421, 1.1348, 4.0688, 0.8939,\n        0.9684, 1.0505, 1.1034, 1.1027, 3.9411, 1.0582, 3.9680, 4.0465, 3.9554,\n        4.0419, 1.0965, 1.0784, 0.9954, 4.0205, 0.9373, 3.9045, 1.0255, 3.8102,\n        1.0640], device='cuda:0', grad_fn=<AddBackward0>)\n\n\n\nlrnr.model()은 GPU메모리에 존재하고 X는 일반메모리에 존재하므로 X를 GPU메모리로 옮겨주어야 함\nX.to(“cuda:0”)을 통하여 X를 GPU메모리로 옮기는 작업을 수행할 수 있다.\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어진 자료중에서 예측)\n\nX.shape\n\ntorch.Size([64, 2])\n\n\n\nX[0:1]\n\ntensor([[18,  5]])\n\n\n\n18번 유저가 5번 아이템(커피)를 먹는다면?\n\n\nlrnr.model(X[0:1].to(\"cuda:0\"))\n\ntensor([4.1128], device='cuda:0', grad_fn=<AddBackward0>)\n\n\n\n평점은 4.1128정도 될것\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어지지 않은 자료중에서 예측)\n\nX[0:1]\n\ntensor([[18,  5]])\n\n\n\nXnew = torch.tensor([[1,  2]])\n\n\nlrnr.model(Xnew.to(\"cuda:0\"))\n\ntensor([3.9397], device='cuda:0', grad_fn=<AddBackward0>)\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame({'text':['h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??']*20000})\ndf\n\n\n\n\n\n  \n    \n      \n      text\n    \n  \n  \n    \n      0\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      1\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      2\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      3\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      4\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      ...\n      ...\n    \n    \n      19995\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19996\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19997\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19998\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19999\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n  \n\n20000 rows × 1 columns\n\n\n\n\ndls = TextDataLoaders.from_df(df,text_col='text',is_lm=True) \n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      text\n      text_\n    \n  \n  \n    \n      0\n      xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\n      h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o .\n    \n    \n      1\n      ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\n      xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\n    \n    \n      2\n      ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n      ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\n    \n    \n      3\n      o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n      ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n    \n    \n      4\n      l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\n      o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n    \n    \n      5\n      l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\n      l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\n    \n    \n      6\n      e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\n      l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\n    \n    \n      7\n      h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\n      e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\n    \n    \n      8\n      ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o\n      h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\n    \n  \n\n\n\n\nis_lm: text의 생성에 관심이 있다면 True로 설정할 것\n\n\n\n\n\nlrnr = language_model_learner(dls, AWD_LSTM)\n\n\n\n\n\nlrnr.fit(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.575245\n      0.245803\n      00:11\n    \n  \n\n\n\n\n\n\n\nlrnr.predict('h e',n_words=30)\n\n\n\n\n\n\n\n\n'h e l l l o . h e l l . e l l o ? ? h e l l o ! ! h e l l o !'"
  },
  {
    "objectID": "posts/2022-09-15-3wk-1.html",
    "href": "posts/2022-09-15-3wk-1.html",
    "title": "DL2022",
    "section": "",
    "text": "Overview - 이미지분석 추천시스템 텍스트분석의 비교정리, GAN\n\n\ntoc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 최규빈\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-wLTADeftdizvmko4y_ATAW\n\n\n\n\n\nfrom fastai.vision.all import * \nfrom fastai.vision.gan import * \n\n\n\n\n- 비교\n\n\n\n\n\n\n\n\n\n\n\n이미지분석(CNN)\n추천시스템\n텍스트분석\nGAN\n\n\n\n\n1단계\nImageDataLoaders\nCollabDataLoaders\nTextDataLoaders\nDataBlock -> dls\n\n\n2단계\ncnn_learner()\ncollab_learner()\nlanguage_model_learner()\nGANLearner.wgan()\n\n\n3단계\nlrnr.fine_tune(1)\nlrnr.fit()\nlrnr.fit()\nlrnr.fit()\n\n\n4단계\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\nlrnr.predict()\n\n\n\n\n\n\n\n- 데이터는 모두 아래와 같은 느낌이다.\n\n데이터는 \\((X,y)\\)의 형태로 정리되어 있다.\n\\(y\\)는 우리가 관심이 있는 변수이다. 즉 우리는 \\(y\\)를 적절하게 추정하는 것에 관심이 있다.\n\\(X\\)는 \\(y\\)를 추정하기 위해 필요한 정보이다.\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\) = 설명변수 = 독립변수\n\\(y\\) = 반응변수 = 종속변수\n비고\n순서\n예시\n\n\n\n\n이미지\n카테고리\n합성곱신경망\n상관없음\n개/고양이 이미지 구분\n\n\n유저,아이템\n평점\n추천시스템\n상관없음\n넷플릭스 영화추천\n\n\n과거~오늘까지의주가\n내일주가\n순환신경망\n순서상관있음\n주가예측\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n이후 1개의 단어(혹은 문장)\n순환신경망\n순서상관있음\n챗봇, 텍스트생성\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n카테고리\n순환신경망\n순서상관있음\n영화리뷰 텍스트 감정분류\n\n\n\n- 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “규칙” 혹은 “원리”를 찾는 것이다. - 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “맵핑”을 찾는 것이다. - 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “힘수”을 찾는 것이다. 즉 \\(y\\approx f(X)\\)가 되도록 만드는 \\(f\\)를 잘 찾는 것이다. (이 경우 함수를 추정한다라고 표현) - 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “모델”을 찾는 것이다. 즉 \\(y\\approx model(X)\\)가 되도록 만드는 \\(model\\)을 잘 찾는 것이다. (이 경우 모형을 학습시킨다라고 표현) - 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “네트워크”을 찾는 것이다. 즉 \\(y\\approx net(X)\\)가 되도록 만드는 \\(net\\)을 잘 찾는 것이다. (이 경우 모형을 네트워크를 학습시킨다라고 표현)\n- prediction이란 학습과정에서 찾은 “규착” 혹은 “원리”를 \\(X\\)에 적용하여 \\(\\hat{y}\\)을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는 \\(f\\),\\(model\\),\\(net\\) 으로 생각가능한데 이에 따르면 아래가 성립한다. - \\(\\hat{y} = f(X)\\) - \\(\\hat{y} = model(X)\\) - \\(\\hat{y} = net(X)\\)\n자잘한개념\n- \\(\\hat{y}\\)는 \\(X\\)가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에 따라 지칭하는 이름이 미묘하게 다르다.\n(경우1) \\(X \\in data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, fitted value 라고 부른다.\n(경우2) \\(X \\notin data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, predicted value with new data 라고 부른다.\n- 경우1은 “\\(loss\\) = \\(y\\) 와 \\(\\hat{y}\\) 의 차이” 를 정의할 수 있으나 경우2는 그렇지 않다.\n\n\n\n- 저자: 이안굿펠로우 - 천재임 - 지도교수가 요수아 벤지오\n- 논문 NIPS, 저는 이 논문 읽고 소름돋았어요.. - https://arxiv.org/abs/1406.2661 (현재시점, 38751회 인용되었음 \\(\\to\\) 48978회 인용..)\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 무슨내용? 생성모형\n\n\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n\n\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면?\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요…..\n\n\n\n\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다. 여기에서 \\(p(\\boldsymbol{x},y)\\)는 \\({\\boldsymbol x},y\\)의 결합확률밀도함수.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다. 여기에서 \\(p(y|\\boldsymbol{x})\\)는 조건부 확률밀도 함수\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol x}) = \\frac{p({\\boldsymbol x},y)}{p({\\boldsymbol x})} = \\frac{p({\\boldsymbol x},y)}{\\sum_{y}p({\\boldsymbol x},y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다.\n\n\n\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –> 상사에게 혼남. 그것도 구분못하냐고\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다.\n\n\n\n- 아래와 같은 두 모델(네트워크)를 생각하자. - 위조범네트워크: X=노이즈(=아무숫자) \\(\\to\\) y=지폐이미지(=가짜지폐) - 경찰네트워크: X={가짜지폐,진짜지폐} \\(\\to\\) y={진짜,가짜}\n- 전체 알고리즘은 아래와 같은 순서로 돌아간다. (전체 이미지 자료는 \\(n\\)개라고 하자)\n\n적당한 크기의 \\(n\\)개의 노이즈가 위조범네트워크에 입력으로 들어감\n위조범네트워크는 적당한 크기의 \\(n\\)개의 노이즈를 입력으로 받고 출력으로 \\(n\\)개의 이미지를 뱉어냄.\n위조범이 뱉어낸 이미지와 진짜이미지를 합쳐 \\(2n\\)개의 자료를 만들고 이를 경창네트워크의 입력으로 넣음.\n경찰네트워크는 \\(2n\\)개의 자료를 입력으로 받아서 \\(2n\\)개의 예측결과를 제공.\n\n\n\n\n\n\n\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\ndblock = DataBlock(blocks=(TransformBlock,ImageBlock),\n          get_x = generate_noise,\n          get_items=get_image_files,\n          item_tfms=Resize(32))\ndls = dblock.dataloaders(path) \n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\ncounterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1) # 32*32의 이미지가 칼라이미지로 출력. \npolice = basic_critic(32,n_channels=3,n_extra_layers=1) # 32*32의 칼라이미지가 입력으로 들어옴. \n\n\nlrnr = GANLearner.wgan(dls,counterfeiter,police) \n\n\n\n\n- lrnr.fit(10) 진행\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.546135\n      0.362349\n      0.362349\n      -0.757082\n      00:02\n    \n    \n      1\n      -0.582954\n      0.300018\n      0.300018\n      -0.770161\n      00:02\n    \n    \n      2\n      -0.585224\n      0.277624\n      0.277624\n      -0.769241\n      00:02\n    \n    \n      3\n      -0.582842\n      0.385249\n      0.385249\n      -0.764790\n      00:02\n    \n    \n      4\n      -0.584591\n      0.333895\n      0.333895\n      -0.768902\n      00:02\n    \n    \n      5\n      -0.587377\n      0.304535\n      0.304535\n      -0.773640\n      00:02\n    \n    \n      6\n      -0.580959\n      0.274871\n      0.274871\n      -0.765747\n      00:02\n    \n    \n      7\n      -0.559458\n      0.348925\n      0.348925\n      -0.734318\n      00:02\n    \n    \n      8\n      -0.486598\n      0.074547\n      0.074547\n      -0.545082\n      00:03\n    \n    \n      9\n      -0.550950\n      0.278006\n      0.278006\n      -0.724520\n      00:03\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n- lrnr.fit(10) 추가로 진행 // 총20회\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.534234\n      0.261044\n      0.261044\n      -0.737007\n      00:02\n    \n    \n      1\n      -0.515386\n      0.241006\n      0.241006\n      -0.720394\n      00:02\n    \n    \n      2\n      -0.561530\n      0.249572\n      0.249572\n      -0.742900\n      00:02\n    \n    \n      3\n      -0.544423\n      0.315043\n      0.315043\n      -0.739004\n      00:02\n    \n    \n      4\n      -0.534188\n      0.235120\n      0.235120\n      -0.686251\n      00:02\n    \n    \n      5\n      -0.494047\n      0.284046\n      0.284046\n      -0.633201\n      00:02\n    \n    \n      6\n      -0.506470\n      0.214011\n      0.214011\n      -0.687545\n      00:02\n    \n    \n      7\n      -0.527870\n      0.262492\n      0.262492\n      -0.731213\n      00:02\n    \n    \n      8\n      -0.504433\n      0.192755\n      0.192755\n      -0.674976\n      00:02\n    \n    \n      9\n      -0.538148\n      0.204089\n      0.204089\n      -0.728712\n      00:02\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n- lrnr.fit(30) 추가로 진행 // 총50회\n\nlrnr.fit(30)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.509745\n      0.286478\n      0.286478\n      -0.691290\n      00:02\n    \n    \n      1\n      -0.502572\n      0.285199\n      0.285199\n      -0.675554\n      00:02\n    \n    \n      2\n      -0.473333\n      0.219742\n      0.219742\n      -0.650543\n      00:02\n    \n    \n      3\n      -0.419040\n      0.287789\n      0.287789\n      -0.543150\n      00:02\n    \n    \n      4\n      -0.275088\n      0.264852\n      0.264852\n      -0.105730\n      00:02\n    \n    \n      5\n      -0.350050\n      0.330111\n      0.330111\n      -0.529484\n      00:02\n    \n    \n      6\n      -0.394095\n      0.228335\n      0.228335\n      -0.616371\n      00:02\n    \n    \n      7\n      -0.247936\n      0.177943\n      0.177943\n      -0.286712\n      00:02\n    \n    \n      8\n      -0.333396\n      0.207328\n      0.207328\n      -0.585255\n      00:02\n    \n    \n      9\n      -0.370004\n      0.356040\n      0.356040\n      -0.641916\n      00:02\n    \n    \n      10\n      -0.463898\n      0.195165\n      0.195165\n      -0.215188\n      00:02\n    \n    \n      11\n      -0.241843\n      0.110512\n      0.110512\n      -0.411598\n      00:02\n    \n    \n      12\n      -0.227809\n      -0.094414\n      -0.094414\n      -0.306309\n      00:02\n    \n    \n      13\n      -0.185607\n      -0.063660\n      -0.063660\n      -0.261691\n      00:02\n    \n    \n      14\n      -0.219289\n      -0.041734\n      -0.041734\n      -0.424938\n      00:02\n    \n    \n      15\n      -0.048843\n      0.063750\n      0.063750\n      -0.088812\n      00:02\n    \n    \n      16\n      -0.092374\n      -0.218327\n      -0.218327\n      -0.001817\n      00:02\n    \n    \n      17\n      -0.081938\n      -0.068263\n      -0.068263\n      -0.052643\n      00:02\n    \n    \n      18\n      -0.031063\n      -0.183604\n      -0.183604\n      -0.013827\n      00:02\n    \n    \n      19\n      -0.025211\n      0.041027\n      0.041027\n      -0.061204\n      00:02\n    \n    \n      20\n      -0.023948\n      0.244387\n      0.244387\n      -0.001813\n      00:02\n    \n    \n      21\n      -0.073112\n      0.275998\n      0.275998\n      -0.150063\n      00:02\n    \n    \n      22\n      -0.064780\n      0.112151\n      0.112151\n      -0.123186\n      00:02\n    \n    \n      23\n      -0.030959\n      0.002616\n      0.002616\n      -0.134843\n      00:02\n    \n    \n      24\n      -0.066342\n      0.604107\n      0.604107\n      -0.118417\n      00:02\n    \n    \n      25\n      -0.025819\n      0.066880\n      0.066880\n      -0.087840\n      00:02\n    \n    \n      26\n      -0.061908\n      -0.129382\n      -0.129382\n      -0.101803\n      00:02\n    \n    \n      27\n      -0.096987\n      -0.213048\n      -0.213048\n      -0.081656\n      00:02\n    \n    \n      28\n      -0.114984\n      0.287159\n      0.287159\n      -0.152345\n      00:02\n    \n    \n      29\n      -0.062543\n      -0.076906\n      -0.076906\n      -0.078245\n      00:02\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n그럴싸한 글씨가 몇개 보이긴 함"
  },
  {
    "objectID": "posts/2022-09-01-1wk-1.html",
    "href": "posts/2022-09-01-1wk-1.html",
    "title": "DL2022",
    "section": "",
    "text": "(1주차) 9월1일\n\n강의소개\n\n\n강의영상\n\n없어요..\n\n\n\n질문하는 방법\n\n\n수업목표\n- 다양한 딥러닝 분석기법의 원리를 이해한다.\n- 파이토치 사용방법을 익힌다.\n\n\n강의교재 및 참고자료\n- 강의교재: 강의노트\n- 참고자료: - 2021년 빅데이터분석 강의노트 (본 수업은 2021년 빅데이터분석 수업과 유사한 콘텐츠로 진행할 예정임) - 2022년 파이썬입문 강의노트 (numpy, class 부분이 약하다고 생각하면 참고 할 것) - fastai, Deep Learning for Coders with fastai & PyTorch, Deep Learning for Coders with fastai & PyTorch (번역판)\n\n\n선수과목\n- 필수: 파이썬입문 (수업시간에 별도로 파이썬을 리뷰하는 시간을 갖지 않음)\n- 선택: 수리통계학, 회귀분석, 선형대수학 (수업이해에 필요한 최소한의 지식은 리뷰함)\n\n\n강의범위\n- 딥러닝의 기초: DNN, 손실함수, 옵티마이저, 역전파, universal approximation thm\n- 이미지 자료 분석: CNN, Class Activation Map (CAM) and XAI\n- 추천시스템: SVD, Collaborative Filtering …\n- 텍스트와 시퀀스 자료 분석: RNN, LSTM, GRU, Attention…\n- 생성모형: 식별모형과 생성모형, GAN\n\n\n주의사항\n- 출석을 모두 하고 과제를 모두 제출하였더라도 중간고사와 기말고사 합산점수가 매우 낮을 경우 F 혹은 D 학점이 나갈 수 있음.\n- 2022년 1학기 데이터과학 수업과 내용이 일부 겹칠 수 있음 (다만 2022년 1학기 데이터과학 수업은 텐서플로우로 본 수업은 파이토치로 진행하는 차이점은 있음)"
  },
  {
    "objectID": "posts/2022-09-19-Assignment1.html",
    "href": "posts/2022-09-19-Assignment1.html",
    "title": "DL2022",
    "section": "",
    "text": "제출은 이름(학번).ipynb 파일과 이름(학번).html파일 2개를 제출할 것.\nipynb 혹은 html 파일을 이용한 제출이 익숙하지 않은 학생은 질문할 것.\n이 hw은 9월13일 + 9월15일 분량임 (다른숙제 대비 배점2배)\n\n\nfrom fastai.vision.all import *\nfrom fastai.collab import * \nfrom fastai.text.all import *\n\n\n\n아래를 이용하여 MNIST_SAMPLE 이미지 자료를 다운로드 받고 dls오브젝트를 만들어라.\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\ndls = ImageDataLoaders.from_folder(path,suffle=False) \n\n\ndls.show_batch()\n\n\n\n\n(1) cnn_learner를 이용하여 lrnr 오브젝트를 생성하라. - arch 는 resnet34 로 설정할 것 - metrics 는 error_rate 로 설정할 것\n(풀이)\n\nlrnr = cnn_learner(dls, arch = resnet34, metrics=error_rate)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n(2) fine_tune 을 이용하여 lrnr 오브젝트를 학습하라.\n(풀이)\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.282870\n      0.150136\n      0.049068\n      00:05\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.042991\n      0.017522\n      0.006379\n      00:05\n    \n  \n\n\n\n(3) 아래를 이용하여 X,y를 만들어라.\nX,y = dls.one_batch()\nX,y의 shape을 조사하라. X에는 몇개의 이미지가 있는가? 이미지의 size는 얼마인가?\n(풀이)\n\nX,y = dls.one_batch()\nX.shape\n\ntorch.Size([64, 3, 28, 28])\n\n\nX에는 64개의 이미지가 있고 크기는 (28,28) 이다.\n(4) 아래의 코드를 이용하여 X의 두번째 이미지가 어떠한 숫자를 의미하는지 확인하라. (그림보고 3인지 7인지 확인하여 답을 쓸 것)\nshow_image(X[0])\n그리고 show_image가 정의된 파일의 경로를 확인하고 show_image가 python 내장함수 인지, torch에서 지원하는 함수인지 fastai에서 지원하는 함수인지 파악하라.\n(풀이)\n\nshow_image(X[1]) # 두번째 이미지 \n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n<AxesSubplot:>\n\n\n\n\n\n\nshow_image?\n\n\nSignature:\nshow_image(\n    im,\n    ax=None,\n    figsize=None,\n    title=None,\n    ctx=None,\n    cmap=None,\n    norm=None,\n    *,\n    aspect=None,\n    interpolation=None,\n    alpha=None,\n    vmin=None,\n    vmax=None,\n    origin=None,\n    extent=None,\n    interpolation_stage=None,\n    filternorm=True,\n    filterrad=4.0,\n    resample=None,\n    url=None,\n    data=None,\n    **kwargs,\n)\nDocstring: Show a PIL or PyTorch image on `ax`.\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/torch_core.py\nType:      function\n\n\n\n\n\nfastai에서 지원하는 함수\n\n(5) lrnr 오브젝트를 이용하여 AI가 X[0]을 어떤 값으로 판단하는지 확인하라. 올바르게 판단하였는가? 올바르게 판단했다면 몇 프로의 확신으로 판단하였는가? <– 문제가 의도한 것과 다르게 만들어졌어요\n(풀이)\n\nshow_image(X[0]) # 첫번째 이미지\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n<AxesSubplot:>\n\n\n\n\n\n\nlrnr.model(X[0].reshape(1,3,28,28))\n\nTensorBase([[ 3.4148, -5.0356]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nimport numpy as np\na=np.exp(3.4148)\nb=np.exp(-5.0356)\nprint('3일확률',a/(a+b))\nprint('7일확률',b/(a+b))\n\n3일확률 0.9997862308347155\n7일확률 0.0002137691652844868\n\n\n\n원래문제의도: lrnr.predict(X[0].to(\"cpu\"))\n\n\n\n\n아래를 이용하여 rcmd_anal.csv 를 다운로드 받고 dls오브젝트를 만들어라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      0\n      1\n      15\n      1.084308\n      홍차5\n    \n    \n      1\n      1\n      1\n      4.149209\n      커피1\n    \n    \n      2\n      1\n      11\n      1.142659\n      홍차1\n    \n    \n      3\n      1\n      5\n      4.033415\n      커피5\n    \n    \n      4\n      1\n      4\n      4.078139\n      커피4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      100\n      18\n      4.104276\n      홍차8\n    \n    \n      996\n      100\n      17\n      4.164773\n      홍차7\n    \n    \n      997\n      100\n      14\n      4.026915\n      홍차4\n    \n    \n      998\n      100\n      4\n      0.838720\n      커피4\n    \n    \n      999\n      100\n      7\n      1.094826\n      커피7\n    \n  \n\n1000 rows × 4 columns\n\n\n\n(1) 73번 유저가 먹은 아이템 및 평점을 출력하는 코드를 작성하라. 이를 기반으로 73번 유저가 어떠한 취향인지 파악하라.\n(풀이)\n\ndf.query('user == 73')\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      720\n      73\n      20\n      3.733853\n      홍차10\n    \n    \n      721\n      73\n      18\n      3.975004\n      홍차8\n    \n    \n      722\n      73\n      9\n      1.119541\n      커피9\n    \n    \n      723\n      73\n      13\n      3.840801\n      홍차3\n    \n    \n      724\n      73\n      2\n      0.943742\n      커피2\n    \n    \n      725\n      73\n      4\n      1.152405\n      커피4\n    \n    \n      726\n      73\n      1\n      0.887292\n      커피1\n    \n    \n      727\n      73\n      7\n      0.947641\n      커피7\n    \n    \n      728\n      73\n      6\n      0.868370\n      커피6\n    \n    \n      729\n      73\n      17\n      3.873590\n      홍차7\n    \n  \n\n\n\n\n\n홍차를 선호\n\n(2) dls와 lrnr 오브젝트를 생성하고 lrnr 오브젝트를 학습하라.\n(풀이)\n\ndls = CollabDataLoaders.from_df(df)\nlrnr = collab_learner(dls,y_range=(0,5))\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      2.337114\n      2.258755\n      00:00\n    \n    \n      1\n      2.328897\n      2.254714\n      00:00\n    \n    \n      2\n      2.320246\n      2.237874\n      00:00\n    \n    \n      3\n      2.300545\n      2.191783\n      00:00\n    \n    \n      4\n      2.265857\n      2.104007\n      00:00\n    \n    \n      5\n      2.207397\n      1.966761\n      00:00\n    \n    \n      6\n      2.123599\n      1.783263\n      00:00\n    \n    \n      7\n      2.008980\n      1.562448\n      00:00\n    \n    \n      8\n      1.865242\n      1.317642\n      00:00\n    \n    \n      9\n      1.697832\n      1.068948\n      00:00\n    \n    \n      10\n      1.515044\n      0.833239\n      00:00\n    \n    \n      11\n      1.326496\n      0.625003\n      00:00\n    \n    \n      12\n      1.139156\n      0.453686\n      00:00\n    \n    \n      13\n      0.962462\n      0.320953\n      00:00\n    \n    \n      14\n      0.802481\n      0.223124\n      00:00\n    \n    \n      15\n      0.662327\n      0.155420\n      00:00\n    \n    \n      16\n      0.542384\n      0.110662\n      00:00\n    \n    \n      17\n      0.442099\n      0.082435\n      00:00\n    \n    \n      18\n      0.359706\n      0.064858\n      00:00\n    \n    \n      19\n      0.292656\n      0.054441\n      00:00\n    \n    \n      20\n      0.238817\n      0.048325\n      00:00\n    \n    \n      21\n      0.195901\n      0.045092\n      00:00\n    \n    \n      22\n      0.161955\n      0.043386\n      00:00\n    \n    \n      23\n      0.135049\n      0.042616\n      00:00\n    \n    \n      24\n      0.113653\n      0.042549\n      00:00\n    \n    \n      25\n      0.096877\n      0.042678\n      00:00\n    \n    \n      26\n      0.083618\n      0.043010\n      00:00\n    \n    \n      27\n      0.073081\n      0.043308\n      00:00\n    \n    \n      28\n      0.064768\n      0.043905\n      00:00\n    \n    \n      29\n      0.058133\n      0.044605\n      00:00\n    \n    \n      30\n      0.053050\n      0.044990\n      00:00\n    \n    \n      31\n      0.048904\n      0.045569\n      00:00\n    \n    \n      32\n      0.045665\n      0.045833\n      00:00\n    \n    \n      33\n      0.043033\n      0.045906\n      00:00\n    \n    \n      34\n      0.040883\n      0.046624\n      00:00\n    \n    \n      35\n      0.039263\n      0.046878\n      00:00\n    \n    \n      36\n      0.037608\n      0.047040\n      00:00\n    \n    \n      37\n      0.036450\n      0.047146\n      00:00\n    \n    \n      38\n      0.035638\n      0.047335\n      00:00\n    \n    \n      39\n      0.034883\n      0.047623\n      00:00\n    \n    \n      40\n      0.034177\n      0.048048\n      00:00\n    \n    \n      41\n      0.033486\n      0.047836\n      00:00\n    \n    \n      42\n      0.033047\n      0.048263\n      00:00\n    \n    \n      43\n      0.032634\n      0.048296\n      00:00\n    \n    \n      44\n      0.032165\n      0.048577\n      00:00\n    \n    \n      45\n      0.031884\n      0.048578\n      00:00\n    \n    \n      46\n      0.031517\n      0.048725\n      00:00\n    \n    \n      47\n      0.031158\n      0.048977\n      00:00\n    \n    \n      48\n      0.030711\n      0.048955\n      00:00\n    \n    \n      49\n      0.030465\n      0.049127\n      00:00\n    \n  \n\n\n\n(3) 아래와 같은 데이터 프레임을 생성하고 df_new 에 저장하라.\n\n#collapse\nimport IPython \n_html='<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>user</th>\\n      <th>item</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>73</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>73</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>73</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>73</td>\\n      <td>4</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>73</td>\\n      <td>5</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>73</td>\\n      <td>6</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>73</td>\\n      <td>7</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>73</td>\\n      <td>8</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>73</td>\\n      <td>9</td>\\n    </tr>\\n    <tr>\\n      <th>9</th>\\n      <td>73</td>\\n      <td>10</td>\\n    </tr>\\n    <tr>\\n      <th>10</th>\\n      <td>73</td>\\n      <td>11</td>\\n    </tr>\\n    <tr>\\n      <th>11</th>\\n      <td>73</td>\\n      <td>12</td>\\n    </tr>\\n    <tr>\\n      <th>12</th>\\n      <td>73</td>\\n      <td>13</td>\\n    </tr>\\n    <tr>\\n      <th>13</th>\\n      <td>73</td>\\n      <td>14</td>\\n    </tr>\\n    <tr>\\n      <th>14</th>\\n      <td>73</td>\\n      <td>15</td>\\n    </tr>\\n    <tr>\\n      <th>15</th>\\n      <td>73</td>\\n      <td>16</td>\\n    </tr>\\n    <tr>\\n      <th>16</th>\\n      <td>73</td>\\n      <td>17</td>\\n    </tr>\\n    <tr>\\n      <th>17</th>\\n      <td>73</td>\\n      <td>18</td>\\n    </tr>\\n    <tr>\\n      <th>18</th>\\n      <td>73</td>\\n      <td>19</td>\\n    </tr>\\n    <tr>\\n      <th>19</th>\\n      <td>73</td>\\n      <td>20</td>\\n    </tr>\\n  </tbody>\\n</table>'\nIPython.display.HTML(_html)\n\n\n\n  \n    \n      \n      user\n      item\n    \n  \n  \n    \n      0\n      73\n      1\n    \n    \n      1\n      73\n      2\n    \n    \n      2\n      73\n      3\n    \n    \n      3\n      73\n      4\n    \n    \n      4\n      73\n      5\n    \n    \n      5\n      73\n      6\n    \n    \n      6\n      73\n      7\n    \n    \n      7\n      73\n      8\n    \n    \n      8\n      73\n      9\n    \n    \n      9\n      73\n      10\n    \n    \n      10\n      73\n      11\n    \n    \n      11\n      73\n      12\n    \n    \n      12\n      73\n      13\n    \n    \n      13\n      73\n      14\n    \n    \n      14\n      73\n      15\n    \n    \n      15\n      73\n      16\n    \n    \n      16\n      73\n      17\n    \n    \n      17\n      73\n      18\n    \n    \n      18\n      73\n      19\n    \n    \n      19\n      73\n      20\n    \n  \n\n\n\n(풀이)\n\ndf_new=pd.DataFrame({'user':[73]*20,'item':range(1,21)})\ndf_new\n\n\n\n\n\n  \n    \n      \n      user\n      item\n    \n  \n  \n    \n      0\n      73\n      1\n    \n    \n      1\n      73\n      2\n    \n    \n      2\n      73\n      3\n    \n    \n      3\n      73\n      4\n    \n    \n      4\n      73\n      5\n    \n    \n      5\n      73\n      6\n    \n    \n      6\n      73\n      7\n    \n    \n      7\n      73\n      8\n    \n    \n      8\n      73\n      9\n    \n    \n      9\n      73\n      10\n    \n    \n      10\n      73\n      11\n    \n    \n      11\n      73\n      12\n    \n    \n      12\n      73\n      13\n    \n    \n      13\n      73\n      14\n    \n    \n      14\n      73\n      15\n    \n    \n      15\n      73\n      16\n    \n    \n      16\n      73\n      17\n    \n    \n      17\n      73\n      18\n    \n    \n      18\n      73\n      19\n    \n    \n      19\n      73\n      20\n    \n  \n\n\n\n\n(4) 아래의 코드를 이용하여 73번 유저의 취향을 파악하라. 73번 유저가 커피3, 커피5를 먹는다면 얼마정도의 평점을 줄 것이라 예측되는가?\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n(풀이)\n\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n\n\n\n\n\n\n\n\n(tensor([0.9698, 1.0314, 1.0191, 1.0177, 1.0122, 0.9323, 1.0513, 1.0184, 1.0316,\n         0.9842, 3.8255, 3.9591, 3.8640, 3.8937, 3.9437, 3.8947, 3.8272, 3.9503,\n         3.8117, 3.8603]),\n None)\n\n\n\n커피3: 1.0191, 커피5: 1.0122\n\n\n\n\n아래를 이용하여 자료를 다운로드 받아라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-19-human_numbers_100.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      text\n    \n  \n  \n    \n      0\n      0\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1\n      1\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      2\n      2\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      3\n      3\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      4\n      4\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      1995\n      1995\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1996\n      1996\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1997\n      1997\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1998\n      1998\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1999\n      1999\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n  \n\n2000 rows × 2 columns\n\n\n\n(1) TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라. - is_lm = True 로 설정할 것 - seq_len = 5 로 설정할 것\n(풀이)\n\ndls = TextDataLoaders.from_df(df,is_lm=True,seq_len=5,text_col='text')\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      text_\n    \n  \n  \n    \n      0\n      xxbos one , two ,\n      one , two , three\n    \n    \n      1\n      hundred xxbos one , two\n      xxbos one , two ,\n    \n    \n      2\n      one hundred xxbos one ,\n      hundred xxbos one , two\n    \n    \n      3\n      , one hundred xxbos one\n      one hundred xxbos one ,\n    \n    \n      4\n      nine , one hundred xxbos\n      , one hundred xxbos one\n    \n    \n      5\n      ninety nine , one hundred\n      nine , one hundred xxbos\n    \n    \n      6\n      , ninety nine , one\n      ninety nine , one hundred\n    \n    \n      7\n      eight , ninety nine ,\n      , ninety nine , one\n    \n    \n      8\n      ninety eight , ninety nine\n      eight , ninety nine ,\n    \n  \n\n\n\n(2) lrnr 오브젝트를 만들어라. - arch = AWD_LSTM 이용 - metrics = accuracy 이용\n(풀이)\n\nlrnr = language_model_learner(dls, arch= AWD_LSTM, metrics=accuracy)\n\n(3) lrnr오브젝트에서 fine_tune(3) 메소드를 이용하여 모형을 학습하라.\n(풀이)\n\nlrnr.fine_tune(3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.534681\n      0.168856\n      0.977650\n      00:49\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.018749\n      0.003256\n      0.999205\n      00:54\n    \n    \n      1\n      0.001580\n      0.002430\n      0.999324\n      00:54\n    \n    \n      2\n      0.000651\n      0.002244\n      0.999315\n      00:54\n    \n  \n\n\n\n(4) ‘one , two ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('one, two,', n_words=50) \n\n\n\n\n\n\n\n\n'one , two , three , four , five , six , seven , eight , nine , ten , eleven , twelve , thirteen , fourteen , fifteen , sixteen , seventeen , eighteen , nineteen , twenty , twenty one , twenty two , twenty three , twenty four , twenty five'\n\n\n(5) ‘twenty , twenty one ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('twenty, twenty one,', n_words=50) \n\n\n\n\n\n\n\n\n'twenty , twenty one , twenty two , twenty three , twenty four , twenty five , twenty six , twenty seven , twenty eight , twenty nine , thirty , thirty one , thirty two , thirty three , thirty four , thirty five , thirty six , thirty seven , thirty eight ,'\n\n\n\n\n\nCollab 에서 (혹은 리눅스기반 서버에서) 아래의 명령어를 순서대로 실행해보라.\n!ls\n!ls -a \n!ls .\n!ls .. \n!ls sample\n!mkdir asdf \n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n!cp 2022-09-08-rcmd_anal.csv ./asdf \n!ls ./asdf \n!rm 2022-09-08-rcmd_anal.csv \n!rm -rf asdf \n각 명령들이 무엇을 의미하는지 간단히 서술하라.\n(풀이)\n!ls - 현재디렉토리 파일+폴더 출력 - !ls . 와 같음 - !ls ./ 와 같음\n!ls -a - 현재디렉토리 파일+폴더 출력, 숨겨진 항목까지 출력\n!ls . - 현재디렉토리 파일+폴더 출력 - !ls 와 같음 - !ls ./ 와 같음\n!ls .. - 현재디렉토리보다 상위디렉토리의 파일+폴더 출력\n!ls sample - 현재디렉토리에 sample 디렉토리 출력 - !ls ./sample 과 같음\n!mkdir asdf - 현재디렉토리에 asdf 폴더 생성 - !mkdir ./asdf 와 같음\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv - url에 있는 파일 다운로드하여 현재디렉토리에 저장\n!cp 2022-09-08-rcmd_anal.csv ./asdf - 2022-09-08-rcmd_anal.csv 파일을 ./asdf 로 복사\n!ls ./asdf - 현재디렉토리에서 asdf 디렉토리의 내용출력 - !ls asdf 와 같음\n!rm 2022-09-08-rcmd_anal.csv - 현재 디렉토리에서 2022-09-08-rcmd_anal.csv 파일삭제; - rm ./2022-09-08-rcmd_anal.csv 와 같음\n!rm -rf asdf - 현재 디렉토리에서 asdf 삭제 (asdf 폴더내에 파일이 존재하면 파일도 같이 삭제) - r은 recursively, f는 force의 약자\n\n\n\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-x3HQLeyrS7GLh70Dv_54Yg"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DL2022",
    "section": "",
    "text": "(2주차) 9월8일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(1주차) 9월6일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(3주차) 9월20일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(2주차) 9월13일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n(3주차) 9월15일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n(1주차) 9월1일\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 1 (09.19) – 풀이O\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]