[
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "",
    "text": "Transfer Learninig (CIFAR10/ResNet18), CAM의 구현 및 시각화"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#수제네트워크",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#수제네트워크",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "수제네트워크",
    "text": "수제네트워크\n(1) dls\n\ndls = ImageDataLoaders.from_folder(path,train='train',valid='test') \n\n\n_X,_y = dls.one_batch()\n_X.shape, _y.shape\n\n(torch.Size([64, 3, 32, 32]), torch.Size([64]))\n\n\n\n!ls /home/cgb4/.fastai/data/cifar10/train # 10개의 클래스\n\nairplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n\n\n\ndls.show_batch()\n\n\n\n\n(2) lrnr 생성\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,128,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\n\nnet1(_X.to(\"cpu\")).shape\n\ntorch.Size([64, 25088])\n\n\n\nnet = torch.nn.Sequential(\n    net1, \n    torch.nn.Linear(25088,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy) \n\n(3) 학습\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      1.104867\n      1.105857\n      0.620600\n      00:04\n    \n    \n      1\n      0.961969\n      1.050836\n      0.640000\n      00:04\n    \n    \n      2\n      0.902597\n      1.058793\n      0.637600\n      00:04\n    \n    \n      3\n      0.854093\n      1.036581\n      0.657200\n      00:04\n    \n    \n      4\n      0.779191\n      1.013788\n      0.663400\n      00:04\n    \n    \n      5\n      0.723487\n      1.091586\n      0.642500\n      00:04\n    \n    \n      6\n      0.694052\n      1.064836\n      0.655700\n      00:04\n    \n    \n      7\n      0.629718\n      1.044633\n      0.668900\n      00:04\n    \n    \n      8\n      0.589516\n      1.168362\n      0.645100\n      00:04\n    \n    \n      9\n      0.572035\n      1.117689\n      0.654800\n      00:04\n    \n  \n\n\n\n\n이게 생각보다 잘 안맞아요.. 70넘기 힘듬"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#전이학습-남이-만든-네트워크",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#전이학습-남이-만든-네트워크",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "전이학습 (남이 만든 네트워크)",
    "text": "전이학습 (남이 만든 네트워크)\n(2) lrnr 생성\n\nnet = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1)\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n\\(k=1000\\) 즉 1000개의 물체를 구분하는 모형임\n\n\nnet.fc = torch.nn.Linear(in_features=512, out_features=10) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy)\n\n(3) 학습\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.813139\n      0.803660\n      0.735300\n      00:10\n    \n    \n      1\n      0.667533\n      0.742656\n      0.756300\n      00:11\n    \n    \n      2\n      0.544296\n      0.735011\n      0.755900\n      00:10\n    \n    \n      3\n      0.449801\n      0.671868\n      0.784000\n      00:10\n    \n    \n      4\n      0.390996\n      0.657825\n      0.780100\n      00:11\n    \n    \n      5\n      0.310046\n      0.690071\n      0.788700\n      00:10\n    \n    \n      6\n      0.259605\n      0.671683\n      0.802500\n      00:10\n    \n    \n      7\n      0.199240\n      0.715251\n      0.796800\n      00:10\n    \n    \n      8\n      0.195551\n      0.772891\n      0.795100\n      00:10\n    \n    \n      9\n      0.150421\n      0.764864\n      0.801600\n      00:10\n    \n  \n\n\n\n\nCIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음\n일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다."
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#전이학습-다른-구현-순수-fastai-이용",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#전이학습-다른-구현-순수-fastai-이용",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "전이학습 다른 구현: 순수 fastai 이용",
    "text": "전이학습 다른 구현: 순수 fastai 이용\n- 예전코드 복습\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfiles= get_image_files(path)\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.191067\n      0.027880\n      0.991881\n      00:29\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.039166\n      0.012174\n      0.996617\n      00:37\n    \n  \n\n\n\n- 사실 위의 코드가 transfer learning 이었음.\n\n#collapse_output\nlrnr.model\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#cam이란",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#cam이란",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "CAM이란?",
    "text": "CAM이란?\n\nref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n- Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#학습에-사용할-데이터-load",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#학습에-사용할-데이터-load",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "학습에 사용할 데이터 Load",
    "text": "학습에 사용할 데이터 Load\n\npath = untar_data(URLs.PETS)/'images'\n\n\npath.ls()\n\n(#7393) [Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/miniature_pinscher_81.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/english_setter_78.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/chihuahua_156.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/english_cocker_spaniel_181.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/scottish_terrier_131.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/Bengal_188.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_101.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/British_Shorthair_41.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/great_pyrenees_49.jpg'),Path('/home/cgb4/.fastai/data/oxford-iiit-pet/images/wheaten_terrier_194.jpg')...]\n\n\n\nfiles= get_image_files(path)\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512))"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#구현0단계-예비학습",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#구현0단계-예비학습",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "구현0단계– 예비학습",
    "text": "구현0단계– 예비학습\n\n# 하나의 이미지 선택\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nximg\n\n\n\n\n\nx = first(dls.test_dl([ximg]))[0]\nx\n\nTensorImage([[[[0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8745, 0.8784, 0.8824,  ..., 0.8902, 0.8863, 0.8824],\n               [0.9059, 0.8980, 0.8902,  ..., 0.8824, 0.8863, 0.8824],\n               [0.8863, 0.8863, 0.8824,  ..., 0.8784, 0.8863, 0.8863]],\n\n              [[0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8784, 0.8824, 0.8863,  ..., 0.8745, 0.8667, 0.8588],\n               [0.9098, 0.9020, 0.8902,  ..., 0.8745, 0.8706, 0.8627],\n               [0.8902, 0.8902, 0.8784,  ..., 0.8784, 0.8745, 0.8706]],\n\n              [[0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               ...,\n               [0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n               [0.9176, 0.9137, 0.9059,  ..., 0.8745, 0.8706, 0.8667],\n               [0.8980, 0.9020, 0.8980,  ..., 0.8745, 0.8706, 0.8667]]]],\n            device='cuda:0')\n\n\n\n\n# AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1) \n\n\nX = torch.arange(48).reshape(1,3,4,4)*1.0 \nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X)\n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nX[0,0,...].mean(),X[0,1,...].mean(),X[0,2,...].mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\n\n# torch.einsum\n(예시1)\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntorch.einsum('ij->ji',tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n(예시2)\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -> ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n(예시3)\n\nx.to(\"cpu\").shape\n\ntorch.Size([1, 3, 512, 512])\n\n\n\ntorch.einsum('ocij -> ijc',x.to(\"cpu\")).shape\n\ntorch.Size([512, 512, 3])\n\n\n\nplt.imshow(torch.einsum('ocij -> ijc',x.to(\"cpu\")))\n\n<matplotlib.image.AxesImage at 0x7f5fc4136290>"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#구현1단계-이미지분류-잘하는-네트워크-선택",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#구현1단계-이미지분류-잘하는-네트워크-선택",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "구현1단계– 이미지분류 잘하는 네트워크 선택",
    "text": "구현1단계– 이미지분류 잘하는 네트워크 선택\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.169602\n      0.011903\n      0.996617\n      00:29\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.052203\n      0.012352\n      0.998647\n      00:38"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#구현2단계-네트워크의-끝-부분-수정",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#구현2단계-네트워크의-끝-부분-수정",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "구현2단계– 네트워크의 끝 부분 수정",
    "text": "구현2단계– 네트워크의 끝 부분 수정\n- 모형의 분해\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n- net2를 좀더 살펴보자.\n\nnet2\n\nSequential(\n  (0): AdaptiveConcatPool2d(\n    (ap): AdaptiveAvgPool2d(output_size=1)\n    (mp): AdaptiveMaxPool2d(output_size=1)\n  )\n  (1): fastai.layers.Flatten(full=False)\n  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (3): Dropout(p=0.25, inplace=False)\n  (4): Linear(in_features=1024, out_features=512, bias=False)\n  (5): ReLU(inplace=True)\n  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (7): Dropout(p=0.5, inplace=False)\n  (8): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nprint(net1(_X).shape)\nprint(net2[0](net1(_X)).shape)\nprint(net2[1](net2[0](net1(_X))).shape)\nprint(net2[2](net2[1](net2[0](net1(_X)))).shape)\n\ntorch.Size([64, 512, 16, 16])\ntorch.Size([64, 1024, 1, 1])\ntorch.Size([64, 1024])\ntorch.Size([64, 1024])\n\n\n- net2를 아래와 같이 수정하고 재학습하자 (왜?)\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # (64,512,16,16) -> (64,512,1,1) \n    torch.nn.Flatten(), # (64,512,1,1) -> (64,512) \n    torch.nn.Linear(512,2,bias=False) # (64,512) -> (64,2) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy) # loss_fn??\n\n\nlrnr2.loss_func, lrnr.loss_func ## 알아서 기존의 loss function으로 잘 들어가 있음. \n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 수정해서 accuracy가 안좋아지긴 했는데 그래도 쓸만함 \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.252908\n      0.741022\n      0.755751\n      00:38\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.130946\n      0.126084\n      0.957375\n      00:38\n    \n    \n      1\n      0.143405\n      0.229703\n      0.905954\n      00:38\n    \n    \n      2\n      0.092800\n      0.104366\n      0.962788\n      00:38\n    \n    \n      3\n      0.046969\n      0.043439\n      0.983762\n      00:38\n    \n    \n      4\n      0.024211\n      0.038318\n      0.983762\n      00:38"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#구현3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈",
    "text": "구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정하였을 경우 출력과정 상상\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nnet2\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nprint(net1(x).shape)\nprint(net2[0](net1(x)).shape)\nprint(net2[1](net2[0](net1(x))).shape)\nprint(net2[2](net2[1](net2[0](net1(x)))).shape)\n\ntorch.Size([1, 512, 16, 16])\ntorch.Size([1, 512, 1, 1])\ntorch.Size([1, 512])\ntorch.Size([1, 2])\n\n\n- 최종결과 확인\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\ndls.vocab\n\n['cat', 'dog']\n\n\n\nnet(x)에서 뒤쪽의 값이 클수록 ’dog’를 의미한다.\n\n- net2의 순서 바꾸기 전 전체 네트워크:\n\\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [-9.0358,  9.0926]\\]\n- 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)\n\\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [−9.0358,9.0926]\\]\n\n여기에서 (1,512,16,16) -> (1,2,16,16) 로 가는 선형변환을 적용하는 방법? (16,16) each pixel에 대하여 (512 \\(\\to\\) 2)로 가는 변환을 수행\n\n- 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까)\n\n_x =torch.tensor([1,2,3.14,4]).reshape(4,1)\n_x \n\ntensor([[1.0000],\n        [2.0000],\n        [3.1400],\n        [4.0000]])\n\n\n\n_l1 = torch.nn.Linear(1,1,bias=False)\n_l1(_x).mean() # _x -> 선형변환 -> 평균 \n\ntensor(-1.4045, grad_fn=<MeanBackward0>)\n\n\n\n_l1(_x.mean().reshape(1,1)) # _x -> 평균 -> 선형변환\n\ntensor([[-1.4045]], grad_fn=<MmBackward0>)\n\n\n- 구현해보자.\n\nwhy = torch.einsum('cb,abij->acij',net2[2].weight,net1(x))\n\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#잠깐-멈추고-생각",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#잠깐-멈추고-생각",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "잠깐 멈추고 생각",
    "text": "잠깐 멈추고 생각\n- 이미지\n\nximg\n\n\n\n\n- 네트워크의 결과\n\nnet2(net1(x))\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n-9.0358 << 9.0926 이므로 ’ximg’는 높은 확률로 개라는 뜻이다.\n\n- 아래의네트워크를 관찰\n\\[\\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [-9.0358,9.0926]\\]\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n더 파고들어서 분석해보자.\n\nwhy.shape\n\ntorch.Size([1, 2, 16, 16])\n\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(-9.0358, device='cuda:0', grad_fn=<AliasBackward0>),\n TensorImage(9.0926, device='cuda:0', grad_fn=<AliasBackward0>))\n\n\nwhy[0,0,:,:]\n\n#collapse_output\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[   0,    0,    0,    0,    0,    0,   -1,   -4,   -5,   -4,   -1,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -12,  -26,  -33,  -28,  -14,\n                -3,    0,    0,    0,    0],\n             [   0,    0,    1,    1,    0,   -2,  -22,  -60,  -75,  -73,  -41,\n               -10,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -2,  -25,  -75, -116, -110,  -64,\n               -18,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -22,  -76, -147, -132,  -69,\n               -21,   -1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -16,  -60, -112, -110,  -59,\n               -18,   -3,    0,    0,   -7],\n             [   0,    0,    0,    0,    0,    0,   -9,  -38,  -66,  -66,  -37,\n               -12,   -2,    0,    0,   -2],\n             [   0,    1,    1,    0,    0,    0,   -4,  -25,  -34,  -27,  -18,\n                -6,   -1,    0,    0,    0],\n             [   1,    1,    1,    0,    0,    0,   -2,  -11,  -15,  -10,   -5,\n                -2,    0,    0,    0,    0],\n             [   1,    1,    0,    0,    0,    0,   -1,   -2,   -4,   -3,    0,\n                 0,    0,    0,   -1,    0],\n             [   0,    0,    0,   -1,   -3,   -1,   -1,   -1,   -2,   -2,   -2,\n                -1,   -2,   -2,    0,    0],\n             [   0,    0,    0,   -1,   -1,   -1,   -1,   -2,   -5,   -4,   -3,\n                -1,    0,    0,   -1,   -1],\n             [  -1,    0,    0,    0,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n                -2,    0,   -1,   -1,   -1],\n             [  -1,   -2,   -1,    0,   -1,   -3,   -2,    0,    2,    0,    0,\n                -1,    0,   -1,   -2,   -3],\n             [  -3,   -4,   -3,   -3,   -3,   -5,   -3,   -1,   -1,   -3,   -2,\n                -2,   -1,   -2,   -4,   -4],\n             [  -3,   -4,   -4,   -4,   -4,   -3,   -3,   -2,   -3,   -4,   -4,\n                -3,   -2,   -3,   -4,   -4]], device='cuda:0')\n\n\n\n이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다.\n\nwhy[0,1,:,:]\n\n#collapse_output\n(why[0,1,:,:]).to(torch.int64)\n\nTensorImage([[  0,   0,   0,   0,   0,   0,   1,   4,   5,   4,   1,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  12,  27,  34,  29,  15,   3,   0,\n                0,   0,   0],\n             [  0,   0,  -1,  -1,   0,   2,  23,  62,  79,  76,  43,  11,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   2,  26,  79, 122, 116,  66,  18,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  24,  81, 152, 136,  72,  21,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,  18,  64, 116, 113,  61,  19,   3,\n                0,   0,   6],\n             [  0,   0,   0,   0,   0,   0,  10,  40,  69,  68,  38,  12,   1,\n                0,   0,   2],\n             [  0,  -1,  -1,   0,   0,   0,   4,  25,  35,  28,  18,   6,   1,\n                0,   0,   0],\n             [ -1,  -1,  -1,   0,   0,   0,   2,  10,  14,  10,   5,   1,   0,\n                0,   0,   0],\n             [  0,  -1,   0,   0,   0,   0,   0,   2,   4,   3,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   3,   1,   0,   1,   2,   2,   2,   0,   1,\n                2,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   2,   5,   3,   3,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   1,   1,   0,\n                0,   0,   1],\n             [  1,   1,   1,   0,   0,   2,   1,   0,  -2,   0,   0,   1,   0,\n                0,   1,   1],\n             [  2,   2,   2,   2,   2,   4,   2,   1,   1,   2,   1,   1,   1,\n                1,   3,   3],\n             [  2,   3,   3,   3,   3,   2,   2,   2,   2,   3,   2,   2,   2,\n                2,   3,   3]], device='cuda:0')\n\n\n\n이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다.\n\n- 시각화\n\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma')\n\n<matplotlib.image.AxesImage at 0x7f5fce6d7b90>\n\n\n\n\n\n\nmagma = 검은색 < 보라색 < 빨간색 < 노란색\n왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거\n\n- why_cat, why_dog를 (16,16) \\(\\to\\) (512,512) 로 resize\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n<matplotlib.image.AxesImage at 0x7f5fbd81c890>\n\n\n\n\n\n- 겹쳐그리기\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n<matplotlib.image.AxesImage at 0x7f5fd48cd7d0>\n\n\n\n\n\n- 하니이미지 시각화\n\n#\n#!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true\nximg= PILImage.create('2022-09-06-hani01.jpeg')\nx= first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij->acij',net2[2].weight,net1(x))\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n<matplotlib.image.AxesImage at 0x7f5fbca0ad10>\n\n\n\n\n\n- 하니이미지 시각화 with prob\n\nsftmax=torch.nn.Softmax(dim=1)\n\n\nsftmax(net(x))\n\nTensorImage([[1.5489e-05, 9.9998e-01]], device='cuda:0',\n            grad_fn=<AliasBackward0>)\n\n\n\ncatprob, dogprob = sftmax(net(x))[0,0].item(), sftmax(net(x))[0,1].item()\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[0].set_title('catprob= %f' % catprob) \nax[1].imshow(torch.einsum('ocij -> ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].set_title('dogprob=%f' % dogprob)\n\nText(0.5, 1.0, 'dogprob=0.999985')"
  },
  {
    "objectID": "posts/III. CNN/2022-10-25-8wk-2.html#구현4단계-cam-시각화",
    "href": "posts/III. CNN/2022-10-25-8wk-2.html#구현4단계-cam-시각화",
    "title": "08wk-2: 이미지분석 (3)",
    "section": "구현4단계– CAM 시각화",
    "text": "구현4단계– CAM 시각화\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=75\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -> acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob>dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/III. CNN/2022-10-26-Assignment3.html",
    "href": "posts/III. CNN/2022-10-26-Assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "assignment 3"
  },
  {
    "objectID": "posts/III. CNN/2022-10-26-Assignment3.html#크롤링을-통한-이미지-분석-및-cam",
    "href": "posts/III. CNN/2022-10-26-Assignment3.html#크롤링을-통한-이미지-분석-및-cam",
    "title": "Assignment 3",
    "section": "1. 크롤링을 통한 이미지 분석 및 CAM",
    "text": "1. 크롤링을 통한 이미지 분석 및 CAM\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것)\n힌트1: hynn, iu 라는 키워드로 크롤링하여 이미지자료를 모으는 코드\n\n# 크롤링에 필요한 준비작업들\n#!pip install -Uqq duckduckgo_search\nfrom duckduckgo_search import ddg_images\nfrom fastdownload import download_url\nfrom fastcore.all import *\ndef search_images(term, max_images=200): return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\n\n# 폴더만드는코드 -- 사실 손으로 만들어도 무방함.. \n!mkdir images\n!mkdir images/train\n!mkdir images/test \n!mkdir images/train/iu\n!mkdir images/train/hynn\n!mkdir images/test/iu\n!mkdir images/test/hynn\n\n\ndownload_images(dest='./images/train/iu',urls=search_images('iu',max_images=200)) # iu 라는 키워드로 200개 이미지 크롤링 -> ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn',max_images=200)) # hynn 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/iu',urls=search_images('iu kpop',max_images=200))  # iu kpop 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/hynn',urls=search_images('hynn kpop',max_images=200)) # hynn kpop 이라는 키워드로 200개 이미지 크롤링 -> ./images/train/hynn 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\ndownload_images(dest='./images/test/iu',urls=search_images('iu photo',max_images=50)) # iu photo 라는 키워드로 50개 이미지 크롤링 -> ./images/test/iu 에 저장\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/hynn',urls=search_images('hynn photo',max_images=50)) # hynn photo 라는 키워드로 50개 이미지 크롤링 -> ./images/test/hynn 에 저장 \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n힌트2: 불량이미지 삭제\n\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n\n(#11) [Path('images/train/iu/b6f25ccd-4629-4686-8867-ea2b0de61e9e.jpg'),Path('images/train/iu/3bd8e46c-bb07-43ea-8e1a-5772e2ce25a1.jpg'),Path('images/train/iu/3970a84d-4625-435c-bc1d-1446b2b00709.jpg'),Path('images/train/iu/e794b8bd-78f9-43f0-a3a8-21d688a551fd.jpg'),Path('images/train/hynn/a26b0c36-8188-4c46-b9f5-03c46b0ad863.png'),Path('images/train/hynn/4024807e-da9a-45e6-a238-f5c3f66a043e.jpg'),Path('images/train/hynn/356d6cbb-b091-4ffb-8006-6e762947f7b3.jpg'),Path('images/train/hynn/4af71c78-5ed5-429b-aa15-92d24af461a5.jpg'),Path('images/train/hynn/d0892ddb-77f3-4ef6-98f6-09e8b53a9ea1.png'),Path('images/train/hynn/9959d239-6157-47f3-a6f5-318b6f00ca7d.jpg')...]\n\n\n\n불량이미지 목록\n\n\nbad_images.map(Path.unlink)\n\n(#11) [None,None,None,None,None,None,None,None,None,None...]\n\n\n\n불량이미지는 dls를 불러올때 방해되므로 제거\n\n(2) ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라.\n힌트1: dls를 만드는 코드\n\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \n\n\ndls.show_batch()\n\n\n\n\n(3) resnet34를 이용하여 학습하라.\n(4) CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라."
  },
  {
    "objectID": "posts/III. CNN/2022-10-26-Assignment3.html#다음을-읽고-참거짓을-판단하여라.",
    "href": "posts/III. CNN/2022-10-26-Assignment3.html#다음을-읽고-참거짓을-판단하여라.",
    "title": "Assignment 3",
    "section": "2. 다음을 읽고 참거짓을 판단하여라.",
    "text": "2. 다음을 읽고 참거짓을 판단하여라.\n(1) 아래의 레이어에 의하여 수행되는 변환은 선형변환이다.\ntorch.nn.Conv2d(3,16,(5,5))"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "",
    "text": "Minor topics in CNN– 다중클래스분류 (BCELoss vs CELoss), fastai metric 사용"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#결론-그냥-외우세요",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#결론-그냥-외우세요",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "결론 (그냥 외우세요)",
    "text": "결론 (그냥 외우세요)\n- 2개의 class를 구분하는 문제가 아니라 \\(k\\)개의 class를 구분해야 한다면?\n일반적인 개념\n\n손실함수: BCE loss \\(\\to\\) Cross Entropy loss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: sig \\(\\to\\) softmax\n\n파이토치 한정\n\ny의형태: (n,) vector + int형 // (n,k) one-hot encoded vector + float형\n손실함수: torch.nn.BCEWithLogitsLoss, \\(\\to\\) torch.nn.CrossEntropyLoss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: None \\(\\to\\) None (손실함수에 이미 마지막층의 활성화가 포함)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#실습-3개의-클래스를-구분",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#실습-3개의-클래스를-구분",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "실습: 3개의 클래스를 구분",
    "text": "실습: 3개의 클래스를 구분\n\npath = untar_data(URLs.MNIST)\n\ntraining set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\ntest set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n(1) dls\n\nlen(X)\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번 iter\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr\n\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\n\nnet1(X).shape\n\ntorch.Size([18623, 2304])\n\n\n\nnet = torch.nn.Sequential(\n    net1,\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\nloss_fn = torch.nn.CrossEntropyLoss() \n\n\nlrnr = Learner(dls,net,loss_fn) \n\n(3) 학습\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.155762\n      0.045966\n      00:00\n    \n    \n      1\n      0.087853\n      0.093116\n      00:00\n    \n    \n      2\n      0.089215\n      0.033146\n      00:00\n    \n    \n      3\n      0.075707\n      0.039687\n      00:00\n    \n    \n      4\n      0.063615\n      0.031188\n      00:00\n    \n    \n      5\n      0.055850\n      0.029167\n      00:00\n    \n    \n      6\n      0.050883\n      0.028610\n      00:00\n    \n    \n      7\n      0.047144\n      0.028127\n      00:00\n    \n    \n      8\n      0.044129\n      0.027425\n      00:00\n    \n    \n      9\n      0.041849\n      0.026887\n      00:00\n    \n  \n\n\n\n(4) 예측\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n    (3): Flatten(start_dim=1, end_dim=-1)\n  )\n  (1): Linear(in_features=2304, out_features=3, bias=True)\n)\n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      y\n    \n  \n  \n    \n      0\n      2.025615\n      -17.453382\n      -2.335629\n      0\n    \n    \n      1\n      2.531184\n      -9.890347\n      -3.949971\n      0\n    \n    \n      2\n      1.587324\n      -13.035635\n      -3.257438\n      0\n    \n    \n      3\n      2.749664\n      -9.918694\n      -6.867003\n      0\n    \n    \n      4\n      2.155442\n      -15.885134\n      -3.019295\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3142\n      -9.030737\n      -8.673495\n      1.204605\n      2\n    \n    \n      3143\n      -3.569304\n      -10.748278\n      -0.645055\n      2\n    \n    \n      3144\n      -3.627095\n      -12.919289\n      1.046083\n      2\n    \n    \n      3145\n      -5.151307\n      -9.524368\n      0.068864\n      2\n    \n    \n      3146\n      -8.014889\n      -14.518770\n      2.732226\n      2\n    \n  \n\n3147 rows × 4 columns\n\n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      y\n    \n  \n  \n    \n      0\n      2.025615\n      -17.453382\n      -2.335629\n      0\n    \n    \n      1\n      2.531184\n      -9.890347\n      -3.949971\n      0\n    \n    \n      2\n      1.587324\n      -13.035635\n      -3.257438\n      0\n    \n    \n      3\n      2.749664\n      -9.918694\n      -6.867003\n      0\n    \n    \n      4\n      2.155442\n      -15.885134\n      -3.019295\n      0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      975\n      4.450414\n      -19.329332\n      -5.451057\n      0\n    \n    \n      976\n      2.597144\n      -21.202513\n      -2.372313\n      0\n    \n    \n      977\n      3.089397\n      -15.486772\n      -3.171502\n      0\n    \n    \n      978\n      2.591355\n      -17.475590\n      -3.039083\n      0\n    \n    \n      979\n      4.575789\n      -21.636261\n      -5.077421\n      0\n    \n  \n\n980 rows × 4 columns\n\n\n\n\n대체적으로 첫번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==1')\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      y\n    \n  \n  \n    \n      980\n      -7.629252\n      2.701625\n      -3.049654\n      1\n    \n    \n      981\n      -6.666027\n      2.027717\n      -4.440878\n      1\n    \n    \n      982\n      -7.120140\n      3.354897\n      -3.937105\n      1\n    \n    \n      983\n      -7.139010\n      2.058928\n      -2.954304\n      1\n    \n    \n      984\n      -6.999043\n      3.258377\n      -3.432081\n      1\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2110\n      -7.406105\n      4.032059\n      -3.826451\n      1\n    \n    \n      2111\n      -6.172441\n      3.187883\n      -3.490717\n      1\n    \n    \n      2112\n      -7.035848\n      3.202726\n      -3.547020\n      1\n    \n    \n      2113\n      -7.149322\n      1.741414\n      -1.765136\n      1\n    \n    \n      2114\n      -5.775263\n      3.041395\n      -2.980052\n      1\n    \n  \n\n1135 rows × 4 columns\n\n\n\n\n대체적으로 두번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==2')\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      y\n    \n  \n  \n    \n      2115\n      -7.452892\n      -7.137640\n      0.605079\n      2\n    \n    \n      2116\n      -5.262731\n      -7.798437\n      -1.708323\n      2\n    \n    \n      2117\n      -9.056837\n      -9.649239\n      1.557607\n      2\n    \n    \n      2118\n      -6.614496\n      -10.291727\n      1.293422\n      2\n    \n    \n      2119\n      -3.120885\n      -10.670292\n      -0.660188\n      2\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      3142\n      -9.030737\n      -8.673495\n      1.204605\n      2\n    \n    \n      3143\n      -3.569304\n      -10.748278\n      -0.645055\n      2\n    \n    \n      3144\n      -3.627095\n      -12.919289\n      1.046083\n      2\n    \n    \n      3145\n      -5.151307\n      -9.524368\n      0.068864\n      2\n    \n    \n      3146\n      -8.014889\n      -14.518770\n      2.732226\n      2\n    \n  \n\n1032 rows × 4 columns\n\n\n\n\n대체적으로 세번째 칼럼의 숫자들이 다른칼럼보다 크다.\n\n- 예측하는방법?\n\n칼럼0의 숫자가 크다 -> y=0일 확률이 큼\n칼럼1의 숫자가 크다 -> y=1일 확률이 큼\n칼럼2의 숫자가 크다 -> y=2일 확률이 큼"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#공부-softmax",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#공부-softmax",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "공부: Softmax",
    "text": "공부: Softmax\n- 눈치: softmax를 쓰기 직전의 숫자들은 (n,k)꼴로 되어있음. 각 observation 마다 k개의 숫자가 있는데, 그중에서 유난히 큰 하나의 숫자가 있음.\n- torch.nn.Softmax() 손계산\n(예시1) – 잘못계산\n\nsftmax = torch.nn.Softmax(dim=0)\n\n\n_netout = torch.tensor([[-2.0,-2.0,0.0],\n                        [3.14,3.14,3.14],\n                        [0.0,0.0,2.0],\n                        [2.0,2.0,4.0],\n                        [0.0,0.0,0.0]])\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout) \n\ntensor([[0.0041, 0.0041, 0.0115],\n        [0.7081, 0.7081, 0.2653],\n        [0.0306, 0.0306, 0.0848],\n        [0.2265, 0.2265, 0.6269],\n        [0.0306, 0.0306, 0.0115]])\n\n\n(예시2) – 이게 맞게 계산되는 것임\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout)\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시3) – 차원을 명시안하면 맞게 계산해주고 경고 줌\n\nsftmax = torch.nn.Softmax()\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsftmax(_netout)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  \"\"\"Entry point for launching an IPython kernel.\n\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시4) – 진짜 손계산\n\n_netout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\ntorch.exp(_netout)\n\ntensor([[ 0.1353,  0.1353,  1.0000],\n        [23.1039, 23.1039, 23.1039],\n        [ 1.0000,  1.0000,  7.3891],\n        [ 7.3891,  7.3891, 54.5981],\n        [ 1.0000,  1.0000,  1.0000]])\n\n\n\n0.1353/(0.1353 + 0.1353 + 1.0000), 0.1353/(0.1353 + 0.1353 + 1.0000), 1.0000/(0.1353 + 0.1353 + 1.0000) # 첫 obs\n\n(0.10648512513773022, 0.10648512513773022, 0.7870297497245397)\n\n\n\nnp.exp(_netout[1])/np.exp(_netout[1]).sum() # 두번째 obs \n\ntensor([0.3333, 0.3333, 0.3333])\n\n\n\nnp.apply_along_axis(lambda x: np.exp(x) / np.exp(x).sum(),1,_netout)\n\narray([[0.10650698, 0.10650698, 0.78698605],\n       [0.33333334, 0.33333334, 0.33333334],\n       [0.10650699, 0.10650699, 0.78698605],\n       [0.10650698, 0.10650698, 0.78698605],\n       [0.33333334, 0.33333334, 0.33333334]], dtype=float32)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#공부-crossentropyloss",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#공부-crossentropyloss",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "공부: CrossEntropyLoss",
    "text": "공부: CrossEntropyLoss\n\n# torch.nn.CrossEntropyLoss() 손계산: one-hot version\n\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n_netout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\n_y_onehot = torch.tensor([[0,0,1],\n                          [0,1,0],\n                          [0,0,1],\n                          [0,0,1],\n                          [1,0,0]])*1.0\n_y_onehot\n\ntensor([[0., 0., 1.],\n        [0., 1., 0.],\n        [0., 0., 1.],\n        [0., 0., 1.],\n        [1., 0., 0.]])\n\n\n\nsftmax = torch.nn.Softmax(dim=1) \nsftmax(_netout), _y_onehot\n\n(tensor([[0.1065, 0.1065, 0.7870],\n         [0.3333, 0.3333, 0.3333],\n         [0.1065, 0.1065, 0.7870],\n         [0.1065, 0.1065, 0.7870],\n         [0.3333, 0.3333, 0.3333]]),\n tensor([[0., 0., 1.],\n         [0., 1., 0.],\n         [0., 0., 1.],\n         [0., 0., 1.],\n         [1., 0., 0.]]))\n\n\n- 계산결과\n\nloss_fn(_netout,_y_onehot)\n\ntensor(0.5832)\n\n\n\n- torch.sum(torch.log(sftmax(_netout)) * _y_onehot)/5 \n\ntensor(0.5832)\n\n\n- 계산하는 방법도 중요한데 torch.nn.CrossEntropyLoss() 에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 더 중요함.\n- 따라서 torch.nn.CrossEntropyLoss() 는 사실 torch.nn.CEWithSoftmaxLoss() 정도로 바꾸는 것이 더 말이 되는 것 같다.\n\n\n# torch.nn.CrossEntropyLoss() 손계산: lenght \\(n\\) vertor version\n\n_netout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\n_y = torch.tensor([2,1,2,2,0])\n\n\nloss_fn(_netout,_y)\n\ntensor(0.5832)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#실습-k2로-두면-이진분류도-가능",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#실습-k2로-두면-이진분류도-가능",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "실습: \\(k=2\\)로 두면 이진분류도 가능",
    "text": "실습: \\(k=2\\)로 두면 이진분류도 가능\n- download data\n\npath = untar_data(URLs.MNIST) \n\ntraining\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\n\ny_onehot = torch.nn.functional.one_hot(y).float()\n#y_onehot = torch.tensor(list(map(lambda x: [1,0] if x==0 else [0,1],y))).float()\n\ntest\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\n\nyy_onehot = torch.nn.functional.one_hot(yy).float()\n#yy_onehot = torch.tensor(list(map(lambda x: [1,0] if x==0 else [0,1],yy))).float()\n\n(1) dls\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot) \nds2 = torch.utils.data.TensorDataset(XX,yy_onehot) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번 iter\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n(3) 학습\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.018623\n      0.012110\n      00:00\n    \n    \n      1\n      0.017453\n      0.010544\n      00:00\n    \n    \n      2\n      0.016391\n      0.009324\n      00:00\n    \n    \n      3\n      0.015412\n      0.008343\n      00:00\n    \n    \n      4\n      0.014506\n      0.007542\n      00:00\n    \n    \n      5\n      0.013664\n      0.006874\n      00:00\n    \n    \n      6\n      0.012881\n      0.006318\n      00:00\n    \n    \n      7\n      0.012152\n      0.005849\n      00:00\n    \n    \n      8\n      0.011473\n      0.005448\n      00:00\n    \n    \n      9\n      0.010841\n      0.005103\n      00:00\n    \n  \n\n\n\n(4) 예측 및 시각화\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=2, bias=True)\n)\n\n\n\nsftmax = torch.nn.Softmax(dim=1) \nsig = torch.nn.Sigmoid()\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).diff(axis=1).data,',',color=\"C1\")\nax[1].plot(y)\nax[1].plot(sftmax(net(X))[:,1].data,',')\n#ax[1].plot(sig(net(X).diff(axis=1)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).diff(axis=1).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(sftmax(net(XX))[:,1].data,',')\n#ax[1].plot(sig(net(XX).diff(axis=1)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')\n\n\n\n\n\n- note: softmax(u1,u2)=[sig(u1-u2), sig(u2-u1)]=[1-sig(u2-u1),sig(u2-u1)]"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#공부-이진분류에서-소프트맥스-vs-시그모이드",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#공부-이진분류에서-소프트맥스-vs-시그모이드",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "공부: 이진분류에서 소프트맥스 vs 시그모이드",
    "text": "공부: 이진분류에서 소프트맥스 vs 시그모이드\n- 이진분류문제 = “y=0 or y=1” 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제\n- softmax, sigmoid\n\nsoftmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다.\nsigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다.\n\n- 그런데 “실패확률=1-성공확률” 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까)\n- 아래는 사실상 같은 모형이다.\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"?\"\n    \"??\"\n    \"..\"\n    \"???\"\n    label = \"Layer ?\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"?\" -> \"node1\"\n    \"??\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \"???\" -> \"node1\"\n    \n    \"?\" -> \"node2\"\n    \"??\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"???\" -> \"node2\"\n    \n    \"?\" -> \"...\"\n    \"??\" -> \"...\"\n    \"..\" -> \"...\"\n    \"???\" -> \"...\"\n    \n    \"?\" -> \"node2304\"\n    \"??\" -> \"node2304\"\n    \"..\" -> \"node2304\"\n    \"???\" -> \"node2304\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"y1\"\n    \"node2\" -> \"y1\"\n    \"...\" -> \"y1\"\n    \"node2304\" -> \"y1\"\n    \n    \"node1\" -> \"y2\"\n    \"node2\" -> \"y2\"\n    \"...\" -> \"y2\"\n    \"node2304\" -> \"y2\"    \n    label = \"Layer: Softmax\"\n}\n''')\n\n\n\n\n\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"?\"\n    \"??\"\n    \"..\"\n    \"???\"\n    label = \"Layer ?\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"?\" -> \"node1\"\n    \"??\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \"???\" -> \"node1\"\n    \n    \"?\" -> \"node2\"\n    \"??\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"???\" -> \"node2\"\n    \n    \"?\" -> \"...\"\n    \"??\" -> \"...\"\n    \"..\" -> \"...\"\n    \"???\" -> \"...\"\n    \n    \"?\" -> \"node2304\"\n    \"??\" -> \"node2304\"\n    \"..\" -> \"node2304\"\n    \"???\" -> \"node2304\"\n\n    label = \"Layer: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"y\"\n    \"node2\" -> \"y\"\n    \"...\" -> \"y\"\n    \"node2304\" -> \"y\"\n    label = \"Layer: Sigmoid\"\n}\n''')\n\n\n\n\n\n- 둘은 사실상 같은 효과를 주는 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. \\(\\to\\) sigmoid를 사용하는 모형이 비용은 싸고 효과는 동일하다는 말 \\(\\to\\) 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함.\n\nsoftmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#소프트맥스-vs-시그모이드-정리",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#소프트맥스-vs-시그모이드-정리",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "소프트맥스 vs 시그모이드 정리",
    "text": "소프트맥스 vs 시그모이드 정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (흑백이미지를 칼라잉크로 출력하는 느낌)\n참고\n\n\n\n\\(y\\)\n분포가정\n마지막층의 활성화함수\n손실함수\n\n\n\n\n3.45, 4.43, … (연속형)\n정규분포\nNone (or Identity)\nMSE\n\n\n0 or 1\n이항분포 with \\(n=1\\) (=베르누이)\nSigmoid\nBCE\n\n\n[0,0,1], [0,1,0], [1,0,0]\n다항분포 with \\(n=1\\)\nSoftmax\nCross Entropy"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#데이터준비",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#데이터준비",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "데이터준비",
    "text": "데이터준비\n- download data\n\npath = untar_data(URLs.MNIST)\n\n- training set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n- test set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1]))"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#사용자정의-메트릭이용",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#사용자정의-메트릭이용",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "사용자정의 메트릭이용",
    "text": "사용자정의 메트릭이용\n(1) dls 만들기\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr 생성\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \n\n\ndef acc(yhat,y) : \n    return ((yhat>0.5)==y).float().mean()\n\n\ndef err(yhat,y):\n    return 1-((yhat>0.5)==y).float().mean()\n\n\nlrnr = Learner(dls,net,loss_fn,metrics=[acc,err])\n\n(3) 학습\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      acc\n      err\n      time\n    \n  \n  \n    \n      0\n      0.930635\n      0.633062\n      0.463357\n      0.536643\n      00:00\n    \n    \n      1\n      0.700525\n      0.435254\n      0.989125\n      0.010875\n      00:00\n    \n    \n      2\n      0.562099\n      0.293302\n      0.992435\n      0.007565\n      00:00\n    \n    \n      3\n      0.453646\n      0.169834\n      0.992908\n      0.007092\n      00:00\n    \n    \n      4\n      0.360984\n      0.098153\n      0.994326\n      0.005674\n      00:00\n    \n    \n      5\n      0.286862\n      0.062732\n      0.993853\n      0.006147\n      00:00\n    \n    \n      6\n      0.229778\n      0.044261\n      0.994799\n      0.005201\n      00:00\n    \n    \n      7\n      0.185838\n      0.032975\n      0.995745\n      0.004255\n      00:00\n    \n    \n      8\n      0.151484\n      0.025062\n      0.996217\n      0.003783\n      00:00\n    \n    \n      9\n      0.124157\n      0.019350\n      0.996690\n      0.003310\n      00:00\n    \n  \n\n\n\n(4) 예측\n\n생략"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-잘못된사용",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-잘못된사용",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "fastai지원 메트릭이용– 잘못된사용",
    "text": "fastai지원 메트릭이용– 잘못된사용\n(1) dls 만들기\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr 생성\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\naccuracy??\n\n\nSignature: accuracy(inp, targ, axis=-1)\nSource:   \ndef accuracy(inp, targ, axis=-1):\n    \"Compute accuracy with `targ` when `pred` is bs * n_classes\"\n    pred,targ = flatten_check(inp.argmax(dim=axis), targ)\n    return (pred == targ).float().mean()\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/metrics.py\nType:      function\n\n\n\n\n\nerror_rate??\n\n\nSignature: error_rate(inp, targ, axis=-1)\nSource:   \ndef error_rate(inp, targ, axis=-1):\n    \"1 - `accuracy`\"\n    return 1 - accuracy(inp, targ, axis=axis)\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/metrics.py\nType:      function\n\n\n\n\n(3) 학습\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.958819\n      0.638672\n      0.463357\n      0.536643\n      00:00\n    \n    \n      1\n      0.698769\n      0.425380\n      0.463357\n      0.536643\n      00:00\n    \n    \n      2\n      0.556408\n      0.278437\n      0.463357\n      0.536643\n      00:00\n    \n    \n      3\n      0.447104\n      0.153257\n      0.463357\n      0.536643\n      00:00\n    \n    \n      4\n      0.352915\n      0.088516\n      0.463357\n      0.536643\n      00:00\n    \n    \n      5\n      0.278620\n      0.056958\n      0.463357\n      0.536643\n      00:00\n    \n    \n      6\n      0.221951\n      0.040489\n      0.463357\n      0.536643\n      00:00\n    \n    \n      7\n      0.178791\n      0.030974\n      0.463357\n      0.536643\n      00:00\n    \n    \n      8\n      0.145480\n      0.024886\n      0.463357\n      0.536643\n      00:00\n    \n    \n      9\n      0.119392\n      0.020659\n      0.463357\n      0.536643\n      00:00\n    \n  \n\n\n\n\n이상하다..?\n\n(4) 예측\n\nlrnr.model.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nplt.plot(yy)\nplt.plot(lrnr.model(XX).data,'.')\n\n\n\n\n\n맞추는건 잘 맞추는데?"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-올바른-사용1",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-올바른-사용1",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "fastai지원 메트릭이용– 올바른 사용(1)",
    "text": "fastai지원 메트릭이용– 올바른 사용(1)\n- 가정\n\nX의 형태는 (n,채널,픽셀,픽셀)로 가정한다.\ny의 형태는 (n,) 벡터이다. 즉 \\(n\\times 1\\) 이 아니라 그냥 길이가 \\(n\\)인 벡터로 가정한다.\ny의 각 원소는 0,1,2,3,… 와 같이 카테고리를 의미하는 숫자이어야 하며 이 숫자는 int형으로 저장되어야 한다.\nloss function은 CrossEntropyLoss()를 쓴다고 가정한다. (따라서 네트워크의 최종레이어는 torch.nn.Linear(?,클래스의수) 꼴이 되어야 한다.)\n\n(1) dls 만들기\n\ny.to(torch.int64).reshape(-1),yy.to(torch.int64).reshape(-1)\n\n(tensor([0, 0, 0,  ..., 1, 1, 1]), tensor([0, 0, 0,  ..., 1, 1, 1]))\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr 생성\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n(3) 학습\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.083689\n      0.592268\n      0.463357\n      0.536643\n      00:00\n    \n    \n      1\n      0.674220\n      0.340684\n      0.963593\n      0.036407\n      00:00\n    \n    \n      2\n      0.510727\n      0.152380\n      0.991489\n      0.008511\n      00:00\n    \n    \n      3\n      0.380071\n      0.069530\n      0.997163\n      0.002837\n      00:00\n    \n    \n      4\n      0.284898\n      0.038776\n      0.997163\n      0.002837\n      00:00\n    \n    \n      5\n      0.217856\n      0.025257\n      0.997163\n      0.002837\n      00:00\n    \n    \n      6\n      0.169902\n      0.018588\n      0.997163\n      0.002837\n      00:00\n    \n    \n      7\n      0.134621\n      0.014637\n      0.998582\n      0.001418\n      00:00\n    \n    \n      8\n      0.107967\n      0.012024\n      0.998582\n      0.001418\n      00:00\n    \n    \n      9\n      0.087427\n      0.010147\n      0.998582\n      0.001418\n      00:00"
  },
  {
    "objectID": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-올바른-사용2",
    "href": "posts/III. CNN/2022-10-20-8wk-1.html#fastai지원-메트릭이용-올바른-사용2",
    "title": "08wk-1: 이미지분석 (2)",
    "section": "fastai지원 메트릭이용– 올바른 사용(2)",
    "text": "fastai지원 메트릭이용– 올바른 사용(2)\n- 가정\n\nX의 형태는 (n,채널,픽셀,픽셀)로 가정한다.\ny의 형태는 (n,클래스의수)로 가정한다. 즉 y가 one_hot 인코딩된 형태로 가정한다.\ny의 각 원소는 0 혹은 1이다.\nloss function은 CrossEntropyLoss()를 쓴다고 가정한다. (따라서 네트워크의 최종레이어는 torch.nn.Linear(?,클래스의수) 꼴이 되어야 한다.)\n\n(1) dls 만들기\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n# y_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\n# yy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n(2) lrnr 생성\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\n(3) 학습\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      1.073728\n      0.608127\n      0.463357\n      00:00\n    \n    \n      1\n      0.683059\n      0.328684\n      0.982979\n      00:00\n    \n    \n      2\n      0.508058\n      0.156030\n      0.990780\n      00:00\n    \n    \n      3\n      0.378242\n      0.071232\n      0.995272\n      00:00\n    \n    \n      4\n      0.284064\n      0.041114\n      0.995981\n      00:00\n    \n    \n      5\n      0.217714\n      0.027780\n      0.996217\n      00:00\n    \n    \n      6\n      0.170183\n      0.021023\n      0.995981\n      00:00\n    \n    \n      7\n      0.135240\n      0.016962\n      0.996927\n      00:00\n    \n    \n      8\n      0.108881\n      0.014204\n      0.997400\n      00:00\n    \n    \n      9\n      0.088585\n      0.012181\n      0.997872\n      00:00"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "",
    "text": "CNN– CNN 예비학습, CNN 구현 (CPU), CNN 구현 (GPU), BCEWithLogisticLoss"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#기존의-mlp-모형",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#기존의-mlp-모형",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "기존의 MLP 모형",
    "text": "기존의 MLP 모형\n- 교재의 모형\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n    \n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node30\"\n    \"x2\" -> \"node30\"\n    \"..\" -> \"node30\"\n    \"x784\" -> \"node30\"\n\n\n    label = \"Layer 1: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"y\"\n    \"node2\" -> \"y\"\n    \"...\" -> \"y\"\n    \"node30\" -> \"y\"\n    label = \"Layer 2: Sigmoid\"\n}\n''')\n\n\n\n\n\n- 왜 28 \\(\\times\\) 28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다."
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#새로운-아키텍처의-제시",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#새로운-아키텍처의-제시",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "새로운 아키텍처의 제시",
    "text": "새로운 아키텍처의 제시\n- 예전\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\\(l_1\\): 선형변환, feature를 뻥튀기하는 역할\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처\n\n\\(conv\\): feature를 뻥튀기하는 역할 (2d ver \\(l_1\\) 느낌)\n\\(relu\\):\n\\(pooling\\): 데이터를 요약하는 역할\n\n\nCONV 레이어 (선형변환의 2D 버전)\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,2,2).float()\n_X\n\ntensor([[[0., 1.],\n         [2., 3.]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\n_conv(_X)\n\ntensor([[[1.5410]]], grad_fn=<SqueezeBackward1>)\n\n\n(예시2) 잘하면 평균도 계산하겠다?\n\n_conv.weight.data = torch.tensor([[[[1/4, 1/4],[1/4,1/4]]]])\n_conv.bias.data = torch.tensor([0.0])\n\n\n_conv(_X) , (0+1+2+3)/4\n\n(tensor([[[1.5000]]], grad_fn=<SqueezeBackward1>), 1.5)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(0,25).float().reshape(1,5,5) \n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=<SqueezeBackward1>)\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_conv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n\n_X,_conv(_X)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.0000,  7.0000,  8.0000],\n          [11.0000, 12.0000, 13.0000],\n          [16.0000, 17.0000, 18.0000]]], grad_fn=<SqueezeBackward1>))\n\n\n\n(1+2+3+6+7+8+11+12+13)/9\n\n7.0\n\n\n(예시5) 피처뻥튀기\n\n_X = torch.tensor([1.0,1.0,1.0,1.0]).reshape(1,2,2)\n_X\n\ntensor([[[1., 1.],\n         [1., 1.]]])\n\n\n\n_conv = torch.nn.Conv2d(1,8,(2,2))\n_conv.weight.data.shape,_conv.bias.data.shape\n\n(torch.Size([8, 1, 2, 2]), torch.Size([8]))\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=<ReshapeAliasBackward0>)\n\n\n\ntorch.sum(_conv.weight.data[0,...])+_conv.bias.data[0],\\\ntorch.sum(_conv.weight.data[1,...])+_conv.bias.data[1]\n\n(tensor(-0.3464), tensor(0.2739))\n\n\n결국 아래를 계산한다는 의미\n\ntorch.sum(_conv.weight.data,axis=(2,3)).reshape(-1)+ _conv.bias.data\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345])\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=<ReshapeAliasBackward0>)\n\n\n(잔소리) axis 사용 익숙하지 않으면 아래 꼭 들으세요..\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6주차)-4월11일.html , numpy공부 4단계: 축"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#relu-2d",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#relu-2d",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "ReLU (2d)",
    "text": "ReLU (2d)\n\n_X = torch.randn(25).reshape(1,5,5)\n_X\n\ntensor([[[ 0.2656,  0.0780,  3.0465,  1.0151, -2.3908],\n         [ 0.4749,  1.6519,  1.5454,  1.0376,  0.9291],\n         [-0.7858,  0.4190,  2.6057, -0.4022,  0.2092],\n         [ 0.9594,  0.6408, -0.0411, -1.0720, -2.0659],\n         [-0.0996,  1.1351,  0.9758,  0.4952, -0.5475]]])\n\n\n\na1=torch.nn.ReLU()\n\n\na1(_X)\n\ntensor([[[0.2656, 0.0780, 3.0465, 1.0151, 0.0000],\n         [0.4749, 1.6519, 1.5454, 1.0376, 0.9291],\n         [0.0000, 0.4190, 2.6057, 0.0000, 0.2092],\n         [0.9594, 0.6408, 0.0000, 0.0000, 0.0000],\n         [0.0000, 1.1351, 0.9758, 0.4952, 0.0000]]])"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#maxpooling-레이어",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#maxpooling-레이어",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "Maxpooling 레이어",
    "text": "Maxpooling 레이어\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n\n\n_X = torch.arange(16).float().reshape(1,4,4) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]),\n tensor([[[ 5.,  7.],\n          [13., 15.]]]))\n\n\n\n_X = torch.arange(25).float().reshape(1,5,5) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.,  8.],\n          [16., 18.]]]))\n\n\n\n_X = torch.arange(36).float().reshape(1,6,6) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.],\n          [24., 25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34., 35.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.],\n          [31., 33., 35.]]]))"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#conv2d",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#conv2d",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "(1) Conv2d",
    "text": "(1) Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5))\nprint(X.shape)\nprint(c1(X).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#relu",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#relu",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "(2) ReLU",
    "text": "(2) ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#maxpool2d",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#maxpool2d",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "(3) MaxPool2D",
    "text": "(3) MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#적당히-마무리하고-시그모이드-태우자",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#적당히-마무리하고-시그모이드-태우자",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "(4) 적당히 마무리하고 시그모이드 태우자",
    "text": "(4) 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,2304).shape\n\ntorch.Size([12665, 2304])\n\n\n\n16*12*12 \n\n2304\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a1(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])\n\n\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d->1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nt1= time.time()\nfor epoc in range(100): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2= time.time()\nt2-t1\n\n51.493837118148804\n\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#dls",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#dls",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "1. dls",
    "text": "1. dls\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\nlen(X)/10\n\n1266.5\n\n\n\nlen(XX)\n\n2115\n\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#lrnr-생성-아키텍처-손실함수-옵티마이저",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#lrnr-생성-아키텍처-손실함수-옵티마이저",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "2. lrnr 생성: 아키텍처, 손실함수, 옵티마이저",
    "text": "2. lrnr 생성: 아키텍처, 손실함수, 옵티마이저\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#학습",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#학습",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "3. 학습",
    "text": "3. 학습\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.904232\n      0.605049\n      00:01\n    \n    \n      1\n      0.661176\n      0.371011\n      00:00\n    \n    \n      2\n      0.507179\n      0.213586\n      00:00\n    \n    \n      3\n      0.392649\n      0.113123\n      00:00\n    \n    \n      4\n      0.304377\n      0.065496\n      00:00\n    \n    \n      5\n      0.238253\n      0.043172\n      00:00\n    \n    \n      6\n      0.188984\n      0.031475\n      00:00\n    \n    \n      7\n      0.151837\n      0.024563\n      00:00\n    \n    \n      8\n      0.123364\n      0.020047\n      00:00\n    \n    \n      9\n      0.101180\n      0.016816\n      00:00"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#예측-및-시각화",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#예측-및-시각화",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "4. 예측 및 시각화",
    "text": "4. 예측 및 시각화\n\nnet.to(\"cpu\") \n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n- 결과를 시각화하면 아래와 같다.\n\nplt.plot(net(X).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(XX).data,'.')\nplt.title(\"Test Set\",size=15)\n\nText(0.5, 1.0, 'Test Set')\n\n\n\n\n\n- 빠르고 적합결과도 좋음"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#lrnr-오브젝트",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#lrnr-오브젝트",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "Lrnr 오브젝트",
    "text": "Lrnr 오브젝트\n\nlrnr.model\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nnet\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nid(lrnr.model), id(net)\n\n(140681387850000, 140681387850000)\n\n\n\nlrnr.model(X)\n\ntensor([[5.4047e-03],\n        [5.1475e-04],\n        [9.8561e-04],\n        ...,\n        [9.9602e-01],\n        [9.9584e-01],\n        [9.9655e-01]], grad_fn=<SigmoidBackward0>)"
  },
  {
    "objectID": "posts/III. CNN/2022-10-18-7wk-2.html#bcewithlogitsloss",
    "href": "posts/III. CNN/2022-10-18-7wk-2.html#bcewithlogitsloss",
    "title": "07wk-2: 이미지분석 (1)",
    "section": "BCEWithLogitsLoss",
    "text": "BCEWithLogitsLoss\n- BCEWithLogitsLoss = Sigmoid + BCELoss - 왜 써요? 수치적으로 더 안정\n- 사용방법\n\ndls 만들기\n\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\nlrnr생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    #torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.896794\n      0.560268\n      00:00\n    \n    \n      1\n      0.613384\n      0.301413\n      00:00\n    \n    \n      2\n      0.454223\n      0.169741\n      00:00\n    \n    \n      3\n      0.346758\n      0.092166\n      00:00\n    \n    \n      4\n      0.268065\n      0.056573\n      00:00\n    \n    \n      5\n      0.210524\n      0.039757\n      00:00\n    \n    \n      6\n      0.167973\n      0.030431\n      00:00\n    \n    \n      7\n      0.135910\n      0.024560\n      00:00\n    \n    \n      8\n      0.111290\n      0.020503\n      00:00\n    \n    \n      9\n      0.092058\n      0.017516\n      00:00\n    \n  \n\n\n\n\n예측 및 시각화\n\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n)\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).data,',',color=\"C1\")\nax[1].plot(y)\nax[1].plot(a2(net(X)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(a2(net(XX)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')"
  },
  {
    "objectID": "posts/2022-10-28-9wk-1-midsol.html",
    "href": "posts/2022-10-28-9wk-1-midsol.html",
    "title": "mid",
    "section": "",
    "text": "중간고사"
  },
  {
    "objectID": "posts/2022-10-28-9wk-1-midsol.html#크롤링을-통한-이미지-분석-및-cam.-50점-풀이생략",
    "href": "posts/2022-10-28-9wk-1-midsol.html#크롤링을-통한-이미지-분석-및-cam.-50점-풀이생략",
    "title": "mid",
    "section": "1. 크롤링을 통한 이미지 분석 및 CAM. (50점) – 풀이생략",
    "text": "1. 크롤링을 통한 이미지 분석 및 CAM. (50점) – 풀이생략\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. - 키워드는 {‘iu’,‘hynn’}을 제외하고 본인이 선택할 것)\n(2) ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라.\n(3) resnet34를 이용하여 학습하라.\n(4) CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라."
  },
  {
    "objectID": "posts/2022-10-28-9wk-1-midsol.html#다음을-읽고-물음에-답하라.-30점",
    "href": "posts/2022-10-28-9wk-1-midsol.html#다음을-읽고-물음에-답하라.-30점",
    "title": "mid",
    "section": "2. 다음을 읽고 물음에 답하라. (30점)",
    "text": "2. 다음을 읽고 물음에 답하라. (30점)\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(7676)\nx = torch.randn(100).sort().values\nϵ = torch.randn(100)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n아래와 같은 모형을 가정하고 물음에 답하라.\n\\[y_i = w_0+w_1 x_i +\\epsilon_i, \\quad \\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)\\]\n(1) ??를 적당하게 채워 아래와 같은 네트워크를 설정하고 최초의 예측값이 \\(\\hat{y}_i=-5+10x_i\\)가 출력되도록 net의 가중치를 조정하라.\nnet = torch.nn.Linear(in_features=2,out_features=??,bias=??)\n(풀이)\n\nX = torch.stack([torch.ones_like(x), x],axis=1) \ny = y.reshape(-1,1)\n\n\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=False)\n\n\nnet.weight.data = torch.tensor([[ -5.0, 10.0]]) \n\n(2) 학습률은 0.1로 설정하고 torch.optim.Adam을 이용하여 optimizer를 선언하라. \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)에서 MSELoss의 미분계수 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1) ~\\Big|_{~\\hat{w}_0,\\hat{w}_1}\\)를 구하고 이를 바탕으로 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 1회 갱신하라. 계산된 미분계수값과 갱신된 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 출력하라.\n(풀이)\n\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n\n\nfor epoc in range(1):\n    ## step1\n    yhat = net(X)\n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    print(net.weight.grad)\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n    print(net.weight.data)\n    print(\"---\")\n\ntensor([[-15.7290,  14.7198]])\ntensor([[-4.9000,  9.9000]])\n---\n\n\n(3) (2)에서 설정한 optimizer를 이용하여 \\((\\hat{w}_0,\\hat{w}_1)\\)의 값을 5회 갱신한 값을 구하여라. - 문제(2)에 갱신한 1회를 포함하여 5회임.\n(풀이)\n\nfor epoc in range(4):\n    ## step1 \n    yhat = net(X) \n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    print(net.weight.grad)\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    print(net.weight.data)\n    print(\"---\")\n\ntensor([[-15.5179,  14.4789]])\ntensor([[-4.8000,  9.8000]])\n---\ntensor([[-15.3068,  14.2382]])\ntensor([[-4.7001,  9.7002]])\n---\ntensor([[-15.0960,  13.9976]])\ntensor([[-4.6003,  9.6004]])\n---\ntensor([[-14.8852,  13.7572]])\ntensor([[-4.5006,  9.5008]])\n---\n\n\n(4) 학습률을 0.2로 설정하고 torch.optim.SGD를 이용하여 새로운 optimizr를 선언하라. (3)의 결과로 총 5회 갱신된 값에 이어서 10회 추가로 학습하라. 학습된 값은 얼마인가?\n(풀이)\n\noptimizr2= torch.optim.SGD(net.parameters(),lr=0.2) \n\n\nfor epoc in range(10):\n    ## step1 \n    yhat = net(X) \n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    print(net.weight.grad)\n    ## step4\n    optimizr2.step()\n    optimizr2.zero_grad()\n    print(net.weight.data)\n    print(\"---\")\n\ntensor([[-14.6748,  13.5172]])\ntensor([[-1.5657,  6.7973]])\n---\ntensor([[-8.5044,  6.9790]])\ntensor([[0.1352, 5.4015]])\n---\ntensor([[-4.9476,  3.5827]])\ntensor([[1.1247, 4.6850]])\n---\ntensor([[-2.8889,  1.8262]])\ntensor([[1.7025, 4.3198]])\n---\ntensor([[-1.6928,  0.9227]])\ntensor([[2.0411, 4.1352]])\n---\ntensor([[-0.9951,  0.4611]])\ntensor([[2.2401, 4.0430]])\n---\ntensor([[-0.5868,  0.2271]])\ntensor([[2.3575, 3.9976]])\n---\ntensor([[-0.3471,  0.1097]])\ntensor([[2.4269, 3.9756]])\n---\ntensor([[-0.2058,  0.0516]])\ntensor([[2.4680, 3.9653]])\n---\ntensor([[-0.1223,  0.0233]])\ntensor([[2.4925, 3.9607]])\n---\n\n\n(5) (4)의 수렴값이 학습이 잘 되었다고 생각하는가? 잘 되었다고 생각하면 그 근거는 무엇인가? (단, \\((w_0,w_1)\\)의 참값은 모른다고 가정한다) - hint: 미분값을 근거로 대답할 것\n(풀이)\n최종업데이트에서 계산된 미분계수가 거의 0이므로 잘 수렴했다고 판단되어 진다. (이 경우 손실함수가 convex 이므로 미분계수가 0인 지점이 global minimum이라 주장가능)"
  },
  {
    "objectID": "posts/2022-10-28-9wk-1-midsol.html#다음을-읽고-참-거짓을-판단하라.-20점",
    "href": "posts/2022-10-28-9wk-1-midsol.html#다음을-읽고-참-거짓을-판단하라.-20점",
    "title": "mid",
    "section": "3. 다음을 읽고 참 거짓을 판단하라. (20점)",
    "text": "3. 다음을 읽고 참 거짓을 판단하라. (20점)\nAssignment1의 1번: 아래는 fastai를 사용하여 MNIST 이미지자료중 일부를 분석하는 코드 중 일부이다. (Assignment1의 1번 문항 참고)\npath = untar_data(URLs.MNIST_SAMPLE)\ndls = ImageDataLoaders.from_folder(path,suffle=False) \nlrnr = cnn_learner(dls, arch = resnet34, metrics=error_rate)\nlrnr.fine_tune(1)\nX,y = dls.one_batch()\nlrnr.model(X[0].reshape(1,3,28,28))\n마지막 lrnr.model(X[0].reshape(1,3,28,28))의 실행결과는 아래와 같다.\nTensorBase([[ 3.4148, -5.0356]], device='cuda:0', grad_fn=<AliasBackward0>)\n위의 코드를 올바르게 해석한 것을 모두 고르라.\n(1) MNIST 이미지를 분석하였으므로 X는 흑백이미지의 형태로 저장되어 있을 것이다. 즉 텐서 \\({\\bf X}\\)의 shape은 (n,1,28,28) 과 같은 형태일 것이다.\n\nhint: “lrnr.model(X[0].reshape(1,3,28,28))” 코드를 잘 관찰하세요..\n\n\nFalse # 채널=3이므로 칼라이미지로 저장되어있음. \n\nFalse\n\n\n(2) lrnr.model(X[0].reshape(1,3,28,28)) 의 실행결과로 미루어 볼때 손실함수는 torch.nn.CrossEntropyLoss 를 사용했을 것이다.\n\nTrue \n\nTrue\n\n\n(3) 위의 코드는 resnet34를 이용한 transfer learning 을 구현하였다.\n\nTrue\n\nTrue\n\n\n(4) 현재 lrnr.model와 X[0]는 모두 GPU연산이 가능한 저장장치에 있다.\n\nTrue # lrnr.model(X[0].reshape(1,3,28,28)) 의 연산결과로 유추가능\n\nTrue\n\n\n(5) TensorBase([[ 3.4148, -5.0356]], device='cuda:0', grad_fn=<AliasBackward0>)의 결과에 softmax함수를 취하게 되면 [0,1] 근처의 값이 나올것이다.\n\nFalse \n\nFalse\n\n\n\n(6) torch.nn.Linear(in_features=1,out_features=1,bias=True) 는 학습가능한 파라메터수가 2개이다.\n\nTrue\n\nTrue\n\n\n(7) 아래 2개의 레이어에 대한 학습가능한 파레메터 수는 같다. - torch.nn.Linear(in_features=4,out_features=1,bias=False) - torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=(2,2),bias=False)\n\nTrue\n\nTrue\n\n\n(8) 아래의 네트워크에서 K를 충분히 크게 설정하면 모든 1차원 연속함수를 원하는 정확도로 근사시킬 수 있다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=K),\n    torch.nn.Linear(in_features=K,out_features=1)\n)\n\nFalse \n\nFalse\n\n\n(9) torch.nn.Dropout(0.9)을 이용하여 생성된 layer는 10%의 layer input을 임의로 0으로 만든다.\n\nFalse\n\nFalse\n\n\n(10) 아래와 같은 모형에서 자료가 생성되었다고 하자.\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\n이 경우 다음과 같은 네트워크와 손실함수를 선택한다면 손실함수는 항상 convex function이 된다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1)\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss() \n\nTrue\n\nTrue"
  },
  {
    "objectID": "posts/I. Overview/2022-09-08-2wk-1.html",
    "href": "posts/I. Overview/2022-09-08-2wk-1.html",
    "title": "02wk-1: Overview (2)",
    "section": "",
    "text": "이미지자료분석(2) 데이터정리 \\(\\to\\) lrnr \\(\\to\\) lrnr.학습() \\(\\to\\) lrnr.예측()\n\n\n강의영상\nhttps://youtube.com/playlist?list=PLQqh36zP38-zcq1v38u87lMmD47ujarOZ\n\n\nimports\n\nfrom fastai.vision.all import * \n\n\n\n지난시간 복습\n(1) 데이터의 정리\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfnames = get_image_files(path)\n\n\nf = lambda fname: 'cat' if fname[0].isupper() else 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    f, # f대신 (lambda fname: 'cat' if fname[0].isupper() else 'dog') 를 넣어도 가능\n    item_tfms=Resize(224))\n\n(2) lrnr 오브젝트 생성\n\nlrnr = cnn_learner(dls,resnet34,metrics=error_rate)\n\n(3) lrnr.학습()\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.152362\n      0.015960\n      0.004060\n      00:08\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.066467\n      0.028969\n      0.008119\n      00:10\n    \n  \n\n\n\n\nfine_tune()은 모든 가중치를 학습하는 것이 아니라 일부만 학습하는 것임.\nfine_tune()이외이 방법으로 학습할 수도 있음.\n\n(4) lrnr.예측()\n(방법1) lrnr.predict() 함수를 이용\n\nlrnr.predict('2022-09-06-hani03.jpg') # 방법1-1\n#lrnr.predict(PILImage.create('2022-09-06-hani03.jpg')) # 방법1-2\n#lrnr.predict(path.ls()[0]) # 방법1-3\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([0.2726, 0.7274]))\n\n\n(방법2) lrnr.model(X) 를 이용: X의 shape이 (?,3,224,224)의 형태의 텐서이어야함\n\nX,y = dls.one_batch() # 방법2\nlrnr.model(X[0:1]) \n\nTensorBase([[-3.8654,  2.9234]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\n\n프로그래밍 과정 overview\n- overview\n\ndls 오브젝트 생성\nlrnr 오브젝트 생성\nlrnr.학습()\nlrnr.예측()\n\n- 비교\n\n\n\n\n\n\n\n\n\n\n회귀분석(R)\n이미지분석(CNN)\n추천시스템\n\n\n\n\n1단계\ndata.frame()\nImageDataLoaders.from_name_func()\nCollabDataLoaders.from_df()\n\n\n2단계\nNone\ncnn_learner()\ncollab_learner()\n\n\n3단계\nlm(y~x1+x2,df)\nlrnr.fine_tune(1)\nlrnr.fit()\n\n\n4단계\npredict(ob,newdf)\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\n\n\n\n\n\n숙제\n아래의 함수들이 정의된 위치를 찾아보고 경로를 제출하라.\n\nImageDataLoaders.from_name_func\ncnn_learner\nlrnr.fine_tune\nlrnr.predict\n\n단, 여기에서 lrnr는 cnn_learner()로부터 생성된 오브젝트 이다.\n제출예시\nImageDataLoaders.from_name_func\n\n~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/vision/data.py"
  },
  {
    "objectID": "posts/I. Overview/2022-09-06-1wk-2.html",
    "href": "posts/I. Overview/2022-09-06-1wk-2.html",
    "title": "01wk-2: Overview (1)",
    "section": "",
    "text": "이미지자료분석(1)– 데이터저장, 학습, 기존데이터를 잘맞추는지 확인, 오답분석, 진짜 잘 맞추는게 맞을까?\n\n\n강의영상\nhttps://www.youtube.com/playlist?list=PLQqh36zP38-w4djJcMLe2Jgfuj5V14NPi\n\n\nImport\n\nfrom fastai.vision.all import * \n\n\n\n데이터저장\n\npath = untar_data(URLs.PETS)/'images'\n# URLs.PETS: 스트링 -> 주소가 저장되어 있음.. -> 주소로 들어가보니 어떠한 압축파일이 자동으로 다운 받아짐, 이게 데이터 \n# untar_data: (1) URLs.PETS에 저장된 주소로 찾아가서 (2) 압축을 풀어서 (3) 어떠한 폴더에 저장, 그 폴더의 위치는 path 에 저장 \n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:10<00:00]\n    \n    \n\n\n\npath # 여기에 그림이 있다는 말이지?? \n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\n# 탐색... 여러파일들이 있기는함.. \n# Abyssinian_1.jpg 를 보고싶다면? \nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg')\n\n\n\n\n\n# Abyssinian_100.jpg 를 보고싶다면? \nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.jpg')\n\n\n\n\n- 그림을 확인 할 수 있는건 좋은데 이렇게 확인하니까 조금 귀찮음..\n\n_lst = ['/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg','/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg']\n\n\n_lst[0]\n\n'/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg'\n\n\n\nPILImage.create(_lst[0])\n\n\n\n\n\nfiles= get_image_files(path)\nfiles\n\n(#7390) [Path('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_173.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_192.jpg')...]\n\n\n\nfiles[0]\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg')\n\n\n\n#PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/english_setter_59.jpg')\nPILImage.create(files[0])\n\n\n\n\n\nprint(files[2])\nPILImage.create(files[2])\n\n/root/.fastai/data/oxford-iiit-pet/images/shiba_inu_120.jpg\n\n\n\n\n\n\nprint(files[3])\nPILImage.create(files[3])\n\n/root/.fastai/data/oxford-iiit-pet/images/Persian_26.jpg\n\n\n\n\n\n\nprint(files[4])\nPILImage.create(files[4])\n\n/root/.fastai/data/oxford-iiit-pet/images/yorkshire_terrier_86.jpg\n\n\n\n\n\n\nprint(files[5])\nPILImage.create(files[5])\n\n/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_56.jpg\n\n\n\n\n\n\nprint(files[6])\nPILImage.create(files[6])\n\n/root/.fastai/data/oxford-iiit-pet/images/german_shorthaired_2.jpg\n\n\n\n\n\n\nprint(files[7])\nPILImage.create(files[7])\n\n/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg\n\n\n\n\n\n\nprint(files[8])\nPILImage.create(files[8])\n\n/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_169.jpg\n\n\n\n\n\n\n# 특1: 대문자이면 고양이, 소문자이면 강아지그림이다!! (천재적인 저장방식)\n# 특2: 이미지크기가 서로 다르다..\n\n\ndef label_func(fname):\n  if fname[0].isupper():\n    return 'cat'\n  else:\n    return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(224))\n# path 경로에서 \n# files 에 해당하는 파일들을 불러와서 X를 만들고 \n# item_tfms 에 정의된 방식으로 X를 변환하여 저장한다. 그리고 \n# label_func: \"파일이름\" -> \"라벨\", 에 저장된 함수내용을 바탕으로 y를 만들어 저장한다. \n# 이 모든것이 저장된 자료는 변수 dls에 저장한다. \n\n\ndls.show_batch(max_n=16)\n\n\n\n\n\n\n학습\n\n# 우리의 1차 목표: 이미지 -> 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n# cnn_learner 라는 함수를 이용해서 1차목표와 2차목표를 달성할 \"썸띵(Object)\"을 만들것임. \n## 오브젝트란? 정보와 함수를 동시에 가지는 어떠한 집합체 \n# - 오브젝트.명사이름: 이것 통채로 하나의 변수처럼 쓸 수 있음. \n# - 오브젝트.동사이름: 이것 통채로 하나의 함수처럼 쓸 수 있음. (이때 함수의 첫번째 입력은 명시하지 않아도 오브젝트 그 자체가 된다)\n\n## clafr에 필요한 명사(=정보) <-- 우리가 넣어줘야하는 것들이 대부분\n# (1) 모델정보: 클래시파이어로 누구를 뽑을것인가 (유명한 모델이 무엇인가? 잘 맞추는 모델이 무엇인가)\n# (2) 데이터: 데이터를 줘야함 \n# (3) 평가기준표: 채점을 할 지표 \n## clafr에 필요한 동사(=함수) <-- 이미 구현이 되어있음.. \n# (1) 학습 \n# (2) 결과를 판단\n# (3) 예측 \n\nclsfr = cnn_learner(dls,resnet34,metrics=error_rate)\n# clsfr 라는 오브젝트를 만들건데.. \n# 그 오브젝트의 재료로 dls (데이터), resnet34 (데이터를 분석할 모형이름), metrics (모형의 성능을 평가할 기준) 를 넣음. \n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\nclsfr.fine_tune(1) # 학습을 하는 함수\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.189062\n      0.012517\n      0.006089\n      01:01\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.051309\n      0.010439\n      0.003383\n      00:57\n    \n  \n\n\n\n\n\n기존 데이터를 잘 맞추는지 확인\n\nfiles[0] # 강아지 \n\nPath('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_92.jpg')\n\n\n\nclsfr.predict(files[0])\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([6.8846e-07, 1.0000e+00]))\n\n\n\nfiles[7] # 고양이\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg')\n\n\n\nclsfr.predict(files[7])\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n오답분석\n\ninterpreter = Interpretation.from_learner(clsfr) # 오답을 분석하는 오브젝트를 만듬.. 재료는 클래시파이어! \n\n\n\n\n\n\n\n\n\ninterpreter.plot_top_losses(16) # 오답을 분석하는 오브젝트는 가장 오류가 높은 이미지를 정렬하여 보여주는 기능이 있음..\n\n\n\n\n\n\n\n\n\n\n\n\n\n진짜 잘되는게 맞는건가?\n\nclsfr.predict(files[7])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.predict('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg')\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nclsfr.predict(PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_34.jpg'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.3773e-08]))\n\n\n\nPILImage.create('2022-09-06-cat1.png')\n\n\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-cat1.png'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 1.5662e-10]))\n\n\n\nPILImage.create('2022-09-06-cat2.jpeg')\n\n\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-cat2.jpeg'))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([0.9809, 0.0191]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani01.jpeg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([3.2573e-10, 1.0000e+00]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani02.jpeg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([7.0723e-07, 1.0000e+00]))\n\n\n\nclsfr.predict(PILImage.create('2022-09-06-hani03.jpg'))\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([0.1814, 0.8186]))\n\n\n\n\n숙제\n- 인터넷에 존재하는 개 혹은 고양이 이미지를 임의로 하나 불러온뒤 clsfr에 넣어보고 결과를 관찰하라. 관찰결과를 스크린샷하여 제출하라.\n\n숙제를 위한 예시코드\n\n# https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg <-- 인터넷의 이미지 주소\nimg=PILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\nclsfr.predict(img)\n- 숙제 못하겠으면 카톡으로 물어보세요! 답 알려드립니다.\n- 숙제는 간단하게 편한 형식으로 제출하세요. (저는 스크린샷 선호해요..) pdf나 hwp로 만드실 필요 없습니다."
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html",
    "title": "02wk-1: Overview (3)",
    "section": "",
    "text": "fastai를 이용한 분석 steps, 추천시스템 실습, 텍스트분석 실습"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계",
    "title": "02wk-1: Overview (3)",
    "section": "1단계",
    "text": "1단계\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n  \n    \n      \n      커피1\n      커피2\n      커피3\n      커피4\n      커피5\n      커피6\n      커피7\n      커피8\n      커피9\n      커피10\n      홍차1\n      홍차2\n      홍차3\n      홍차4\n      홍차5\n      홍차6\n      홍차7\n      홍차8\n      홍차9\n      홍차10\n    \n  \n  \n    \n      0\n      4.149209\n      NaN\n      NaN\n      4.078139\n      4.033415\n      4.071871\n      NaN\n      NaN\n      NaN\n      NaN\n      1.142659\n      1.109452\n      NaN\n      0.603118\n      1.084308\n      NaN\n      0.906524\n      NaN\n      NaN\n      0.903826\n    \n    \n      1\n      4.031811\n      NaN\n      NaN\n      3.822704\n      NaN\n      NaN\n      NaN\n      4.071410\n      3.996206\n      NaN\n      NaN\n      0.839565\n      1.011315\n      NaN\n      1.120552\n      0.911340\n      NaN\n      0.860954\n      0.871482\n      NaN\n    \n    \n      2\n      4.082178\n      4.196436\n      NaN\n      3.956876\n      NaN\n      NaN\n      NaN\n      4.450931\n      3.972090\n      NaN\n      NaN\n      NaN\n      NaN\n      0.983838\n      NaN\n      0.918576\n      1.206796\n      0.913116\n      NaN\n      0.956194\n    \n    \n      3\n      NaN\n      4.000621\n      3.895570\n      NaN\n      3.838781\n      3.967183\n      NaN\n      NaN\n      NaN\n      4.105741\n      1.147554\n      NaN\n      1.346860\n      NaN\n      0.614099\n      1.297301\n      NaN\n      NaN\n      NaN\n      1.147545\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      3.888208\n      NaN\n      3.970330\n      3.979490\n      NaN\n      4.010982\n      NaN\n      0.920995\n      1.081111\n      0.999345\n      NaN\n      1.195183\n      NaN\n      0.818332\n      1.236331\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      95\n      0.511905\n      1.066144\n      NaN\n      1.315430\n      NaN\n      1.285778\n      NaN\n      0.678400\n      1.023020\n      0.886803\n      NaN\n      4.055996\n      NaN\n      NaN\n      4.156489\n      4.127622\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      96\n      NaN\n      1.035022\n      NaN\n      1.085834\n      NaN\n      0.812558\n      NaN\n      1.074543\n      NaN\n      0.852806\n      3.894772\n      NaN\n      4.071385\n      3.935935\n      NaN\n      NaN\n      3.989815\n      NaN\n      NaN\n      4.267142\n    \n    \n      97\n      NaN\n      1.115511\n      NaN\n      1.101395\n      0.878614\n      NaN\n      NaN\n      NaN\n      1.329319\n      NaN\n      4.125190\n      NaN\n      4.354638\n      3.811209\n      4.144648\n      NaN\n      NaN\n      4.116915\n      3.887823\n      NaN\n    \n    \n      98\n      NaN\n      0.850794\n      NaN\n      NaN\n      0.927884\n      0.669895\n      NaN\n      NaN\n      0.665429\n      1.387329\n      NaN\n      NaN\n      4.329404\n      4.111706\n      3.960197\n      NaN\n      NaN\n      NaN\n      3.725288\n      4.122072\n    \n    \n      99\n      NaN\n      NaN\n      1.413968\n      0.838720\n      NaN\n      NaN\n      1.094826\n      0.987888\n      NaN\n      1.177387\n      3.957383\n      4.136731\n      NaN\n      4.026915\n      NaN\n      NaN\n      4.164773\n      4.104276\n      NaN\n      NaN\n    \n  \n\n100 rows × 20 columns\n\n\n\n\nrow0 - row49 에 해당하는 유저는 커피를 선호\nrow50 - row99 에 해당하는 유저는 홍차를 선호\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      0\n      1\n      15\n      1.084308\n      홍차5\n    \n    \n      1\n      1\n      1\n      4.149209\n      커피1\n    \n    \n      2\n      1\n      11\n      1.142659\n      홍차1\n    \n    \n      3\n      1\n      5\n      4.033415\n      커피5\n    \n    \n      4\n      1\n      4\n      4.078139\n      커피4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      100\n      18\n      4.104276\n      홍차8\n    \n    \n      996\n      100\n      17\n      4.164773\n      홍차7\n    \n    \n      997\n      100\n      14\n      4.026915\n      홍차4\n    \n    \n      998\n      100\n      4\n      0.838720\n      커피4\n    \n    \n      999\n      100\n      7\n      1.094826\n      커피7\n    \n  \n\n1000 rows × 4 columns\n\n\n\n\n컴퓨터는 이러한 형태를 더 분석하기 좋아한다.\n\n\ndf.item.unique(),df.user.unique()\n# 유저는 1~100 으로 아이템은 1~20으로 번호가 매겨져 있음 \n\n(array([15,  1, 11,  5,  4, 14,  6, 20, 12, 17,  8,  9, 13, 19, 18, 16,  2,\n         3, 10,  7]),\n array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100]))\n\n\n\ndls=CollabDataLoaders.from_df(df)\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n    \n  \n  \n    \n      0\n      2\n      1\n      4.031811\n    \n    \n      1\n      40\n      19\n      1.015886\n    \n    \n      2\n      39\n      20\n      0.853394\n    \n    \n      3\n      58\n      8\n      0.854745\n    \n    \n      4\n      38\n      6\n      4.055263\n    \n    \n      5\n      45\n      17\n      0.608018\n    \n    \n      6\n      59\n      14\n      3.986921\n    \n    \n      7\n      6\n      12\n      0.833454\n    \n    \n      8\n      98\n      13\n      4.354638\n    \n    \n      9\n      74\n      12\n      4.199568\n    \n  \n\n\n\n\nX,y= dls.one_batch()\n\n\nX[0],y[0]\n\n(tensor([64, 15]), tensor([4.1146]))\n\n\n\n64번 유저가 15번 아이템을 먹었을때 평점을 4.1146 주었음"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-1",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-1",
    "title": "02wk-1: Overview (3)",
    "section": "2단계",
    "text": "2단계\n\nlrnr = collab_learner(dls,y_range=(0,5)) # y_range는 평점의 범위"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-2",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-2",
    "title": "02wk-1: Overview (3)",
    "section": "3단계",
    "text": "3단계\n\nlrnr.fit(10) # 총 30번 정도 해야 적합이 잘된다. \n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.044790\n      0.064825\n      00:00\n    \n    \n      1\n      0.042065\n      0.059010\n      00:00\n    \n    \n      2\n      0.039907\n      0.055658\n      00:00\n    \n    \n      3\n      0.038412\n      0.053847\n      00:00\n    \n    \n      4\n      0.037186\n      0.052595\n      00:00\n    \n    \n      5\n      0.036020\n      0.052121\n      00:00\n    \n    \n      6\n      0.035041\n      0.051959\n      00:00\n    \n    \n      7\n      0.034370\n      0.051995\n      00:00\n    \n    \n      8\n      0.033759\n      0.052022\n      00:00\n    \n    \n      9\n      0.033237\n      0.052229\n      00:00"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-3",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-3",
    "title": "02wk-1: Overview (3)",
    "section": "4단계",
    "text": "4단계\n- 하나의 배치 전체를 예측\n\nyhat=lrnr.model(X.to(\"cuda:0\"))\nyhat\n\ntensor([4.0162, 0.9041, 4.0706, 0.9730, 0.9861, 1.1032, 4.0559, 4.0745, 3.9329,\n        4.0195, 3.9139, 4.0732, 3.8666, 3.9556, 0.9634, 1.0055, 0.9944, 3.9826,\n        4.0456, 0.9961, 0.9438, 0.9291, 4.0212, 1.0700, 4.0543, 4.0441, 4.0918,\n        0.9850, 1.0140, 4.1212, 4.0628, 3.9923, 4.0395, 0.9331, 3.9581, 3.9999,\n        1.1152, 3.9131, 4.0565, 3.9264, 3.9619, 0.9421, 1.1348, 4.0688, 0.8939,\n        0.9684, 1.0505, 1.1034, 1.1027, 3.9411, 1.0582, 3.9680, 4.0465, 3.9554,\n        4.0419, 1.0965, 1.0784, 0.9954, 4.0205, 0.9373, 3.9045, 1.0255, 3.8102,\n        1.0640], device='cuda:0', grad_fn=<AddBackward0>)\n\n\n\nlrnr.model()은 GPU메모리에 존재하고 X는 일반메모리에 존재하므로 X를 GPU메모리로 옮겨주어야 함\nX.to(“cuda:0”)을 통하여 X를 GPU메모리로 옮기는 작업을 수행할 수 있다.\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어진 자료중에서 예측)\n\nX.shape\n\ntorch.Size([64, 2])\n\n\n\nX[0:1]\n\ntensor([[18,  5]])\n\n\n\n18번 유저가 5번 아이템(커피)를 먹는다면?\n\n\nlrnr.model(X[0:1].to(\"cuda:0\"))\n\ntensor([4.1128], device='cuda:0', grad_fn=<AddBackward0>)\n\n\n\n평점은 4.1128정도 될것\n\n- 하나의 유저가 하나의 아이템을 선택했다고 가정하고 예측 (주어지지 않은 자료중에서 예측)\n\nX[0:1]\n\ntensor([[18,  5]])\n\n\n\nXnew = torch.tensor([[1,  2]])\n\n\nlrnr.model(Xnew.to(\"cuda:0\"))\n\ntensor([3.9397], device='cuda:0', grad_fn=<AddBackward0>)"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-4",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-4",
    "title": "02wk-1: Overview (3)",
    "section": "1단계",
    "text": "1단계\n\ndf = pd.DataFrame({'text':['h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??']*20000})\ndf\n\n\n\n\n\n  \n    \n      \n      text\n    \n  \n  \n    \n      0\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      1\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      2\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      3\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      4\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      ...\n      ...\n    \n    \n      19995\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19996\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19997\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19998\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n    \n      19999\n      h e l l o . h e l l o ! h e l l o ? h e l l o !! h e l l o ??\n    \n  \n\n20000 rows × 1 columns\n\n\n\n\ndls = TextDataLoaders.from_df(df,text_col='text',is_lm=True) \n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n  \n    \n      \n      text\n      text_\n    \n  \n  \n    \n      0\n      xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\n      h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o .\n    \n    \n      1\n      ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\n      xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o\n    \n    \n      2\n      ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n      ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l\n    \n    \n      3\n      o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n      ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l\n    \n    \n      4\n      l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\n      o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e\n    \n    \n      5\n      l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\n      l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h\n    \n    \n      6\n      e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\n      l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos\n    \n    \n      7\n      h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\n      e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ?\n    \n    \n      8\n      ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o\n      h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ? ? xxbos h e l l o . h e l l o ! h e l l o ? h e l l o ! ! h e l l o ?\n    \n  \n\n\n\n\nis_lm: text의 생성에 관심이 있다면 True로 설정할 것"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-5",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-5",
    "title": "02wk-1: Overview (3)",
    "section": "2단계",
    "text": "2단계\n\nlrnr = language_model_learner(dls, AWD_LSTM)"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-6",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-6",
    "title": "02wk-1: Overview (3)",
    "section": "3단계",
    "text": "3단계\n\nlrnr.fit(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.575245\n      0.245803\n      00:11"
  },
  {
    "objectID": "posts/I. Overview/2022-09-13-2wk-2.html#단계-7",
    "href": "posts/I. Overview/2022-09-13-2wk-2.html#단계-7",
    "title": "02wk-1: Overview (3)",
    "section": "4단계",
    "text": "4단계\n\nlrnr.predict('h e',n_words=30)\n\n\n\n\n\n\n\n\n'h e l l l o . h e l l . e l l o ? ? h e l l o ! ! h e l l o !'"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html",
    "title": "02wk-1: Overview (4)",
    "section": "",
    "text": "이미지분석, 추천시스템, 텍스트분석 복습 및 비교정리 // GAN intro, GAN 실습"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#생성모형이란-쉬운-설명",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#생성모형이란-쉬운-설명",
    "title": "02wk-1: Overview (4)",
    "section": "생성모형이란? (쉬운 설명)",
    "text": "생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#gan의-응용분야",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#gan의-응용분야",
    "title": "02wk-1: Overview (4)",
    "section": "GAN의 응용분야",
    "text": "GAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면?\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요….."
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#생성모형이란-통계학과-버전의-설명",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#생성모형이란-통계학과-버전의-설명",
    "title": "02wk-1: Overview (4)",
    "section": "생성모형이란? 통계학과 버전의 설명",
    "text": "생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다. 여기에서 \\(p(\\boldsymbol{x},y)\\)는 \\({\\boldsymbol x},y\\)의 결합확률밀도함수.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다. 여기에서 \\(p(y|\\boldsymbol{x})\\)는 조건부 확률밀도 함수\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol x}) = \\frac{p({\\boldsymbol x},y)}{p({\\boldsymbol x})} = \\frac{p({\\boldsymbol x},y)}{\\sum_{y}p({\\boldsymbol x},y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다."
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#gan의-원리",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#gan의-원리",
    "title": "02wk-1: Overview (4)",
    "section": "GAN의 원리",
    "text": "GAN의 원리\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –> 상사에게 혼남. 그것도 구분못하냐고\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#아키텍처",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#아키텍처",
    "title": "02wk-1: Overview (4)",
    "section": "아키텍처",
    "text": "아키텍처\n- 아래와 같은 두 모델(네트워크)를 생각하자.\n\n위조범네트워크: X=노이즈(=아무숫자) \\(\\to\\) y=지폐이미지(=가짜지폐)\n경찰네트워크: X={가짜지폐,진짜지폐} \\(\\to\\) y={진짜,가짜}\n\n- 전체 알고리즘은 아래와 같은 순서로 돌아간다. (전체 이미지 자료는 \\(n\\)개라고 하자)\n\n적당한 크기의 \\(n\\)개의 노이즈가 위조범네트워크에 입력으로 들어감\n위조범네트워크는 적당한 크기의 \\(n\\)개의 노이즈를 입력으로 받고 출력으로 \\(n\\)개의 이미지를 뱉어냄.\n위조범이 뱉어낸 이미지와 진짜이미지를 합쳐 \\(2n\\)개의 자료를 만들고 이를 경창네트워크의 입력으로 넣음.\n경찰네트워크는 \\(2n\\)개의 자료를 입력으로 받아서 \\(2n\\)개의 예측결과를 제공."
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#단계",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#단계",
    "title": "02wk-1: Overview (4)",
    "section": "1단계",
    "text": "1단계\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\ndblock = DataBlock(blocks=(TransformBlock,ImageBlock),\n          get_x = generate_noise,\n          get_items=get_image_files,\n          item_tfms=Resize(32))\ndls = dblock.dataloaders(path) \n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#단계-1",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#단계-1",
    "title": "02wk-1: Overview (4)",
    "section": "2단계",
    "text": "2단계\n\ncounterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1) # 32*32의 이미지가 칼라이미지로 출력. \npolice = basic_critic(32,n_channels=3,n_extra_layers=1) # 32*32의 칼라이미지가 입력으로 들어옴. \n\n\nlrnr = GANLearner.wgan(dls,counterfeiter,police)"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#단계-2",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#단계-2",
    "title": "02wk-1: Overview (4)",
    "section": "3단계",
    "text": "3단계\n- lrnr.fit(10) 진행\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.546135\n      0.362349\n      0.362349\n      -0.757082\n      00:02\n    \n    \n      1\n      -0.582954\n      0.300018\n      0.300018\n      -0.770161\n      00:02\n    \n    \n      2\n      -0.585224\n      0.277624\n      0.277624\n      -0.769241\n      00:02\n    \n    \n      3\n      -0.582842\n      0.385249\n      0.385249\n      -0.764790\n      00:02\n    \n    \n      4\n      -0.584591\n      0.333895\n      0.333895\n      -0.768902\n      00:02\n    \n    \n      5\n      -0.587377\n      0.304535\n      0.304535\n      -0.773640\n      00:02\n    \n    \n      6\n      -0.580959\n      0.274871\n      0.274871\n      -0.765747\n      00:02\n    \n    \n      7\n      -0.559458\n      0.348925\n      0.348925\n      -0.734318\n      00:02\n    \n    \n      8\n      -0.486598\n      0.074547\n      0.074547\n      -0.545082\n      00:03\n    \n    \n      9\n      -0.550950\n      0.278006\n      0.278006\n      -0.724520\n      00:03\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n- lrnr.fit(10) 추가로 진행 // 총20회\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.534234\n      0.261044\n      0.261044\n      -0.737007\n      00:02\n    \n    \n      1\n      -0.515386\n      0.241006\n      0.241006\n      -0.720394\n      00:02\n    \n    \n      2\n      -0.561530\n      0.249572\n      0.249572\n      -0.742900\n      00:02\n    \n    \n      3\n      -0.544423\n      0.315043\n      0.315043\n      -0.739004\n      00:02\n    \n    \n      4\n      -0.534188\n      0.235120\n      0.235120\n      -0.686251\n      00:02\n    \n    \n      5\n      -0.494047\n      0.284046\n      0.284046\n      -0.633201\n      00:02\n    \n    \n      6\n      -0.506470\n      0.214011\n      0.214011\n      -0.687545\n      00:02\n    \n    \n      7\n      -0.527870\n      0.262492\n      0.262492\n      -0.731213\n      00:02\n    \n    \n      8\n      -0.504433\n      0.192755\n      0.192755\n      -0.674976\n      00:02\n    \n    \n      9\n      -0.538148\n      0.204089\n      0.204089\n      -0.728712\n      00:02\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n- lrnr.fit(30) 추가로 진행 // 총50회\n\nlrnr.fit(30)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      gen_loss\n      crit_loss\n      time\n    \n  \n  \n    \n      0\n      -0.509745\n      0.286478\n      0.286478\n      -0.691290\n      00:02\n    \n    \n      1\n      -0.502572\n      0.285199\n      0.285199\n      -0.675554\n      00:02\n    \n    \n      2\n      -0.473333\n      0.219742\n      0.219742\n      -0.650543\n      00:02\n    \n    \n      3\n      -0.419040\n      0.287789\n      0.287789\n      -0.543150\n      00:02\n    \n    \n      4\n      -0.275088\n      0.264852\n      0.264852\n      -0.105730\n      00:02\n    \n    \n      5\n      -0.350050\n      0.330111\n      0.330111\n      -0.529484\n      00:02\n    \n    \n      6\n      -0.394095\n      0.228335\n      0.228335\n      -0.616371\n      00:02\n    \n    \n      7\n      -0.247936\n      0.177943\n      0.177943\n      -0.286712\n      00:02\n    \n    \n      8\n      -0.333396\n      0.207328\n      0.207328\n      -0.585255\n      00:02\n    \n    \n      9\n      -0.370004\n      0.356040\n      0.356040\n      -0.641916\n      00:02\n    \n    \n      10\n      -0.463898\n      0.195165\n      0.195165\n      -0.215188\n      00:02\n    \n    \n      11\n      -0.241843\n      0.110512\n      0.110512\n      -0.411598\n      00:02\n    \n    \n      12\n      -0.227809\n      -0.094414\n      -0.094414\n      -0.306309\n      00:02\n    \n    \n      13\n      -0.185607\n      -0.063660\n      -0.063660\n      -0.261691\n      00:02\n    \n    \n      14\n      -0.219289\n      -0.041734\n      -0.041734\n      -0.424938\n      00:02\n    \n    \n      15\n      -0.048843\n      0.063750\n      0.063750\n      -0.088812\n      00:02\n    \n    \n      16\n      -0.092374\n      -0.218327\n      -0.218327\n      -0.001817\n      00:02\n    \n    \n      17\n      -0.081938\n      -0.068263\n      -0.068263\n      -0.052643\n      00:02\n    \n    \n      18\n      -0.031063\n      -0.183604\n      -0.183604\n      -0.013827\n      00:02\n    \n    \n      19\n      -0.025211\n      0.041027\n      0.041027\n      -0.061204\n      00:02\n    \n    \n      20\n      -0.023948\n      0.244387\n      0.244387\n      -0.001813\n      00:02\n    \n    \n      21\n      -0.073112\n      0.275998\n      0.275998\n      -0.150063\n      00:02\n    \n    \n      22\n      -0.064780\n      0.112151\n      0.112151\n      -0.123186\n      00:02\n    \n    \n      23\n      -0.030959\n      0.002616\n      0.002616\n      -0.134843\n      00:02\n    \n    \n      24\n      -0.066342\n      0.604107\n      0.604107\n      -0.118417\n      00:02\n    \n    \n      25\n      -0.025819\n      0.066880\n      0.066880\n      -0.087840\n      00:02\n    \n    \n      26\n      -0.061908\n      -0.129382\n      -0.129382\n      -0.101803\n      00:02\n    \n    \n      27\n      -0.096987\n      -0.213048\n      -0.213048\n      -0.081656\n      00:02\n    \n    \n      28\n      -0.114984\n      0.287159\n      0.287159\n      -0.152345\n      00:02\n    \n    \n      29\n      -0.062543\n      -0.076906\n      -0.076906\n      -0.078245\n      00:02\n    \n  \n\n\n\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n그럴싸한 글씨가 몇개 보이긴 함"
  },
  {
    "objectID": "posts/I. Overview/2022-09-15-3wk-1.html#단계-없음",
    "href": "posts/I. Overview/2022-09-15-3wk-1.html#단계-없음",
    "title": "02wk-1: Overview (4)",
    "section": "4단계 (없음)",
    "text": "4단계 (없음)"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "assignment1"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html#이미지자료분석",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html#이미지자료분석",
    "title": "Assignment 1",
    "section": "1. 이미지자료분석",
    "text": "1. 이미지자료분석\n아래를 이용하여 MNIST_SAMPLE 이미지 자료를 다운로드 받고 dls오브젝트를 만들어라.\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\ndls = ImageDataLoaders.from_folder(path,suffle=False) \n\n\ndls.show_batch()\n\n\n\n\n(1) cnn_learner를 이용하여 lrnr 오브젝트를 생성하라. - arch 는 resnet34 로 설정할 것 - metrics 는 error_rate 로 설정할 것\n(풀이)\n\nlrnr = cnn_learner(dls, arch = resnet34, metrics=error_rate)\n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n(2) fine_tune 을 이용하여 lrnr 오브젝트를 학습하라.\n(풀이)\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.282870\n      0.150136\n      0.049068\n      00:05\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.042991\n      0.017522\n      0.006379\n      00:05\n    \n  \n\n\n\n(3) 아래를 이용하여 X,y를 만들어라.\nX,y = dls.one_batch()\nX,y의 shape을 조사하라. X에는 몇개의 이미지가 있는가? 이미지의 size는 얼마인가?\n(풀이)\n\nX,y = dls.one_batch()\nX.shape\n\ntorch.Size([64, 3, 28, 28])\n\n\nX에는 64개의 이미지가 있고 크기는 (28,28) 이다.\n(4) 아래의 코드를 이용하여 X의 두번째 이미지가 어떠한 숫자를 의미하는지 확인하라. (그림보고 3인지 7인지 확인하여 답을 쓸 것)\nshow_image(X[0])\n그리고 show_image가 정의된 파일의 경로를 확인하고 show_image가 python 내장함수 인지, torch에서 지원하는 함수인지 fastai에서 지원하는 함수인지 파악하라.\n(풀이)\n\nshow_image(X[1]) # 두번째 이미지 \n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n<AxesSubplot:>\n\n\n\n\n\n\nshow_image?\n\n\nSignature:\nshow_image(\n    im,\n    ax=None,\n    figsize=None,\n    title=None,\n    ctx=None,\n    cmap=None,\n    norm=None,\n    *,\n    aspect=None,\n    interpolation=None,\n    alpha=None,\n    vmin=None,\n    vmax=None,\n    origin=None,\n    extent=None,\n    interpolation_stage=None,\n    filternorm=True,\n    filterrad=4.0,\n    resample=None,\n    url=None,\n    data=None,\n    **kwargs,\n)\nDocstring: Show a PIL or PyTorch image on `ax`.\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/torch_core.py\nType:      function\n\n\n\n\n\nfastai에서 지원하는 함수\n\n(5) lrnr 오브젝트를 이용하여 AI가 X[0]을 어떤 값으로 판단하는지 확인하라. 올바르게 판단하였는가? 올바르게 판단했다면 몇 프로의 확신으로 판단하였는가? <– 문제가 의도한 것과 다르게 만들어졌어요\n(풀이)\n\nshow_image(X[0]) # 첫번째 이미지\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n<AxesSubplot:>\n\n\n\n\n\n\nlrnr.model(X[0].reshape(1,3,28,28))\n\nTensorBase([[ 3.4148, -5.0356]], device='cuda:0', grad_fn=<AliasBackward0>)\n\n\n\nimport numpy as np\na=np.exp(3.4148)\nb=np.exp(-5.0356)\nprint('3일확률',a/(a+b))\nprint('7일확률',b/(a+b))\n\n3일확률 0.9997862308347155\n7일확률 0.0002137691652844868\n\n\n\n원래문제의도: lrnr.predict(X[0].to(\"cpu\"))"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html#추천시스템",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html#추천시스템",
    "title": "Assignment 1",
    "section": "2. 추천시스템",
    "text": "2. 추천시스템\n아래를 이용하여 rcmd_anal.csv 를 다운로드 받고 dls오브젝트를 만들어라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      0\n      1\n      15\n      1.084308\n      홍차5\n    \n    \n      1\n      1\n      1\n      4.149209\n      커피1\n    \n    \n      2\n      1\n      11\n      1.142659\n      홍차1\n    \n    \n      3\n      1\n      5\n      4.033415\n      커피5\n    \n    \n      4\n      1\n      4\n      4.078139\n      커피4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      995\n      100\n      18\n      4.104276\n      홍차8\n    \n    \n      996\n      100\n      17\n      4.164773\n      홍차7\n    \n    \n      997\n      100\n      14\n      4.026915\n      홍차4\n    \n    \n      998\n      100\n      4\n      0.838720\n      커피4\n    \n    \n      999\n      100\n      7\n      1.094826\n      커피7\n    \n  \n\n1000 rows × 4 columns\n\n\n\n(1) 73번 유저가 먹은 아이템 및 평점을 출력하는 코드를 작성하라. 이를 기반으로 73번 유저가 어떠한 취향인지 파악하라.\n(풀이)\n\ndf.query('user == 73')\n\n\n\n\n\n  \n    \n      \n      user\n      item\n      rating\n      item_name\n    \n  \n  \n    \n      720\n      73\n      20\n      3.733853\n      홍차10\n    \n    \n      721\n      73\n      18\n      3.975004\n      홍차8\n    \n    \n      722\n      73\n      9\n      1.119541\n      커피9\n    \n    \n      723\n      73\n      13\n      3.840801\n      홍차3\n    \n    \n      724\n      73\n      2\n      0.943742\n      커피2\n    \n    \n      725\n      73\n      4\n      1.152405\n      커피4\n    \n    \n      726\n      73\n      1\n      0.887292\n      커피1\n    \n    \n      727\n      73\n      7\n      0.947641\n      커피7\n    \n    \n      728\n      73\n      6\n      0.868370\n      커피6\n    \n    \n      729\n      73\n      17\n      3.873590\n      홍차7\n    \n  \n\n\n\n\n\n홍차를 선호\n\n(2) dls와 lrnr 오브젝트를 생성하고 lrnr 오브젝트를 학습하라.\n(풀이)\n\ndls = CollabDataLoaders.from_df(df)\nlrnr = collab_learner(dls,y_range=(0,5))\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      2.337114\n      2.258755\n      00:00\n    \n    \n      1\n      2.328897\n      2.254714\n      00:00\n    \n    \n      2\n      2.320246\n      2.237874\n      00:00\n    \n    \n      3\n      2.300545\n      2.191783\n      00:00\n    \n    \n      4\n      2.265857\n      2.104007\n      00:00\n    \n    \n      5\n      2.207397\n      1.966761\n      00:00\n    \n    \n      6\n      2.123599\n      1.783263\n      00:00\n    \n    \n      7\n      2.008980\n      1.562448\n      00:00\n    \n    \n      8\n      1.865242\n      1.317642\n      00:00\n    \n    \n      9\n      1.697832\n      1.068948\n      00:00\n    \n    \n      10\n      1.515044\n      0.833239\n      00:00\n    \n    \n      11\n      1.326496\n      0.625003\n      00:00\n    \n    \n      12\n      1.139156\n      0.453686\n      00:00\n    \n    \n      13\n      0.962462\n      0.320953\n      00:00\n    \n    \n      14\n      0.802481\n      0.223124\n      00:00\n    \n    \n      15\n      0.662327\n      0.155420\n      00:00\n    \n    \n      16\n      0.542384\n      0.110662\n      00:00\n    \n    \n      17\n      0.442099\n      0.082435\n      00:00\n    \n    \n      18\n      0.359706\n      0.064858\n      00:00\n    \n    \n      19\n      0.292656\n      0.054441\n      00:00\n    \n    \n      20\n      0.238817\n      0.048325\n      00:00\n    \n    \n      21\n      0.195901\n      0.045092\n      00:00\n    \n    \n      22\n      0.161955\n      0.043386\n      00:00\n    \n    \n      23\n      0.135049\n      0.042616\n      00:00\n    \n    \n      24\n      0.113653\n      0.042549\n      00:00\n    \n    \n      25\n      0.096877\n      0.042678\n      00:00\n    \n    \n      26\n      0.083618\n      0.043010\n      00:00\n    \n    \n      27\n      0.073081\n      0.043308\n      00:00\n    \n    \n      28\n      0.064768\n      0.043905\n      00:00\n    \n    \n      29\n      0.058133\n      0.044605\n      00:00\n    \n    \n      30\n      0.053050\n      0.044990\n      00:00\n    \n    \n      31\n      0.048904\n      0.045569\n      00:00\n    \n    \n      32\n      0.045665\n      0.045833\n      00:00\n    \n    \n      33\n      0.043033\n      0.045906\n      00:00\n    \n    \n      34\n      0.040883\n      0.046624\n      00:00\n    \n    \n      35\n      0.039263\n      0.046878\n      00:00\n    \n    \n      36\n      0.037608\n      0.047040\n      00:00\n    \n    \n      37\n      0.036450\n      0.047146\n      00:00\n    \n    \n      38\n      0.035638\n      0.047335\n      00:00\n    \n    \n      39\n      0.034883\n      0.047623\n      00:00\n    \n    \n      40\n      0.034177\n      0.048048\n      00:00\n    \n    \n      41\n      0.033486\n      0.047836\n      00:00\n    \n    \n      42\n      0.033047\n      0.048263\n      00:00\n    \n    \n      43\n      0.032634\n      0.048296\n      00:00\n    \n    \n      44\n      0.032165\n      0.048577\n      00:00\n    \n    \n      45\n      0.031884\n      0.048578\n      00:00\n    \n    \n      46\n      0.031517\n      0.048725\n      00:00\n    \n    \n      47\n      0.031158\n      0.048977\n      00:00\n    \n    \n      48\n      0.030711\n      0.048955\n      00:00\n    \n    \n      49\n      0.030465\n      0.049127\n      00:00\n    \n  \n\n\n\n(3) 아래와 같은 데이터 프레임을 생성하고 df_new 에 저장하라.\n\n#collapse\nimport IPython \n_html='<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>user</th>\\n      <th>item</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>73</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>73</td>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>73</td>\\n      <td>3</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>73</td>\\n      <td>4</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>73</td>\\n      <td>5</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>73</td>\\n      <td>6</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>73</td>\\n      <td>7</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>73</td>\\n      <td>8</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>73</td>\\n      <td>9</td>\\n    </tr>\\n    <tr>\\n      <th>9</th>\\n      <td>73</td>\\n      <td>10</td>\\n    </tr>\\n    <tr>\\n      <th>10</th>\\n      <td>73</td>\\n      <td>11</td>\\n    </tr>\\n    <tr>\\n      <th>11</th>\\n      <td>73</td>\\n      <td>12</td>\\n    </tr>\\n    <tr>\\n      <th>12</th>\\n      <td>73</td>\\n      <td>13</td>\\n    </tr>\\n    <tr>\\n      <th>13</th>\\n      <td>73</td>\\n      <td>14</td>\\n    </tr>\\n    <tr>\\n      <th>14</th>\\n      <td>73</td>\\n      <td>15</td>\\n    </tr>\\n    <tr>\\n      <th>15</th>\\n      <td>73</td>\\n      <td>16</td>\\n    </tr>\\n    <tr>\\n      <th>16</th>\\n      <td>73</td>\\n      <td>17</td>\\n    </tr>\\n    <tr>\\n      <th>17</th>\\n      <td>73</td>\\n      <td>18</td>\\n    </tr>\\n    <tr>\\n      <th>18</th>\\n      <td>73</td>\\n      <td>19</td>\\n    </tr>\\n    <tr>\\n      <th>19</th>\\n      <td>73</td>\\n      <td>20</td>\\n    </tr>\\n  </tbody>\\n</table>'\nIPython.display.HTML(_html)\n\n\n\n  \n    \n      \n      user\n      item\n    \n  \n  \n    \n      0\n      73\n      1\n    \n    \n      1\n      73\n      2\n    \n    \n      2\n      73\n      3\n    \n    \n      3\n      73\n      4\n    \n    \n      4\n      73\n      5\n    \n    \n      5\n      73\n      6\n    \n    \n      6\n      73\n      7\n    \n    \n      7\n      73\n      8\n    \n    \n      8\n      73\n      9\n    \n    \n      9\n      73\n      10\n    \n    \n      10\n      73\n      11\n    \n    \n      11\n      73\n      12\n    \n    \n      12\n      73\n      13\n    \n    \n      13\n      73\n      14\n    \n    \n      14\n      73\n      15\n    \n    \n      15\n      73\n      16\n    \n    \n      16\n      73\n      17\n    \n    \n      17\n      73\n      18\n    \n    \n      18\n      73\n      19\n    \n    \n      19\n      73\n      20\n    \n  \n\n\n\n(풀이)\n\ndf_new=pd.DataFrame({'user':[73]*20,'item':range(1,21)})\ndf_new\n\n\n\n\n\n  \n    \n      \n      user\n      item\n    \n  \n  \n    \n      0\n      73\n      1\n    \n    \n      1\n      73\n      2\n    \n    \n      2\n      73\n      3\n    \n    \n      3\n      73\n      4\n    \n    \n      4\n      73\n      5\n    \n    \n      5\n      73\n      6\n    \n    \n      6\n      73\n      7\n    \n    \n      7\n      73\n      8\n    \n    \n      8\n      73\n      9\n    \n    \n      9\n      73\n      10\n    \n    \n      10\n      73\n      11\n    \n    \n      11\n      73\n      12\n    \n    \n      12\n      73\n      13\n    \n    \n      13\n      73\n      14\n    \n    \n      14\n      73\n      15\n    \n    \n      15\n      73\n      16\n    \n    \n      16\n      73\n      17\n    \n    \n      17\n      73\n      18\n    \n    \n      18\n      73\n      19\n    \n    \n      19\n      73\n      20\n    \n  \n\n\n\n\n(4) 아래의 코드를 이용하여 73번 유저의 취향을 파악하라. 73번 유저가 커피3, 커피5를 먹는다면 얼마정도의 평점을 줄 것이라 예측되는가?\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n(풀이)\n\n_dl = dls.test_dl(df_new)\nlrnr.get_preds(dl=_dl)\n\n\n\n\n\n\n\n\n(tensor([0.9698, 1.0314, 1.0191, 1.0177, 1.0122, 0.9323, 1.0513, 1.0184, 1.0316,\n         0.9842, 3.8255, 3.9591, 3.8640, 3.8937, 3.9437, 3.8947, 3.8272, 3.9503,\n         3.8117, 3.8603]),\n None)\n\n\n\n커피3: 1.0191, 커피5: 1.0122"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html#시퀀스자료분석",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html#시퀀스자료분석",
    "title": "Assignment 1",
    "section": "3. 시퀀스자료분석",
    "text": "3. 시퀀스자료분석\n아래를 이용하여 자료를 다운로드 받아라.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-19-human_numbers_100.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      Unnamed: 0\n      text\n    \n  \n  \n    \n      0\n      0\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1\n      1\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      2\n      2\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      3\n      3\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      4\n      4\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      1995\n      1995\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1996\n      1996\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1997\n      1997\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1998\n      1998\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n    \n      1999\n      1999\n      one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen, seventeen, eighteen, nineteen, twenty, twenty one, twenty two, twenty three, twenty four, twenty five, twenty six, twenty seven, twenty eight, twenty nine, thirty, thirty one, thirty two, thirty three, thirty four, thirty five, thirty six, thirty seven, thirty eight, thirty nine, forty, forty one, forty two, forty three, forty four, forty five, forty six, forty seven, forty eight, forty nine, fifty, fifty one, fifty two, fifty three, fifty four, fifty five, fifty six, fifty seve...\n    \n  \n\n2000 rows × 2 columns\n\n\n\n(1) TextDataLoaders.from_df을 이용하여 dls오브젝트를 만들어라. - is_lm = True 로 설정할 것 - seq_len = 5 로 설정할 것\n(풀이)\n\ndls = TextDataLoaders.from_df(df,is_lm=True,seq_len=5,text_col='text')\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      text\n      text_\n    \n  \n  \n    \n      0\n      xxbos one , two ,\n      one , two , three\n    \n    \n      1\n      hundred xxbos one , two\n      xxbos one , two ,\n    \n    \n      2\n      one hundred xxbos one ,\n      hundred xxbos one , two\n    \n    \n      3\n      , one hundred xxbos one\n      one hundred xxbos one ,\n    \n    \n      4\n      nine , one hundred xxbos\n      , one hundred xxbos one\n    \n    \n      5\n      ninety nine , one hundred\n      nine , one hundred xxbos\n    \n    \n      6\n      , ninety nine , one\n      ninety nine , one hundred\n    \n    \n      7\n      eight , ninety nine ,\n      , ninety nine , one\n    \n    \n      8\n      ninety eight , ninety nine\n      eight , ninety nine ,\n    \n  \n\n\n\n(2) lrnr 오브젝트를 만들어라. - arch = AWD_LSTM 이용 - metrics = accuracy 이용\n(풀이)\n\nlrnr = language_model_learner(dls, arch= AWD_LSTM, metrics=accuracy)\n\n(3) lrnr오브젝트에서 fine_tune(3) 메소드를 이용하여 모형을 학습하라.\n(풀이)\n\nlrnr.fine_tune(3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.534681\n      0.168856\n      0.977650\n      00:49\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy\n      time\n    \n  \n  \n    \n      0\n      0.018749\n      0.003256\n      0.999205\n      00:54\n    \n    \n      1\n      0.001580\n      0.002430\n      0.999324\n      00:54\n    \n    \n      2\n      0.000651\n      0.002244\n      0.999315\n      00:54\n    \n  \n\n\n\n(4) ‘one , two ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('one, two,', n_words=50) \n\n\n\n\n\n\n\n\n'one , two , three , four , five , six , seven , eight , nine , ten , eleven , twelve , thirteen , fourteen , fifteen , sixteen , seventeen , eighteen , nineteen , twenty , twenty one , twenty two , twenty three , twenty four , twenty five'\n\n\n(5) ‘twenty , twenty one ,’ 이후에 이어질 50개의 단어를 생성하라.\n(풀이)\n\nlrnr.predict('twenty, twenty one,', n_words=50) \n\n\n\n\n\n\n\n\n'twenty , twenty one , twenty two , twenty three , twenty four , twenty five , twenty six , twenty seven , twenty eight , twenty nine , thirty , thirty one , thirty two , thirty three , thirty four , thirty five , thirty six , thirty seven , thirty eight ,'"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html#리눅스명령어",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html#리눅스명령어",
    "title": "Assignment 1",
    "section": "4. 리눅스명령어",
    "text": "4. 리눅스명령어\nCollab 에서 (혹은 리눅스기반 서버에서) 아래의 명령어를 순서대로 실행해보라.\n!ls\n!ls -a \n!ls .\n!ls .. \n!ls sample\n!mkdir asdf \n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n!cp 2022-09-08-rcmd_anal.csv ./asdf \n!ls ./asdf \n!rm 2022-09-08-rcmd_anal.csv \n!rm -rf asdf \n각 명령들이 무엇을 의미하는지 간단히 서술하라.\n(풀이)\n!ls - 현재디렉토리 파일+폴더 출력 - !ls . 와 같음 - !ls ./ 와 같음\n!ls -a - 현재디렉토리 파일+폴더 출력, 숨겨진 항목까지 출력\n!ls . - 현재디렉토리 파일+폴더 출력 - !ls 와 같음 - !ls ./ 와 같음\n!ls .. - 현재디렉토리보다 상위디렉토리의 파일+폴더 출력\n!ls sample - 현재디렉토리에 sample 디렉토리 출력 - !ls ./sample 과 같음\n!mkdir asdf - 현재디렉토리에 asdf 폴더 생성 - !mkdir ./asdf 와 같음\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv - url에 있는 파일 다운로드하여 현재디렉토리에 저장\n!cp 2022-09-08-rcmd_anal.csv ./asdf - 2022-09-08-rcmd_anal.csv 파일을 ./asdf 로 복사\n!ls ./asdf - 현재디렉토리에서 asdf 디렉토리의 내용출력 - !ls asdf 와 같음\n!rm 2022-09-08-rcmd_anal.csv - 현재 디렉토리에서 2022-09-08-rcmd_anal.csv 파일삭제; - rm ./2022-09-08-rcmd_anal.csv 와 같음\n!rm -rf asdf - 현재 디렉토리에서 asdf 삭제 (asdf 폴더내에 파일이 존재하면 파일도 같이 삭제) - r은 recursively, f는 force의 약자"
  },
  {
    "objectID": "posts/I. Overview/2022-09-19-Assignment1.html#appendix-ipynb---html-변환",
    "href": "posts/I. Overview/2022-09-19-Assignment1.html#appendix-ipynb---html-변환",
    "title": "Assignment 1",
    "section": "Appendix: ipynb -> html 변환",
    "text": "Appendix: ipynb -> html 변환\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-x3HQLeyrS7GLh70Dv_54Yg"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "",
    "text": "LSTM (2)– LSTM의 계산과정, LSTM은 왜 강한가?"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver1-with-torch.nn.lstmcell",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver1-with-torch.nn.lstmcell",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "1 epoch ver1 (with torch.nn.LSTMCell)",
    "text": "1 epoch ver1 (with torch.nn.LSTMCell)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt)\n    loss = loss / T\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver2-완전-손으로-구현",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver2-완전-손으로-구현",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "1 epoch ver2 (완전 손으로 구현)",
    "text": "1 epoch ver2 (완전 손으로 구현)\n\nt=0 \\(\\to\\) t=1\n- lstm_cell 을 이용한 계산 (결과비교용)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(1):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n이런결과를 어떻게 만드는걸까?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n- 직접계산\n\nht = torch.zeros(1,2)\nct = torch.zeros(1,2)\n\n\n_ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n\n\ninput_gate = sig(_ifgo[:,0:2])\nforget_gate = sig(_ifgo[:,2:4])\ngt = tanh(_ifgo[:,4:6])\noutput_gate = sig(_ifgo[:,6:8])\n\n\nct = forget_gate * ct + input_gate * gt\nht = output_gate * tanh(ct)\n\n\nht,ct\n\n(tensor([[-0.0541,  0.0892]], grad_fn=<MulBackward0>),\n tensor([[-0.1347,  0.2339]], grad_fn=<AddBackward0>))\n\n\n\n\nt=0 \\(\\to\\) t=T\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        \n        ## lstm_cell step1: calculate _ifgo \n        _ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n        ## lstm_cell step2: decompose _ifgo \n        input_gate = sig(_ifgo[:,0:2])\n        forget_gate = sig(_ifgo[:,2:4])\n        gt = tanh(_ifgo[:,4:6])\n        output_gate = sig(_ifgo[:,6:8])\n        ## lstm_cell step3: calculate ht,ct \n        ct = forget_gate * ct + input_gate * gt\n        ht = output_gate * tanh(ct)\n        \n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<MulBackward0>),\n tensor([[-0.0975,  0.7134]], grad_fn=<AddBackward0>))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver3-with-torch.nn.lstm",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch-ver3-with-torch.nn.lstm",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "1 epoch ver3 (with torch.nn.LSTM)",
    "text": "1 epoch ver3 (with torch.nn.LSTM)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2)\nlinr = torch.nn.Linear(2,3) \n\n\nlstm = torch.nn.LSTM(3,2) \n\n\nlstm.weight_hh_l0.data = lstm_cell.weight_hh.data \nlstm.bias_hh_l0.data = lstm_cell.bias_hh.data \nlstm.weight_ih_l0.data = lstm_cell.weight_ih.data \nlstm.bias_ih_l0.data = lstm_cell.bias_ih.data \n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters()) + list(linr.parameters()), lr=0.1) \n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    # ## step2\n    # loss = loss_fn(output,y) \n    # ## step3\n    # loss.backward()\n    # ## step4 \n    # optimizr.step()\n    # optimizr.zero_grad() \n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=<SqueezeBackward1>),\n tensor([[-0.0975,  0.7134]], grad_fn=<SqueezeBackward1>))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#data-abab-1",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#data-abab-1",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nn_words = 3\n\n\nmapping = {'a':0, 'b':1, 'B':2}\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:10],txt_y[:10]\n\n(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],\n ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.],\n         ...,\n         [1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.]]),\n tensor([[0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.],\n         ...,\n         [0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.]]))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#epoch",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "1000 epoch",
    "text": "1000 epoch\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(3,2) \nlinr = torch.nn.Linear(2,3) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1000): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## step2\n    loss = loss_fn(output,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#시각화",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#시각화",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "시각화",
    "text": "시각화\n\nT = len(x)\ninput_gate = torch.zeros(T,2)\nforget_gate = torch.zeros(T,2)\noutput_gate = torch.zeros(T,2)\ng = torch.zeros(T,2)\ncell = torch.zeros(T,2)\nh = torch.zeros(T,2) \n\n\nfor t in range(T): \n    ## 1: calculate _ifgo \n    _ifgo = x[[t]] @ lstm.weight_ih_l0.T + h[[t]] @ lstm.weight_hh_l0.T + lstm.bias_ih_l0 + lstm.bias_hh_l0 \n    ## 2: decompose _ifgo \n    input_gate[[t]] = sig(_ifgo[:,0:2])\n    forget_gate[[t]] = sig(_ifgo[:,2:4])\n    g[[t]] = tanh(_ifgo[:,4:6])\n    output_gate[[t]] = sig(_ifgo[:,6:8])\n    ## 3: calculate ht,ct \n    cell[[t]] = forget_gate[[t]] * cell[[t]] + input_gate[[t]] * g[[t]]\n    h[[t]] = output_gate[[t]] * tanh(cell[[t]])\n\n\ncombinded1 = torch.concat([input_gate,forget_gate,output_gate],axis=1)\ncombinded2 = torch.concat([g,cell,h,soft(output)],axis=1)\n\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n\n\n\n\n상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#시각화의-해석i",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#시각화의-해석i",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "시각화의 해석I",
    "text": "시각화의 해석I\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\n\n\n\n\n- input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.\n- 이 값들은 각각 모두 \\({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}, \\tanh({\\boldsymbol c}_t)\\)에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)\n\ninput_gate: \\({\\boldsymbol g}_t\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\nforget_gate: \\({\\boldsymbol c}_{t-1}\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\noutput_gate: \\(\\tanh({\\boldsymbol c}_t)\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\n\n\n시각화의 해석II\n\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n- 결국 \\({\\boldsymbol g}_t\\to {\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\to \\hat{\\boldsymbol y}\\) 의 느낌이다. (\\({\\boldsymbol h}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_t\\)가 필요했고 \\({\\boldsymbol c}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_{t-1}\\)과 \\({\\boldsymbol g}_t\\)가 필요했음)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol c}_t) \\odot {\\boldsymbol o}_t\\)\n\\({\\boldsymbol c}_t ={\\boldsymbol c}_{t-1} \\odot {\\boldsymbol f}_t + {\\boldsymbol g}_{t} \\odot {\\boldsymbol i}_t\\)\n\n- \\({\\boldsymbol g}_t,{\\boldsymbol c}_t,{\\boldsymbol h}_t\\) 모두 \\({\\boldsymbol x}_t\\)의 정보를 숙성시켜 가지고 있는 느낌이 든다.\n- \\({\\boldsymbol g}_t\\) 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})\\)\n\n- \\({\\boldsymbol c}_t\\) 특징: \\({\\boldsymbol g}_t\\)와 매우 비슷하지만 약간 다른값을 가진다. 그래서 \\({\\boldsymbol g}_t\\)와는 달리 -1,1 이외의 값도 종종 등장.\n\nprint(\"first row: gt={}, ct={}\".format(g[-8].data, cell[-8].data))\nprint(\"second row: gt={}, ct={}\".format(g[-7].data, cell[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])\n\n\n- \\({\\boldsymbol h}_t\\) 특징: (1) \\({\\boldsymbol c}_t\\)의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)\n\nprint(\"first row: gt={}, ct={}, ht={}\".format(g[-8].data, cell[-8].data,h[-8].data))\nprint(\"second row: gt={}, ct={}, ht={}\".format(g[-7].data, cell[-7].data,h[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])\n\n\n- 예전의문 해결\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#lstm의-알고리즘-리뷰-i-수식위주",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#lstm의-알고리즘-리뷰-i-수식위주",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "LSTM의 알고리즘 리뷰 I (수식위주)",
    "text": "LSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\({\\tt ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias\\)\n\\(=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\nifgo = xt @ lstm_cell.weight_ih.T +\\\n       ht @ lstm_cell.weight_hh.T +\\\n       lstm_cell.bias_ih + lstm_cell.bias_hh\n(step2) decompose \\({\\tt ifgo}\\) and get \\({\\boldsymbol i}_t\\), \\({\\boldsymbol f}_t\\), \\({\\boldsymbol g}_t\\), \\({\\boldsymbol o}_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )\\)\n\\({\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )\\)\n\\({\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )\\)\n\\({\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\({\\boldsymbol c}_t\\) and \\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)\\)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "LSTM의 알고리즘 리뷰 II (느낌위주)",
    "text": "LSTM의 알고리즘 리뷰 II (느낌위주)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..\n\n- 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.\n\n콩물: \\({\\boldsymbol x}_t\\)\n1차숙성: \\({\\boldsymbol g}_t\\)\n2차숙성: \\({\\boldsymbol c}_t\\)\n3차숙성: \\({\\boldsymbol h}_t\\)\n\n- 느낌2: \\({\\boldsymbol g}_t\\)에 대하여\n\n계산방법: \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)를 \\({\\bf W}_{ig}, {\\bf W}_{hg}\\)를 이용해 선형결합하고 \\(\\tanh\\)를 취한 결과\nRNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\)로 바꾼것\n크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 \\(\\tanh\\)를 적용\n\n- 느낌3: \\({\\boldsymbol c}_t\\)에 대하여 (1)\n\n계산방법: \\({\\boldsymbol g}_{t}\\)와 \\({\\boldsymbol c}_{t-1}\\)를 요소별로 선택하고 더하는 과정\n\\(g_t\\)는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈\n이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)\n\n- 느낌4: \\({\\boldsymbol c}_t\\)에 대하여 (2) // \\({\\boldsymbol c}_t\\)는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?\n\\(t=1\\) 시점 계산과정관찰\n\ninput_gate[1],g[1],forget_gate[1],cell[0]\n\n(tensor([0.9065, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.9999], grad_fn=<SelectBackward0>),\n tensor([0.9931, 0.0014], grad_fn=<SelectBackward0>),\n tensor([ 0.3592, -0.9373], grad_fn=<SelectBackward0>))\n\n\n\\([0.9,1.0] \\odot {\\boldsymbol g}_t + [1.0,0.0] \\odot {\\boldsymbol c}_{t-1}\\)\n\nforget_gate는 \\(c_{t-1}\\)의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(\\(c_{t-1}\\))의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.\ninput_gate는 \\(g_{t}\\)의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(\\(g_{t}\\))의 정보를 얼만큼 강하게 반영할지 결정한다.\n이 둘을 조합하면 \\({\\boldsymbol c}_t\\)가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.\n\n\n이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님\n\n- 느낌5: \\({\\boldsymbol c}_t\\)에 대하여 (3)\n\n사실상 LSTM 알고리즘의 꽃이라 할 수 있음.\nLSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.\nLSTM이 장기기억을 잘 활용하는 비법은 바로 \\({\\boldsymbol c}_t\\)에 있다.\n\n- 느낌6: \\({\\boldsymbol h}_t\\)에 대하여 - 계산방법: \\(\\tanh({\\boldsymbol c}_t)\\)를 요소별로 선택\n- RNN, LSTM의 변수들 비교 테이블\n\n\n\n\n\n\n\n\n\n\n\n\n\n과거정보\n현재정보\n과거와 현재의 결합방식\n활성화\n느낌\n비고\n\n\n\n\nRNN-\\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n간장\n\n\n\n\n\n\n\n\n\n\n\n\nLSTM-\\({\\boldsymbol g}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n1차간장\n\n\n\nLSTM-\\({\\boldsymbol c}_t\\)\n\\({\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol g}_t\\)\n\\(\\odot\\) \\(\\to\\) \\(+\\)\nNone\n2차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\nLSTM-\\({\\boldsymbol h}_t\\)\nNone\n\\({\\boldsymbol c}_t\\)\nNone\n\\(\\tanh\\), \\(\\odot\\)\n3차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\n\n\nRNN은 기억할 과거정보가 \\({\\boldsymbol h}_{t-1}\\) 하나이지만 LSTM은 \\({\\boldsymbol c}_{t-1}\\), \\({\\boldsymbol h}_{t-1}\\) 2개이다.\n\n- 알고리즘리뷰 :\n\n콩물,과거3차간장 \\(\\overset{\\times,+,\\tanh}{\\longrightarrow}\\) 현재1차간장\n현재1차간장, 과거2차간장 \\(\\overset{\\odot,+,\\tanh}{\\longrightarrow}\\) 현재2차간장\n현재2차간장 \\(\\overset{\\tanh,\\odot}{\\longrightarrow}\\) 현재3차간장\n\n\nLSTM이 강한이유\n- LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)\n\n- 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-17-12wk-1.html#참고자료들",
    "href": "posts/IV. RNN/2022-11-17-12wk-1.html#참고자료들",
    "title": "12wk-1: 순환신경망 (6)",
    "section": "참고자료들",
    "text": "참고자료들\n\nhttps://colah.github.io/posts/2015-08-Understanding-LSTMs/\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\nhttps://arxiv.org/abs/1402.1128"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "",
    "text": "순환신경망 intro (1)– ab예제, embedding layer"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#data",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#data",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "data",
    "text": "data\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#선형모형을-이용한-풀이",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#선형모형을-이용한-풀이",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "선형모형을 이용한 풀이",
    "text": "선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터정리\n\nx = torch.tensor(f(txt_x,{'a':0,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,{'a':0,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1),'y':y[:5].reshape(-1)})\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      0.0\n      1.0\n    \n    \n      1\n      1.0\n      0.0\n    \n    \n      2\n      0.0\n      1.0\n    \n    \n      3\n      1.0\n      0.0\n    \n    \n      4\n      0.0\n      1.0\n    \n  \n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\) 가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황\n\n\\((x_i,y_i)=(0,1)\\) 이면 어떠한 \\(\\hat{w}\\)를 선택해도 \\(y_i \\approx \\hat{w}x_i\\)를 만드는 것이 불가능\n\n\\((x_i,y_i)=(1,0)\\) 이면 \\(\\hat{w}=0\\)일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n\n\n(풀이2) 1개의 파라메터 – 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x,{'a':-1,'b':1})).float().reshape(-1,1) \ny = torch.tensor(f(txt_y,{'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다."
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#로지스틱-모형을-이용한-풀이",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#로지스틱-모형을-이용한-풀이",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "로지스틱 모형을 이용한 풀이",
    "text": "로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터를 다시 a=0, b=1로 정리\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임\n\n아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다.\n\\((x_i,y_i)=(0,1)\\) 이라면 어떠한 \\(\\hat{w}\\)을 선택해도 \\(\\hat{w}x_i=0\\) 이다. 이경우 \\(\\hat{y}_i = \\text{sig}(0) = 0.5\\) 가 된다.\n\\((x_i,y_i)=(1,0)\\) 이라면 \\(\\hat{w}=-5\\)와 같은 값으로 선택하면 \\(\\text{sig}(-5) \\approx 0 = y_i\\) 와 같이 만들 수 있다.\n상황을 종합하면 net의 weight는 \\(\\text{sig}(\\hat{w}x_i) \\approx 0\\) 이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-4.0070]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 – 성공\n- 동일하게 a=0, b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습후결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜초기값 – 성공\n- a=0, b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=<SliceBackward0>)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n결국 수렴하긴 할듯\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야 하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자)\n\n(예비학습1) net(x)와 사실 net.forwardx(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=<SliceBackward0>)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\nnet.forward = lambda x: 1 \n\n\n“lambda x: 1” 은 입력이 x 출력이 1인 함수를 의미 (즉 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1” 이라고 새롭게 선언하였므로 앞으론 net.forward(x), net(x) 도 입력값에 상관없이 항상 1을 출력하게 될 것임\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet1()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet2()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.RuLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet3()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        \n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x) 함수의 리턴값임\n사실, x/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstep2: def __init__(self):에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x –> yhat” 으로 가는 과정을 묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x) \n        v = self.xxx2(u)\n        yhat = self.xxx3(v) \n        ## 정의 끝\n        return yhat\n예비학습 끝\n\n- 우리가 하려고 했던 것: 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과2(ReLU): RuLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n- 실험해석 - sig: 주황색선의 변동폭이 작음 + 항상 0.5근처로 머무는 적합값이 존재 - relu: 주황색선의 변동폭이 큼 + 항상 0.5근처로 머무는 적합값이 존재 - tanh: 주황색선의 변동폭이 큼 + 0.5근처로 머무는 적합값이 존재X\n- 실험해보니까 tanh가 우수한것 같다. \\(\\to\\) 앞으로는 tanh를 쓰자."
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#소프트맥스로-확장",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#소프트맥스로-확장",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "소프트맥스로 확장",
    "text": "소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0],'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5],y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2,bias=False)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5][:,0]\n\ntensor([0., 1., 0., 1., 0.])\n\n\n\nplt.plot(y[:5][:,1],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f2633e40f90>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#motive",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#motive",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "motive",
    "text": "motive\n- 결국 최종적으로는 아래와 같은 맵핑방식이 확장성이 있어보인다.\n\nmapping = {'a':[1,0,0],'b':[0,1,0],'c':[0,0,1]} # 원핫인코딩 방식 \n\n- 그런데 매번 \\(X\\)를 원핫인코딩하고 Linear 변환하는것이 번거로운데 이를 한번에 구현하는 함수가 있으면 좋겠다. \\(\\to\\) torch.nn.Embedding Layer가 그 역할을 한다.\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(list('abc')*100,mapping))\ny = torch.tensor(f(list('bca')*100,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(num_embeddings=3,embedding_dim=1)\n\n\nebdd(x)[:5]\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=<SliceBackward0>)\n\n\n- 그런데 사실 언뜻보면 아래의 linr 함수와 역할의 차이가 없어보인다.\n\ntorch.manual_seed(43052)\nlinr = torch.nn.Linear(in_features=1,out_features=1)\n\n\nlinr(x.float().reshape(-1,1))[:5]\n\ntensor([[-0.8470],\n        [-1.1937],\n        [-1.5404],\n        [-0.8470],\n        [-1.1937]], grad_fn=<SliceBackward0>)\n\n\n- 차이점: 파라메터수에 차이가 있다.\n\nebdd.weight\n\nParameter containing:\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843]], requires_grad=True)\n\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n결국 ebdd는 아래의 구조에 해당하는 파라메터들이고\n\n\\(\\text{x[:5]}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\Longrightarrow \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix} \\quad net(x)= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix} = \\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052 \\end{bmatrix}\\)\n\nlinr는 아래의 구조에 해당하는 파라메터이다.\n\n\\(\\text{x[:5]}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\quad net(x)= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-01-9wk-2.html#연습-ab문제-소프트맥스로-확장한-것-다시-풀이",
    "href": "posts/IV. RNN/2022-11-01-9wk-2.html#연습-ab문제-소프트맥스로-확장한-것-다시-풀이",
    "title": "09wk-2: 순환신경망 (1)",
    "section": "연습 (ab문제 소프트맥스로 확장한 것 다시 풀이)",
    "text": "연습 (ab문제 소프트맥스로 확장한 것 다시 풀이)\n- 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))\n\n\n- torch.nn.Embedding 을 넣은 네트워크\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=2,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nplt.imshow(soft(net(x[:5])).data)\n\n<matplotlib.image.AxesImage at 0x7f2633f7f450>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "",
    "text": "LSTM (1)– GPU실험, abcabC예제, abcdabcD예제"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "20000 len + 20 hidden nodes",
    "text": "20000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n93.01761960983276\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n3.2665085792541504\n\n\n\n왜 빠른지?"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-역전파주석처리",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-역전파주석처리",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "20000 len + 20 hidden nodes + 역전파주석처리",
    "text": "20000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n18.851768255233765\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2901742458343506"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-1",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-1",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "2000 len + 20 hidden nodes",
    "text": "2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.533619165420532\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.7532594203948975"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-역전파주석처리-1",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-20-hidden-nodes-역전파주석처리-1",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "2000 len + 20 hidden nodes + 역전파주석처리",
    "text": "2000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2477965354919434\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.14130854606628418"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-5000-hidden-nodes",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-5000-hidden-nodes",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "2000 len + 5000 hidden nodes",
    "text": "2000 len + 5000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n58.99820685386658\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.7596595287323"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#len-5000-hidden-nodes-역전파주석처리",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#len-5000-hidden-nodes-역전파주석처리",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "2000 len + 5000 hidden nodes + 역전파주석처리",
    "text": "2000 len + 5000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n13.163657188415527\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.2989864349365234"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#실험결과-요약",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#실험결과-요약",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "실험결과 요약",
    "text": "실험결과 요약\n\n\n\nlen\n# of hidden nodes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n93.02\n3.26\n28.53\n\n\n20000\n20\nX\n18.85\n1.29\n14.61\n\n\n2000\n20\nO\n6.53\n0.75\n8.70\n\n\n2000\n20\nX\n1.25\n0.14\n8.93\n\n\n2000\n1000\nO\n58.99\n4.75\n12.41\n\n\n2000\n1000\nX\n13.16\n2.29\n5.74"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#data",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#data",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "data",
    "text": "data\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "RNN",
    "text": "RNN\n\ntorch.manual_seed(43052) \nrnn = torch.nn.RNN(4,3) \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+ list(linr.parameters()))\n\n\nrnn.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e032f890>\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e1078b90>\n\n\n\n\n\n- 9000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e0358590>\n\n\n\n\n\n- 12000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47e2de6f10>\n\n\n\n\n\n- 15000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7f47cc12ae50>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#lstm",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#lstm",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "LSTM",
    "text": "LSTM\n- LSTM\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,3) \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()))\n\n\nlstm.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f47cc0608d0>\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7f47c61dd750>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn-vs-lstm-성능비교실험",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn-vs-lstm-성능비교실험",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#data-1",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#data-1",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "data",
    "text": "data\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'c':2, 'd':3, 'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn-vs-lstm-성능비교실험-1",
    "href": "posts/IV. RNN/2022-11-15-11wk-2.html#rnn-vs-lstm-성능비교실험-1",
    "title": "11wk-2: 순환신경망 (5)",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임."
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "",
    "text": "LSTM (2)– 순환신경망 표현력 비교실험, 문자열에서 단어로"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#data-abcabc",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#data-abcabc",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "data: abcabC",
    "text": "data: abcabC\n\ntxt = list('abcabC')*100\ntxt[:8]\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#실험",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#실험",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 4\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험3\n\nHIDDEN = 8\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,8))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment3: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#결론",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#결론",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "결론",
    "text": "결론\n- 노드수가 많으면 학습에 유리함"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#data-abcc",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#data-abcc",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "data: ab(c,C)",
    "text": "data: ab(c,C)\n\n# torch.manual_seed(43052)\n# txta = 'a'*50\n# txtb = 'b'*50\n# prob_upper = torch.bernoulli(torch.zeros(50)+0.5) \n# txtc = list(map(lambda x: 'c' if x==1 else 'C', prob_upper))\n# txt = ''.join([txta[i]+','+txtb[i]+','+txtc[i]+',' for i in range(50)]).split(',')[:-1]\n# txt_x = txt[:-1] \n# txt_y = txt[1:]\n# pd.DataFrame({'txt_x':txt_x,'txt_y':txt_y}).to_csv(\"2022-11-25-ab(c,C).csv\",index=False)\n\n\ndf= pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-ab(c%2CC).csv\")\ndf\n\n\n\n\n\n  \n    \n      \n      txt_x\n      txt_y\n    \n  \n  \n    \n      0\n      a\n      b\n    \n    \n      1\n      b\n      c\n    \n    \n      2\n      c\n      a\n    \n    \n      3\n      a\n      b\n    \n    \n      4\n      b\n      c\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      144\n      a\n      b\n    \n    \n      145\n      b\n      C\n    \n    \n      146\n      C\n      a\n    \n    \n      147\n      a\n      b\n    \n    \n      148\n      b\n      c\n    \n  \n\n149 rows × 2 columns\n\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(df.txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(df.txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#실험-1",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#실험-1",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 16\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#결론-1",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#결론-1",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "결론",
    "text": "결론\n- 노드수가 너무 많으면 오버피팅 경향도 있음"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#data-human-numbers-5",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#data-human-numbers-5",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#torch를-이용한-learn",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#torch를-이용한-learn",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\nHIDDEN = 20\n\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(6,HIDDEN).to(\"cuda:0\")\nlinr = torch.nn.Linear(HIDDEN,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n_water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\nfor epoc in range(500):\n    ## 1\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nsoft(output).data[-10:].to(\"cpu\")\n\ntensor([[9.9999e-01, 3.9119e-06, 3.0788e-08, 5.8943e-06, 8.8143e-09, 1.3331e-07],\n        [8.5938e-08, 9.9985e-01, 6.4028e-05, 3.1530e-05, 6.9832e-06, 4.5028e-05],\n        [9.9999e-01, 7.3703e-08, 1.2404e-06, 1.9506e-07, 1.1338e-06, 8.8255e-06],\n        [1.9159e-08, 2.4035e-07, 9.9997e-01, 6.6191e-06, 8.3475e-06, 1.1663e-05],\n        [1.0000e+00, 5.3941e-08, 7.1640e-08, 5.5608e-07, 7.2524e-08, 8.5960e-08],\n        [1.6338e-07, 4.2633e-05, 3.8213e-05, 9.9990e-01, 4.0797e-09, 2.3639e-05],\n        [9.9999e-01, 4.6589e-08, 5.8341e-10, 1.2804e-07, 7.0116e-06, 3.6203e-07],\n        [3.1322e-06, 6.1328e-06, 1.2816e-05, 6.0362e-10, 9.9997e-01, 1.2343e-05],\n        [9.9999e-01, 8.8293e-08, 1.0380e-06, 3.5568e-07, 3.3849e-06, 2.7604e-06],\n        [8.2612e-08, 1.1319e-04, 1.1417e-05, 7.7150e-06, 3.7089e-06, 9.9986e-01]])\n\n\n\nplt.matshow(soft(output).data[-10:].to(\"cpu\"),cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7efc22791d50>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-22-12wk-2.html#fastai를-이용한-learn",
    "href": "posts/IV. RNN/2022-11-22-12wk-2.html#fastai를-이용한-learn",
    "title": "12wk-2: 순환신경망 (7)",
    "section": "fastai를 이용한 learn",
    "text": "fastai를 이용한 learn\n\nfrom fastai.text.all import *\n\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=8) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=8) # dummy\ndls = DataLoaders(dl1,dl2) \n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = torch.nn.LSTM(6,HIDDEN)\n        self.linr = torch.nn.Linear(HIDDEN,6)\n    def forward(self,x):\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        hidden, (hT,cT)  = self.lstm(x,(_water,_water))\n        output = self.linr(hidden) \n        return output\n\n\nnet = MyLSTM()\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn)\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      1.552394\n      1.481384\n      00:00\n    \n    \n      1\n      1.142831\n      0.923131\n      00:00\n    \n    \n      2\n      0.758790\n      0.630345\n      00:00\n    \n    \n      3\n      0.446162\n      0.338486\n      00:00\n    \n    \n      4\n      0.227327\n      0.159498\n      00:00\n    \n    \n      5\n      0.104717\n      0.072119\n      00:00\n    \n    \n      6\n      0.048809\n      0.034304\n      00:00\n    \n    \n      7\n      0.023731\n      0.017093\n      00:00\n    \n    \n      8\n      0.012051\n      0.008876\n      00:00\n    \n    \n      9\n      0.006350\n      0.004759\n      00:00\n    \n  \n\n\n\n\nplt.matshow(soft(lrnr.model(x)).data.to(\"cpu\")[-10:],cmap='bwr',vmin=-1,vmax=1)\n\n<matplotlib.image.AxesImage at 0x7efb9552fd50>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "",
    "text": "RNN (1)– AbAcAd예제(2)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#data",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#data",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번엔 원핫인코딩형태까지 미리 정리하자. (임베딩 레이어 안쓸예정)\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#실패했던-풀이-구현1",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#실패했던-풀이-구현1",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "실패했던 풀이: 구현1",
    "text": "실패했던 풀이: 구현1\n- 저번시간의 실패한 풀이\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n- Tanh까지만 클래스로 바꾸어서 구현\n\n클래스를 이용하는 방법: https://guebin.github.io/DL2022/2022/11/01/(9주차)-11월1일.html#로지스틱-모형을-이용한-풀이\n\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,x):\n        hidden = self.tanh(self.i2h(x))\n        return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#실패했던-풀이-구현2",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#실패했던-풀이-구현2",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "실패했던 풀이: 구현2",
    "text": "실패했던 풀이: 구현2\n- Tanh까지 구현한 클래스\n\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회 반복\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt) \n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 <– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=<AddmmBackward0>)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망의-아이디어",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망의-아이디어",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "순환신경망의 아이디어",
    "text": "순환신경망의 아이디어\n\n모티브\n(예비생각1) \\({\\boldsymbol h}\\)에 대한 이해\n\\({\\boldsymbol h}\\)는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다) - (why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능 - (why2) 실제로 예시를 살펴보면 그러했다.\n결론: 사실 \\({\\boldsymbol h}\\)는 잘 숙성되어있는 입력정보 \\({\\bf X}\\) 그 자체로 해석 할 수 있다.\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듬\n* 기존방식 - \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함\n* 알고리즘의 편의상 아래와 같이 생각해도 무방\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\), \\(\\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1) “\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_t\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_t\\)”로 “\\(\\text{간장계란밥}_t\\)를 조리하는 방법이다\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘 (\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n(1) \\(t=0\\)\n\\({\\boldsymbol h}_0=[[0,0]]\\) <– \\(\\text{간장}_0\\)은 맹물로 초기화\n(2) \\(t=1\\)\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\) - \\({\\boldsymbol x}_1\\): (1,4) - \\({\\bf W}_{ih}\\): (4,2) - \\({\\boldsymbol h}_0\\): (1,2) - \\({\\bf W}_{hh}\\): (2,2) - \\({\\boldsymbol b}_{ih}\\): (1,2) - \\({\\boldsymbol b}_{hh}\\): (1,2)\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n(3) \\(t=2\\) <– 여기서부터는 \\(t=2\\)와 비슷\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden))\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n\n전체알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망-구현1-with-rnncell-class-hidden-node-2-성공",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망-구현1-with-rnncell-class-hidden-node-2-성공",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "순환신경망 구현1 (with rNNCell class, hidden node 2) – 성공",
    "text": "순환신경망 구현1 (with rNNCell class, hidden node 2) – 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f99cd09c4d0>\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[:-15] 의 적합결과가 다르다\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까.."
  },
  {
    "objectID": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망-구현2-with-rnncell-hidden-node-2-성공",
    "href": "posts/IV. RNN/2022-11-08-10wk-2.html#순환신경망-구현2-with-rnncell-hidden-node-2-성공",
    "title": "10wk-2: 순환신경망 (3)",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2) – 성공",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2) – 성공\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2)\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n<matplotlib.image.AxesImage at 0x7f99ce91b850>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "",
    "text": "순환신경망 intro (2)– abc예제, abdc예제, AbAcAd예제(1)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#data",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#data",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#하나의-은닉노드를-이용한-풀이-억지로-성공",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#하나의-은닉노드를-이용한-풀이-억지로-성공",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 – 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=1),\n    torch.nn.Tanh(),\n    #===#\n    torch.nn.Linear(in_features=1,out_features=3)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과해석\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nplt.plot(hidden[:9],'--o')\n\n\n\n\n\nplt.plot(net(x).data[:9],'--o')\n\n\n\n\n\nplt.plot(yhat[:9],'--o')\n\n\n\n\n\n억지로 맞추고있긴한데 파라메터가 부족해보인다.\n\n- 결과시각화1\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\nhidden[:9], (net[-1].weight.data).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]]),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\nhidden[:9]@(net[-1].weight.data).T + net[-1].bias.data\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312]])\n\n\n\n(파랑,주황,초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143)\n초록 = hidden * (5.2894) + (-1.3970)\n\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음.\n\nweight: 파랑과 초록을 구분하는 역할을 함\nweight + bias: 뭔가 교모하게 애매한 주황값을 만들어서 애매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려 맞추는 느낌, 쓸수있는 weight가 한정적이라서 생기는 현상 (양수,음수,0)\n\n\n참고: torch.nn.Linear()의 비밀?\n\n사실 \\({\\boldsymbol y}={\\boldsymbol x}{\\bf W} + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf W}\\)와 \\({\\boldsymbol b}\\)가 저장되는게 아니다.\n\\({\\boldsymbol y}={\\boldsymbol x}{\\bf A}^T + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf A}\\)와 \\({\\boldsymbol b}\\)가 저장된다.\n\\({\\bf W} = {\\bf A}^T\\) 인 관계에 있으므로 l1.weight 가 우리가 생각하는 \\({\\bf W}\\) 로 해석하려면 사실 transpose를 취해줘야 한다.\n\n왜 이렇게..?\n\n계산의 효율성 때문 (numpy의 구조를 알아야함)\n\\({\\boldsymbol x}\\), \\({\\boldsymbol y}\\) 는 수학적으로는 col-vec 이지만 메모리에 저장할시에는 row-vec 로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)\n\n잠깐 딴소리!!\n(예시1)\n\n_arr = np.array(range(4)).reshape(2,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시2)\n\n_arr = np.array(range(6)).reshape(3,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시3)\n\n_arr = np.array(range(6)).reshape(2,3)\n\n\n_arr.strides\n\n(24, 8)\n\n\n\n아래로 한칸 = 24칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시4)\n\n_arr = np.array(range(4),dtype=np.int8).reshape(2,2)\n\n\n_arr\n\narray([[0, 1],\n       [2, 3]], dtype=int8)\n\n\n\n_arr.strides\n\n(2, 1)\n\n\n\n아래로한칸 = 2칸 (= 2바이트 jump = 16비트 jump)\n오른쪽으로 한칸 = 1칸 jump (= 1바이트 jump = 8비트 jump)\n\n진짜 참고..\n\n1바이트 = 8비트\n1바이트는 2^8=256 의 정보 표현\nnp.int8은 8비트로 정수를 저장한다는 의미\n\n\n2**8\n\n256\n\n\n\nprint(np.array(55,dtype=np.int8))\nprint(np.array(127,dtype=np.int8))\nprint(np.array(300,dtype=np.int8)) # overflow \n\n55\n127\n44\n\n\n딴소리 끝!!\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([299, 7])\n\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#data-1",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#data-1",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#하나의-은닉노드를-이용한-풀이-억지로-성공-1",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#하나의-은닉노드를-이용한-풀이-억지로-성공-1",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "하나의 은닉노드를 이용한 풀이 – 억지로 성공",
    "text": "하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#두개의-은닉노드를-이용한-풀이-깔끔한-성공",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#두개의-은닉노드를-이용한-풀이-깔끔한-성공",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 – 깔끔한 성공",
    "text": "두개의 은닉노드를 이용한 풀이 – 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#data-2",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#data-2",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "data",
    "text": "data\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-03-10wk-1.html#두개의-은닉노드를-이용한-풀이-실패",
    "href": "posts/IV. RNN/2022-11-03-10wk-1.html#두개의-은닉노드를-이용한-풀이-실패",
    "title": "10wk-1: 순환신경망 (2)",
    "section": "두개의 은닉노드를 이용한 풀이 – 실패",
    "text": "두개의 은닉노드를 이용한 풀이 – 실패\n- 데이터정리\n\nmapping = {'A':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n실패\n\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nX\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n…\n…\n\n\n\n- 순진한 접근방식의 비판: - 결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조 - 만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함. - 그리고 실전에서는 직전 몇개의 문자를 봐야하는지 모름.\n이것에 대한 해결책은 순환신경망이다. 다음시간에 설명"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-10-11wk-1.html",
    "href": "posts/IV. RNN/2022-11-10-11wk-1.html",
    "title": "11wk-1: 순환신경망 (4)",
    "section": "",
    "text": "RNN (2)– AbAcAd예제(3)"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-10-11wk-1.html#data",
    "href": "posts/IV. RNN/2022-11-10-11wk-1.html#data",
    "title": "11wk-1: 순환신경망 (4)",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "href": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "title": "11wk-1: 순환신경망 (4)",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2)",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2)\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\nrnncell = torch.nn.RNNCell(4,2) # x:(n,4) h:(n,2) \n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nhidden = torch.zeros(T,2) \n\n\n# t=0 \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\n# t=1~T \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7702e-02, 1.3384e-02],\n        [2.0031e-02, 1.0660e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n\nplt.matshow(yhat[:15].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67cda0910>\n\n\n\n\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c28ff90>"
  },
  {
    "objectID": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "href": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "title": "11wk-1: 순환신경망 (4)",
    "section": "순환신경망 구현3 (with RNN, hidden node 2) – 성공",
    "text": "순환신경망 구현3 (with RNN, hidden node 2) – 성공\n(예비학습)\n- 네트워크학습이후 yhat을 구하려면 번거로웠음\nhidden = torch.zeros(T,2) \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\nyhat = soft(cook(hidden))\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2)\n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data \nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\nrnn(x,_water), hidden\n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          ...,\n          [-0.9935, -0.9315],\n          [ 0.5777, -1.0000],\n          [-0.9960, -0.0109]], grad_fn=<SqueezeBackward1>),\n  tensor([[-0.9960, -0.0109]], grad_fn=<SqueezeBackward1>)),\n tensor([[-0.9912, -0.9117],\n         [ 0.0698, -1.0000],\n         [-0.9927, -0.9682],\n         ...,\n         [-0.9935, -0.9315],\n         [ 0.5777, -1.0000],\n         [-0.9960, -0.0109]], grad_fn=<IndexPutBackward0>))\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7702e-02, 1.3384e-02],\n        [2.0031e-02, 1.0660e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=<SoftmaxBackward0>)\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\nrnn = torch.nn.RNN(4,2)\n\n가중치초기화\n\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(4,2)\n\n\nrnn.weight_hh_l0.data = _rnncell.weight_hh.data \nrnn.weight_ih_l0.data = _rnncell.weight_ih.data\nrnn.bias_hh_l0.data = _rnncell.bias_hh.data\nrnn.bias_ih_l0.data = _rnncell.bias_ih.data\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,2) \nfor epoc in range(5000):\n    ## 1 \n    hidden,hT = rnn(x,_water)\n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat.data[:15],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c231310>\n\n\n\n\n\n\n처음은 좀 틀렸음 ㅎㅎ\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c1c5d90>\n\n\n\n\n\n\n뒤에는 잘맞음\n\n실전팁: _water 대신에 hT를 대입 (사실 큰 차이는 없음)\n\nrnn(x[:6],_water),rnn(x[:6],hT)\n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          [ 0.5761, -1.0000],\n          [-0.9960, -0.0173],\n          [ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>),\n  tensor([[ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>)),\n (tensor([[-0.9713, -1.0000],\n          [ 0.0535, -1.0000],\n          [-0.9925, -0.9720],\n          [ 0.5759, -1.0000],\n          [-0.9960, -0.0180],\n          [ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>),\n  tensor([[ 0.9960, -1.0000]], grad_fn=<SqueezeBackward1>)))\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c13b7d0>\n\n\n\n\n\n\n히든노드의 해석이 어려움."
  },
  {
    "objectID": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "href": "posts/IV. RNN/2022-11-10-11wk-1.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "title": "11wk-1: 순환신경망 (4)",
    "section": "순환신경망 구현4 (with RNN, hidden node 3) – 성공",
    "text": "순환신경망 구현4 (with RNN, hidden node 3) – 성공\n(1) 숙성네트워크~ (2) 조리네트워크\n\ntorch.manual_seed(2) #1 \nrnn = torch.nn.RNN(4,3) \ncook = torch.nn.Linear(3,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,3) \nfor epoc in range(5000):\n    ## 1\n    hidden,hT = rnn(x,_water) \n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe67c04f550>\n\n\n\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n<matplotlib.image.AxesImage at 0x7fe6747ba910>\n\n\n\n\n\n\n세번째 히든노드 = 대소문자를 구분\n1,2 히든노드 = bcd를 구분"
  },
  {
    "objectID": "posts/2022-11-29-13wk-2-final.html",
    "href": "posts/2022-11-29-13wk-2-final.html",
    "title": "final",
    "section": "",
    "text": "기말고사"
  },
  {
    "objectID": "posts/2022-11-29-13wk-2-final.html#hihello-90점",
    "href": "posts/2022-11-29-13wk-2-final.html#hihello-90점",
    "title": "final",
    "section": "1. hihello (90점)",
    "text": "1. hihello (90점)\n아래와 같은 데이터가 있다고 하자.\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['h', 'i', '?', 'h', 'e'], ['i', '?', 'h', 'e', 'l'])\n\n\ntxt_x와 txt_y를 이용하여 아래와 같은 순서로 다음문자를 예측하고 싶은 신경망을 설계하고 싶다.\nh \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) l \\(\\to\\) l \\(\\to\\) o \\(\\to\\) ! \\(\\to\\) ! \\(\\to\\) h \\(\\to\\) \\(\\dots\\)\n(1) torch.nn.RNN()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(2) torch.nn.RNNCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(3) torch.nn.Module을 상속받은 클래스를 정의하고 (2)의 결과와 동일한 적합값이 나오는 신경망을 설계한 뒤 학습하라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않으면 점수없음.\ntorch.nn.RNN(), torch.nn.RNNCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.RNN(), torch.nn.RNNCell()을 코드에 포함시키는 것이 가능)\n\n(4) torch.nn.LSTM()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(5) torch.nn.LSTMCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(6) (5)의 결과와 동일한 적합값을 출력하는 직접설계한 뒤 학습시켜라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않아도 무방함.\ntorch.nn.LSTM(), torch.nn.LSTMCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.LSTM(), torch.nn.LSTMCell()을 코드에 포함시키는 것이 가능)\n\n\n적절한 히든노드수를 선택할 것"
  },
  {
    "objectID": "posts/2022-11-29-13wk-2-final.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "href": "posts/2022-11-29-13wk-2-final.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "title": "final",
    "section": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)",
    "text": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)\n(1) RNN은 LSTM에 비하여 장기기억에 유리한 장점이 있다.\n(2)\n(3)\n(4)\n(5)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "",
    "text": "로지스틱(2)– 로지스틱 네트워크설계 및 학습, 손실함수의 비교: BCE loss의 위대함"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#motive",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#motive",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "motive",
    "text": "motive\n- 현실에서 이런 경우가 많음\n\n\\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 증가함.\n\n- (X,y)는 어떤모양?\n\n_df = pd.DataFrame({'x':range(-6,7),'y':[0,0,0,0,0,0,1,0,1,1,1,1,1]})\n_df \n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -6\n      0\n    \n    \n      1\n      -5\n      0\n    \n    \n      2\n      -4\n      0\n    \n    \n      3\n      -3\n      0\n    \n    \n      4\n      -2\n      0\n    \n    \n      5\n      -1\n      0\n    \n    \n      6\n      0\n      1\n    \n    \n      7\n      1\n      0\n    \n    \n      8\n      2\n      1\n    \n    \n      9\n      3\n      1\n    \n    \n      10\n      4\n      1\n    \n    \n      11\n      5\n      1\n    \n    \n      12\n      6\n      1\n    \n  \n\n\n\n\n\nplt.plot(_df.x,_df.y,'o')\n\n\n\n\n- (예비학습) 시그모이드라는 함수가 있음\n\n_x = torch.linspace(-6,6,100)\ndef f(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(_df.x,_df.y,'o')\nplt.plot(_x,f(_x))\n\n\n\n\n\nmodel\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 <— 외우세요!!!\n\n\\(y_i \\sim Ber(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) <— 외우세요!!\n\n\n\ntoy example\n- 예제시작\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\n\n\n\n\n\n우리의 목적: \\(x\\)가 들어가면 빨간선 \\(\\hat{y}\\)의 값을 만들어주는 mapping을 학습해보자."
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#net-설계",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#net-설계",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "net 설계",
    "text": "net 설계\n- 최초곡선\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nw0hat = -0.8470\nw1hat = -0.3467 \nplt.plot(x,f(x*w1hat+w0hat),'--b')\n\n\n\n\n- f 대신에 torch.nn.Sigmoid() 사용해서 함수만들어도 무방\n\na1 = torch.nn.Sigmoid()\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nw0hat = -0.8470\nw1hat = -0.3467 \nplt.plot(x,a1(x*w1hat+w0hat),'--b')\n\n\n\n\n- x*w1hat + w0hat 대신에 torch.nn.Linear() 로 써도 무방\n\ntorch.manual_seed(43052) \nl1=torch.nn.Linear(in_features=1,out_features=1,bias=True) \n\n\nl1.weight\n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nl1.bias\n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,a1(l1(x)).data,'--b')\n\n\n\n\n- 지금 \\(x \\overset{l1}{\\to} u \\overset{a1}{\\to} v = \\hat{y}\\) 구조임\n- l1,a1 을 sequential 하게 (직렬로) 엮어서 $ x $ 로 만들수 없을까?\n\nnet = torch.nn.Sequential(l1,a1) \n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x).data,'--b')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#학습",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#학습",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "학습",
    "text": "학습\n- 이제 옵티마이저 설계하고 학습하자.\n\noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n- step1~4\n(1000번 학습)\n\nfor epoc in range(1000): \n    ## 1 \n    yhat= net(x) \n    ## 2 \n    loss= torch.mean((y-yhat)**2) ## loss가 사실 이러면 안됩니다.. ㅠㅠ \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x).data,'--b')\n\n\n\n\n(5000번 추가학습)\n\nfor epoc in range(5000): \n    ## 1 \n    yhat= net(x) \n    ## 2 \n    loss= torch.mean((y-yhat)**2) ## 사실 이러면 안됩니다.. ㅠㅠ \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,net(x).data,'--b')\n\n\n\n\n.. 성공?"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#mse-loss-와-bce-loss-의-비교",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#mse-loss-와-bce-loss-의-비교",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "MSE loss 와 BCE loss 의 비교",
    "text": "MSE loss 와 BCE loss 의 비교\n- loss_fn1, loss_fn2\n\ndef loss_fn1(y,yhat): \n    return torch.mean((y-yhat)**2)\n\n\ndef loss_fn2(y,yhat):\n    return -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n\n- loss_fn1(MSE), SGD, lr=0.05\n\ntorch.manual_seed(43052) \nnet = torch.nn.Sequential(torch.nn.Linear(1,1),torch.nn.Sigmoid()) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \nfor epoc in range(1000): \n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn1(y,yhat)\n    ## step3\n    loss.backward() \n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- loss_fn2(BCE), SGD, lr=0.05\n\ntorch.manual_seed(43052) \nnet = torch.nn.Sequential(torch.nn.Linear(1,1),torch.nn.Sigmoid()) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \nfor epoc in range(1000): \n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn2(y,yhat)\n    ## step3\n    loss.backward() \n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n!! loss_fn2 로 하니까 더 잘맞는다?\n?? 왜?????\n- 손실함수의 모양이 다르다..\n\nfig = plt.figure()\nax1=fig.add_subplot(1,2,1,projection='3d')\nax2=fig.add_subplot(1,2,2,projection='3d')\nax1.elev=15;ax2.elev=15;ax1.azim=75;ax2.azim=75\nfig.set_figheight(8)\nfig.set_figwidth(8)\n\n\n\n\n\ndef plot_loss(loss_fn,ax):\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.15),torch.arange(-1,10,0.15),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(y,yhat) \n    loss = list(map(l,w0hat,w1hat))\n    ax.scatter(w0hat,w1hat,loss,s=0.1,alpha=0.2) \n    ax.scatter(-1,5,l(-1,5),s=200,marker='*') # 실제로 -1,5에서 최소값을 가지는건 아님.. \n\n\nplot_loss(loss_fn1,ax1)\nplot_loss(loss_fn2,ax2)\nax1.set_title('MSE loss')\nax2.set_title('BCE loss')\nfig\n\n\n\n\n\n왼쪽 그림은 손실함수가 convex 하지 않다.\n오른쪽 그림은 손실함수가 convex 하다."
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#시각화를-위한-준비함수들",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#시각화를-위한-준비함수들",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "시각화를 위한 준비함수들",
    "text": "시각화를 위한 준비함수들\n준비1: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수를 만들자!\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    what_history = [] \n\n    for epoc in range(1000): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(y,yhat)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad() \n\n        ## record \n        if epoc % 20 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            what_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    return yhat_history, loss_history, what_history\n\n준비2: 애니메이션을 만들어주는 함수를 만들자!\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\ndef show_lrpr2(net,loss_fn,optimizr,suptitle=''):\n    yhat_history,loss_history,what_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7,2.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ax1.set_xticks([]);ax1.set_yticks([])\n    ax2.set_xticks([]);ax2.set_yticks([]);ax2.set_zticks([])\n    ax2.elev = 15; ax2.azim = 75\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,v,'--')\n    ax1.scatter(x,y,alpha=0.05)\n    line, = ax1.plot(x,yhat_history[0],'--') \n    plot_loss(loss_fn,ax2)\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(what_history)[epoc,0],np.array(what_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#시각화1-mse-loss-sgd-좋은초기값",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#시각화1-mse-loss-sgd-좋은초기값",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "시각화1: MSE loss, SGD, 좋은초기값",
    "text": "시각화1: MSE loss, SGD, 좋은초기값\n\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid()\nnet = torch.nn.Sequential(l1,a1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn1,optimizr,'MSEloss, SGD, good_init')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#시각화2-bce-loss-sgd-좋은초기값",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#시각화2-bce-loss-sgd-좋은초기값",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "시각화2: BCE loss, SGD, 좋은초기값",
    "text": "시각화2: BCE loss, SGD, 좋은초기값\n\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid()\nnet = torch.nn.Sequential(l1,a1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn2,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#시각화3-mse-loss-sgd-나쁜초기값",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#시각화3-mse-loss-sgd-나쁜초기값",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "시각화3: MSE loss, SGD, 나쁜초기값",
    "text": "시각화3: MSE loss, SGD, 나쁜초기값\n\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid()\nnet = torch.nn.Sequential(l1,a1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn1,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-29-5wk-1.html#시각화4-bce-loss-sgd-나쁜초기값",
    "href": "posts/II. DNN/2022-09-29-5wk-1.html#시각화4-bce-loss-sgd-나쁜초기값",
    "title": "05wk-1: 딥러닝의 기초 (4)",
    "section": "시각화4: BCE loss, SGD, 나쁜초기값 (?)",
    "text": "시각화4: BCE loss, SGD, 나쁜초기값 (?)\n\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid()\nnet = torch.nn.Sequential(l1,a1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn2,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "",
    "text": "깊은신경망(2)– 시벤코정리, MNIST with DNN"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#지난시간-논리전개",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#지난시간-논리전개",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "지난시간 논리전개",
    "text": "지난시간 논리전개\n- 아이디어: linear -> relu -> linear (-> sigmoid) 조합으로 꺽은선으로 표현되는 underlying 을 표현할 수 있었다.\n\n아이디어의 실용성: 실제자료에서 꺽은선으로 표현되는 underlying은 몇개 없을 것 같음. 그건 맞는데 꺽이는 점을 많이 설정하면 얼추 비슷하게는 “근사” 시킬 수 있음.\n아이디어의 확장성: 이러한 논리전개는 X:(n,2)인 경우도 가능했음. (이 경우 꺽인선은 꺽인평면이 된다)\n아이디어에 해당하는 용어정리: : 이 구조가 x->y 로 바로 가는 것이 아니라 x->(u1->v1)->(u2->v2)=y 의 구조인데 이러한 네트워크를 하나의 은닉층을 포함하는 네트워크라고 표현한다.\n\n\n시벤코정리\nuniversal approximation thm: (범용근사정리,보편근사정리,시벤코정리), 1989\n\n하나의 은닉층을 가지는 “linear -> sigmoid -> linear” 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다면)\n\n- 사실 엄청 이해안되는 정리임. 왜냐햐면,\n\n그렇게 잘 맞추면 1989년에 세상의 모든 문제를 다 풀어야 한거 아니야?\n요즘은 “linear -> sigmoid -> linear” 가 아니라 “linear -> relu -> linear” 조합으로 많이 쓰던데?\n요즘은 하나의 은닉층을 포함하는 네트워크는 잘 안쓰지 않나? 은닉층이 여러개일수록 좋다고 어디서 본 것 같은데?\n\n- 약간의 의구심이 있지만 아무튼 universal approximation thm에 따르면 우리는 아래와 같은 무기를 가진 꼴이 된다.\n\n우리의 무기: \\({\\bf X}: (n,p)\\) 꼴의 입력에서 \\({\\bf y}:(n,1)\\) 꼴의 출력으로 향하는 맵핑을 “linear -> relu -> linear”와 같은 네트워크를 이용해서 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#목표",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#목표",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "목표",
    "text": "목표\n- 목표: \\({\\bf X}:(n,1,28,28)\\) 에서 \\(y:(n,1)\\) 로 가는 맵핑을 학습하자 –> 배운적이 없는데? –> \\({\\bf X}:(n,784)\\) 에서 \\(y:(n,1)\\) 로 가는 맵핑을 학습하자.."
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습1-path",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습1-path",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "예비학습1: Path",
    "text": "예비학습1: Path\n\npath = untar_data(URLs.MNIST) \npath\n\nPath('/home/cgb4/.fastai/data/mnist_png')\n\n\n\npath 도 오브젝트임\npath 도 정보+기능이 있음\n\n- path의 정보\n\npath._str # 숨겨놓았네?\n\n'/home/cgb4/.fastai/data/mnist_png'\n\n\n- 기능1\n\npath.ls()\n\n(#2) [Path('/home/cgb4/.fastai/data/mnist_png/training'),Path('/home/cgb4/.fastai/data/mnist_png/testing')]\n\n\n- 기능2\n\npath/'training'\n\nPath('/home/cgb4/.fastai/data/mnist_png/training')\n\n\n\npath/'testing'\n\nPath('/home/cgb4/.fastai/data/mnist_png/testing')\n\n\n- 기능1과 기능2의 결합\n\n(path/'training/3').ls()\n\n(#6131) [Path('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/12933.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/3576.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/59955.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/23144.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/40836.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/25536.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/42669.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/7046.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/47380.png')...]\n\n\n\n‘/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’ 이 파일을 더블클릭하면 이미지가 보인단 말임"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습2-plt.imshow",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습2-plt.imshow",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "예비학습2: plt.imshow",
    "text": "예비학습2: plt.imshow\n\nimgtsr = torch.tensor([[1.0,2],[2.0,4.0]])\nimgtsr\n\ntensor([[1., 2.],\n        [2., 4.]])\n\n\n\nplt.imshow(imgtsr,cmap='gray')\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fceac108e50>"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습3-torchvision",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#예비학습3-torchvision",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "예비학습3: torchvision",
    "text": "예비학습3: torchvision\n- /home/cgb4/.fastai/data/mnist_png/training/3/37912.png의 이미지파일을 torchvision.io.read_image 를 이용하여 텐서로 만듬\n\nimgtsr = torchvision.io.read_image('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png')\nimgtsr\n\ntensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66, 138,\n          149, 180, 138, 138,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  22, 162, 161, 228, 252, 252,\n          253, 252, 252, 252, 252,  74,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 253, 252, 252, 252, 189,\n          184, 110, 119, 252, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  74, 161, 160,  77,  45,   4,\n            0,   0,  70, 252, 210,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,  22, 205, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0, 162, 253, 245,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           36, 219, 252, 139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          222, 252, 202,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,\n          253, 252,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 240,\n          253, 157,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 160, 253,\n          231,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 252, 252,\n           42,  30,  78, 161,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          185, 228, 252, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          253, 252, 252, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 179, 252,\n          253, 252, 252, 210,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,\n          255, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,  89, 244,\n          253, 223,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 123, 142, 234, 252, 252,\n          184,  67,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 230, 253, 252, 252, 252, 168,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 126, 253, 252, 168,  43,   2,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n       dtype=torch.uint8)\n\n\n- 이 텐서는 (1,28,28)의 shape을 가짐\n\nimgtsr.shape\n\ntorch.Size([1, 28, 28])\n\n\n- imgtsr를 plt.imshow 로 시각화\n\nplt.imshow(imgtsr.reshape(28,28),cmap='gray')\n\n<matplotlib.image.AxesImage at 0x7fceabd49a90>\n\n\n\n\n\n\n진짜 숫자3이 있음"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#데이터정리",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#데이터정리",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "데이터정리",
    "text": "데이터정리\n\nthrees = (path/'training/3').ls()\nsevens = (path/'training/7').ls()\nlen(threes),len(sevens)\n\n(6131, 6265)\n\n\n\nX3 = torch.stack([torchvision.io.read_image(str(threes[i])) for i in range(6131)])\nX7 = torch.stack([torchvision.io.read_image(str(sevens[i])) for i in range(6265)])\n\n\nX3.shape,X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\nX=torch.concat([X3,X7])\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nXnp = X.reshape(-1,1*28*28).float()\nXnp.shape\n\ntorch.Size([12396, 784])\n\n\n\ny = torch.tensor([0.0]*6131 + [1.0]*6265).reshape(-1,1) \ny.shape\n\ntorch.Size([12396, 1])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n“y=0”은 숫자3을 의미, “y=1”은 숫자7을 의미\n숫자3은 6131개, 숫자7은 6265개 있음"
  },
  {
    "objectID": "posts/II. DNN/2022-10-06-6wk-1.html#학습-숙제-스스로-확인해-볼-것",
    "href": "posts/II. DNN/2022-10-06-6wk-1.html#학습-숙제-스스로-확인해-볼-것",
    "title": "06wk-1: 딥러닝의 기초 (6)",
    "section": "학습 (숙제: 스스로 확인해 볼 것)",
    "text": "학습 (숙제: 스스로 확인해 볼 것)\n- 네트워크의 설계\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1*28*28,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(200):\n    ## 1\n    yhat = net(Xnp) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o')\nplt.plot(net(Xnp).data,'.',alpha=0.2)\n\n\n\n\n\n대부분 잘 적합되었음"
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "assignment 2"
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html#단순회귀모형-풀이생략-강의노트-참고",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html#단순회귀모형-풀이생략-강의노트-참고",
    "title": "Assignment 2",
    "section": "1. 단순회귀모형 – 풀이생략 (강의노트 참고)",
    "text": "1. 단순회귀모형 – 풀이생략 (강의노트 참고)\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(7676)\nx = torch.randn(100).sort().values\nϵ = torch.randn(100)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n아래와 같은 모형을 가정하고 물음에 답하라.\n\\[y_i = w_0+w_1 x_i +\\epsilon_i, \\quad \\epsilon_i \\overset{iid}{\\sim} N(0,\\sigma^2)\\]\n(1) \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)으로 선택하고 \\(\\hat{y}_i\\)를 계산하라.\n(2) \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)에 대한 MSELoss를 계산하라. 즉\n\\[loss(\\hat{w}_0,\\hat{w}_1)\\]\n를 계산하라. 단, \\(loss(w_0,w_1)=\\frac{1}{n}\\sum_{i=1}^{n}(y_i-w_0-w_1x_i)^2\\).\n(3) \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)에서 MSELoss의 미분계수를 구하라. 즉 아래를 계산하라.\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1) ~\\Bigg|_{~\\hat{w}_0,\\hat{w}_1}\\]\n(4) 경사하강법을 이용하여 \\((\\hat{w}_0, \\hat{w}_1)\\)의 값을 1회 업데이트하라. (학습률은 \\(\\alpha=0.1\\)로 설정하라)\n(5) 이 모형에 대한 적절한 \\((\\hat{w}_0, \\hat{w}_1)\\)의 값을 추정하라."
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html#로지스틱모형",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html#로지스틱모형",
    "title": "Assignment 2",
    "section": "2. 로지스틱모형",
    "text": "2. 로지스틱모형\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(7676)\nx1 = torch.tensor(np.random.randint(low=100,high=199,size=10000))*5\nx2 = torch.tensor(np.random.randint(low=150,high=429,size=10000))/100\nu = x1*(1/100) + x2*(1.9) - 12.8 \nv = torch.nn.Sigmoid()(u) \ny = torch.bernoulli(v) \n\n\nx1,x2,y는 각각 토익점수, GPA, 취업성공을 의미하는 변수이다.\n\n\nfig = plt.figure(figsize=(7,7)) \nax = fig.add_subplot(1,1,1,projection='3d')\nax.scatter3D(x1,x2,y,alpha=0.1)\n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fd21c731a10>\n\n\n\n\n\n토익과 GPA로 취업여부를 판단하는 적절한 네트워크를 학습하라.\n(풀이)\n\nX = torch.stack([x1,x2],axis=1)\ny = y.reshape(-1,1) \n\n\nnet = torch.nn.Linear(in_features=2,out_features=1)\noptimizr = torch.optim.Adam(net.parameters())\nloss_fn = torch.nn.BCEWithLogitsLoss()\nfor epoc in range(10000):\n    ## 1\n    yhat = net(X)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\n((yhat>0) == y).float().mean()\n\ntensor(0.7890)\n\n\n\n((v>0.5) == y.reshape(-1)).float().mean() ## true를 알고 있다고 가정하였을 경우 0.7938이 최대예측이므로, 0.79와 비슷할수록 잘 적합된 모형임 \n\ntensor(0.7938)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html#과적합과-드랍아웃",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html#과적합과-드랍아웃",
    "title": "Assignment 2",
    "section": "3. 과적합과 드랍아웃",
    "text": "3. 과적합과 드랍아웃\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(20) \nx=torch.linspace(0,1,200).reshape(200,1)\neps = torch.concat([torch.normal(0,0.1,[60,1]),torch.normal(0,0.075,[60,1]),torch.normal(0,0.05,[80,1])])\ny=0.5*x+ eps\n\n\nplt.plot(x,y,'o',alpha=0.5)\n\n\n\n\n(1) 아래와 같이 자료를 분리하라. - \\({\\boldsymbol x}=(x_1,\\dots,x_{200}) \\to {\\boldsymbol x}_{train} = (x_1\\dots,x_{150}), ~{\\boldsymbol x}_{test}=(x_{151},\\dots,x_{200})\\) - \\({\\boldsymbol y}=(y_1,\\dots,y_{200}) \\to {\\boldsymbol y}_{train} = (y_1\\dots,y_{150}), ~{\\boldsymbol y}_{test}=(y_{151},\\dots,y_{200})\\)\n(풀이)\n\nxtr,xtest = x[:150], x[150:]\nytr,ytest = y[:150], y[150:]\n\n(2) 아래의 코드를 완성하여 네트워크를 설계하고 MSELoss를 손실함수로 선택한 뒤 \\(\\big( {\\boldsymbol x}_{train},{\\boldsymbol y}_{train}\\big)\\)을 사용해 모형을 적합시켜라. (옵티마이저는 자유롭게 선택할 것)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,4096),\n    torch.nn.ReLU(),\n    torch.nn.Linear(???,???)\n)\n(풀이)\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,4096),\n    torch.nn.ReLU(),\n    torch.nn.Linear(4096,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(xtr),ytr)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(3) \\(net({\\boldsymbol x}_{test})\\)의 결과를 시각화 하라.\n(풀이)\n\nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(xtr,net(xtr).data,'--',label='train',lw=5)\nplt.plot(xtest,net(xtest).data,'--',label='test',lw=5)\nplt.legend() \n\n<matplotlib.legend.Legend at 0x7f558cce7dd0>\n\n\n\n\n\n\nplt.legend() 등을 사용하지않아도 감점 X\n\n(4) 아래와 같은 Dropout Layer를 (2)의 네트워크 중 적절한 위치에 추가하라. 그리고 다시 \\(\\big( {\\boldsymbol x}_{train},{\\boldsymbol y}_{train}\\big)\\)만을 사용해 모형을 재학습하라.\ntorch.nn.Dropout(0.5)\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,4096),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),\n    torch.nn.Linear(4096,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10000):\n    ## 1\n    ## 2\n    loss = loss_fn(net(xtr),ytr)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) (4)에서 수정한 네트워크에 대한 \\(net({\\boldsymbol x}_{test})\\)의 결과를 시각화 하라.\n\nnet.eval()\nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(xtr,net(xtr).data,'--',label='train',lw=5)\nplt.plot(xtest,net(xtest).data,'--',label='test',lw=5)\nplt.legend() \n\n<matplotlib.legend.Legend at 0x7f558cee5790>"
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html#overparameterized-model-문제수정",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html#overparameterized-model-문제수정",
    "title": "Assignment 2",
    "section": "4. Overparameterized Model – (문제수정)",
    "text": "4. Overparameterized Model – (문제수정)\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\nhint: 이 모형은 \\(y_i = 3.14 + 6.28 x_i+ \\epsilon_i\\) 에서 생성 (기존 \\(y_i = 6.28 + 3.14 x_i +\\epsilon_i\\) 에서 수정)\n(1) 아래의 모형을 가정하고 \\(\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(풀이)\n\nnet = torch.nn.Linear(1,1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\nplt.title(r\"$model:= \\beta_0+\\beta_1x_i$ (before learing)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_0+\\\\beta_1x_i$ (before learing)')\n\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\nplt.title(r\"$model:= \\beta_0+\\beta_1x_i$ (after 100 epochs)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_0+\\\\beta_1x_i$ (after 100 epochs)')\n\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[6.3289]]), tensor([3.1776]))\n\n\n\n참값인 6.24, 3.14 가 적절하게 추정되었음\n\n(2) 아래의 모형을 가정하고 \\(\\beta_0\\)를 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_0 + \\epsilon_i,\\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(풀이)\n\nw0hat = torch.tensor([0.00],requires_grad=True) \n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\nplt.title(r\"$model:= \\beta_0+0\\times x_i$ (before learing)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_0+0\\\\times x_i$ (before learing)')\n\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = x*0 + w0hat \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    w0hat.data = w0hat.data - 0.1 * w0hat.grad\n    w0hat.grad = None\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\nplt.title(r\"$model:= \\beta_0+ 0\\times x_i$ (after 100 epochs)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_0+ 0\\\\times x_i$ (after 100 epochs)')\n\n\n\n\n\n\nw0hat\n\ntensor([3.2864], requires_grad=True)\n\n\n\n\\(w_0\\)의 참값인 3.14가 적절하게 추정되었음.\n\n(참고) 위에서 추정된 값은 이론적으로 아래와 같게 됩니다.\n\ny.mean() \n\ntensor(3.2864)\n\n\n(3) 아래의 모형을 가정하고 \\(\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\beta_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n(풀이)\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\nplt.title(r\"$model:= \\beta_1x_i$ (before learing)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_1x_i$ (before learing)')\n\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(x).data,'--')\nplt.title(r\"$model:= \\beta_1x_i$ (after 100 epochs)\",size=15)\n\nText(0.5, 1.0, '$model:= \\\\beta_1x_i$ (after 100 epochs)')\n\n\n\n\n\n\nnet.weight\n\nParameter containing:\ntensor([[6.4900]], requires_grad=True)\n\n\n\n참값인 6.28과 비슷하다.\n\n(4) 아래의 모형을 가정하고 \\(\\alpha_0,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\)은 얼마인가? 이 값과 문제 (1)에서 추정된 \\(\\hat{\\beta_0}\\)의 값과 비교하여 보라.\n(풀이)\n\n_1 = torch.ones([1000,1])\nX = torch.concat([_1,x],axis=1)\n\n\nnet = torch.nn.Linear(in_features=2,out_features=1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\nplt.title(r\"$model:= (\\beta_0+\\alpha_0)+ \\beta_1x_i$ (before learing)\",size=15)\n\nText(0.5, 1.0, '$model:= (\\\\beta_0+\\\\alpha_0)+ \\\\beta_1x_i$ (before learing)')\n\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(X).data,'--')\nplt.title(r\"$model:= (\\beta_0+\\alpha_0)+ \\beta_1x_i$ (after 100 epochs)\",size=15)\n\nText(0.5, 1.0, '$model:= (\\\\beta_0+\\\\alpha_0)+ \\\\beta_1x_i$ (after 100 epochs)')\n\n\n\n\n\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([2.0016], requires_grad=True),\n Parameter containing:\n tensor([[1.1759, 6.3301]], requires_grad=True))\n\n\n\n2.0016 + 1.1759\n\n3.1774999999999998\n\n\n\n2.0016 (\\(\\alpha_0\\)의 추정치로 해석가능) 와 1.1759 (\\(\\beta_0\\)의 추정치로 해석가능) 의 합이 (1)에서 추정된 값과 비슷하다.\n6.3301 (\\(\\beta_1\\)의 추정치로 해석가능) 역시 (1)에서 추정된 값과 비슷하다.\n\n(5) 아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하라. – 이거 제가 힌트를 잘못줬어요.. 문제가 좀 어렵게나왔네요 ㅠㅠ\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\), \\(\\hat{\\alpha}_1 + \\hat{\\beta}_1\\)의 값은 각각 얼마인가? 이 값들을 (1) 에서 추정된 \\(\\hat{\\beta}_0\\), \\(\\hat{\\beta}_1\\) 값들과 비교하라.\n(풀이)\n\nX = torch.concat([_1,_1,x,x],axis=1) \nX\n\ntensor([[ 1.0000,  1.0000,  0.8959,  0.8959],\n        [ 1.0000,  1.0000, -0.4144, -0.4144],\n        [ 1.0000,  1.0000, -0.1736, -0.1736],\n        ...,\n        [ 1.0000,  1.0000, -0.8677, -0.8677],\n        [ 1.0000,  1.0000,  0.2317,  0.2317],\n        [ 1.0000,  1.0000, -0.0644, -0.0644]])\n\n\n\nnet = torch.nn.Linear(in_features=4,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\nplt.title(r\"$model:= (\\beta_0+\\alpha_0)+ (\\beta_1+\\alpha_1)x_i$ (before learing)\",size=15)\n\nText(0.5, 1.0, '$model:= (\\\\beta_0+\\\\alpha_0)+ (\\\\beta_1+\\\\alpha_1)x_i$ (before learing)')\n\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\nplt.title(r\"$model:= (\\beta_0+\\alpha_0)+ (\\beta_1+\\alpha_1)x_i$ (after 100 epochs)\",size=15)\n\nText(0.5, 1.0, '$model:= (\\\\beta_0+\\\\alpha_0)+ (\\\\beta_1+\\\\alpha_1)x_i$ (after 100 epochs)')\n\n\n\n\n\n\nnet.weight\n\nParameter containing:\ntensor([[1.2784, 1.8990, 3.2781, 3.0571]], requires_grad=True)\n\n\n\n[1.2784+1.8990, 3.2781+3.0571]\n\n[3.1774, 6.3352]\n\n\n\n\\(\\hat{\\alpha}_0+\\hat{\\beta}_0=3.1774\\), \\(\\hat{\\alpha}_1+\\hat{\\beta}_1=6.3352\\)\n\n(6) 다음은 위의 모형에 대하여 학생들이 discussion한 결과이다. 올바르게 해석한 학생을 모두 골라라.\n민정: \\((x_i,y_i)\\)의 산점도는 직선모양이고 직선의 절펴과 기울기 모두 유의미해 보이므로 \\(y_i = \\beta_0 + \\beta_1 x_i\\) 꼴을 적합하는게 좋겠다.\n슬기: 나도 그렇게 생각해. 그래서 (2)-(3)과 같이 기울기를 제외하고 적합하거나 절편을 제외하고 적합하면 underfitting의 상황에 빠질 수 있어.\n성재: (2)의 경우 사실상 \\(\\bar{y}=\\frac{1}{n}\\sum_{i=1}^{n}y_i\\)를 추정하는 것과 같아지게 되지.\n세민: (4)의 경우 \\({\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_n \\end{bmatrix}\\) 와 같이 설정하고 네트워크를 아래와 같이 설정할 경우 얻어지는 모형이야.\nnet = torch.nn.Linear(in_features=2,out_features=1,bias=True)\n구환: 모델 (4)-(5)는 표현력은 (1)과 동일하지만 추정할 파라메터는 (1)보다 많으므로 효율적인 모델이라고 볼 수 없어.\n(풀이)\n모두 맞게 서술함\n\n아래는 이 문제에 대한 몇 가지 해설입니다.\nunder fitting\n(2)-(3)은 각각 원래직선의 기울기와 절편을 설명할 수 없는 구조이므로 모형의 표현력이 약한 상황이다. 따라서 underfitting 이 된다.\noverparameterized model\n(4)-(5)는 (1)에 대비하여 학습할 파라메터는 상승하였으나 모형의 표현력은 (1)과 동일한 상황이다. 실제로 직선의 적합을 만들기 위해서는 기울기를 의미하는 파라메터와 절편을 의미하는 파라메터 2개로 충분하다. 하지만 (4)의 경우 절편을 표현함에 있어서 \\(\\alpha_0, \\beta_0\\) 두 개의 파라메터를 썼으므로 파라메터의 낭비가 있다고 볼 수 있다. (5)의 경우 절편의 표현에서 파라메터의 낭비가 있었고 또한 기울기의 표현에서도 \\(\\alpha_1,\\beta_1\\) 두 개의 파라메터를 사용하였으므로 낭비가 있다.\n전통적인 통계학에서는 이처럼 잘못계획된 모형이 파라메터를 추정할때 큰 방해요소이지만 경사하강법을 base로 학습하는 경우 크게 문제되지 않는다. (\\(\\hat{\\alpha}_0+\\hat{\\beta}_0\\)이 절편의 추정값 역할을, \\(\\hat{\\alpha}_1+\\hat{\\beta}_1\\)이 기울기의 추정값 역할을 한다.) 여기에서 “왜 pytorch나 tensorflow에서 구현되는 경사하강법 based method 에서는 문제가 되지 않는가?” 에 대한 질문에 답을 하기 위해서는 기계학습 혹은 회귀분석에서 다루는 능형회귀(ridge)를 이해해야 한다. 이 부분은 본 교과과정 범위 밖이라 생각하므로 자세한 서술은 생략한다. (궁금하면 메일로 물어보세요, 단 ridge를 이해한 상태에서 물어보셔야합니다)\noverfiting\n단순히 파라메터를 많이 쓴다고 오버피팅이 되는건 아니다. 파라메터를 많이써서 모형의 표현력이 올라가야 오버피팅의 가능성이 있다. (4)-(5)의 경우 파라메터를 많이 썼으나 모형의 표현력이 상승한 것은 아니므로 오버피팅상황은 아니다.\n(2)에서 절편만 정확하게 학습되는 이유\n결국 \\(loss=\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\frac{1}{n}\\sum_{i=1}^{n}(y_i-w_0)^2\\) 와 같은 형태이다.\n경사하강법은 loss가 최소화되는 \\(w_0\\)를 찾아주는 방법인데, 경사하강법을 이용하지 않고 이론적으로 해결한다면 \\(\\frac{\\partial}{\\partial w_0}loss=0\\)을 계산하여 풀면 된다.\n\\(\\frac{\\partial}{\\partial w_0}loss=0 \\Longleftrightarrow \\frac{1}{n}\\sum_{i=1}^{n}(-2)(y_i-w_0)=0\\) 이고\n\\(\\frac{1}{n}\\sum_{i=1}^{n}(-2)(y_i-w_0)\\)를 \\(w_0\\)에 대하여 정리하면 \\(\\hat{w}_0=\\frac{1}{n}\\sum_{i=1}^{n}y_i\\) 이 된다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-26-Assignment2.html#다음을-읽고-참-거짓을-판단하여라.",
    "href": "posts/II. DNN/2022-10-26-Assignment2.html#다음을-읽고-참-거짓을-판단하여라.",
    "title": "Assignment 2",
    "section": "5. 다음을 읽고 참 거짓을 판단하여라.",
    "text": "5. 다음을 읽고 참 거짓을 판단하여라.\n(1) 로지스틱 모형은 Adam 옵티마이저가 아닐 경우 적합시키는 것이 불가능하다. (거짓)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "",
    "text": "깊은신경망(1)– 로지스틱 회귀의 한계, DNN을 이용한 해결, DNN으로 해결가능한 다양한 예제"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#신문기사-데이터의-모티브",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#신문기사-데이터의-모티브",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "신문기사 (데이터의 모티브)",
    "text": "신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#가짜데이터",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#가짜데이터",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "가짜데이터",
    "text": "가짜데이터\n- 위의 기사를 모티브로 한 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/II.%20DNN/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      underlying\n      y\n    \n  \n  \n    \n      0\n      -1.000000\n      0.000045\n      0.0\n    \n    \n      1\n      -0.998999\n      0.000046\n      0.0\n    \n    \n      2\n      -0.997999\n      0.000047\n      0.0\n    \n    \n      3\n      -0.996998\n      0.000047\n      0.0\n    \n    \n      4\n      -0.995998\n      0.000048\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      0.995998\n      0.505002\n      0.0\n    \n    \n      1996\n      0.996998\n      0.503752\n      0.0\n    \n    \n      1997\n      0.997999\n      0.502501\n      0.0\n    \n    \n      1998\n      0.998999\n      0.501251\n      1.0\n    \n    \n      1999\n      1.000000\n      0.500000\n      1.0\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nplt.plot(df.x,df.y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#로지스틱-회귀로-적합",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#로지스틱-회귀로-적합",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "로지스틱 회귀로 적합",
    "text": "로지스틱 회귀로 적합\n\nx= torch.tensor(df.x).float().reshape(-1,1)\ny= torch.tensor(df.y).float().reshape(-1,1)\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat=net(x)\n\n\nloss_fn = torch.nn.BCELoss() \nloss = loss_fn(yhat,y) # loss = -torch.mean((y)*torch.log(yhat)+(1-y)*torch.log(1-yhat))\nloss\n\ntensor(0.8255, grad_fn=<BinaryCrossEntropyBackward0>)\n\n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- Epoch을 한 6억번 넣어도 이건 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) \\(\\to\\) 모형의 표현력이 너무 낮다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#해결책",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#해결책",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "해결책",
    "text": "해결책\n- sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다.\n\nsig = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0');ax[0,1].plot(sig(u1),'--o',color='C0')\nax[1,0].plot(u2,'--o',color='C1');ax[1,1].plot(sig(u2),'--o',color='C1')\nax[2,0].plot(u3,'--o',color='C2');ax[2,1].plot(sig(u3),'--o',color='C2')\nax[3,0].plot(u4,'--o',color='C3');ax[3,1].plot(sig(u4),'--o',color='C3')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#꺽인-그래프를-만드는-방법1",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#꺽인-그래프를-만드는-방법1",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "꺽인 그래프를 만드는 방법1",
    "text": "꺽인 그래프를 만드는 방법1\n\nu = [9*xi+4.5 if xi <0 else -4.5*xi+4.5 for xi in x.reshape(-1).tolist()]\nplt.plot(u,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#꺽인-그래프를-만드는-방법2",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#꺽인-그래프를-만드는-방법2",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "꺽인 그래프를 만드는 방법2",
    "text": "꺽인 그래프를 만드는 방법2\n- 전략: 선형변환 \\(\\to\\) ReLU \\(\\to\\) 선형변환\n(예비학습) ReLU 함수란?\n\\(ReLU(x) = \\max(0,x)\\)\n\nrelu=torch.nn.ReLU()\nplt.plot(x,'--r')\nplt.plot(relu(x),'--b')\n\n\n\n\n\n빨간색: x, 파란색: relu(x)\n\n예비학습끝\n우리 전략 다시 확인: 선형변환1 -> 렐루 -> 선형변환2\n(선형변환1)\n\nplt.plot(x);plt.plot(-x)\n\n\n\n\n(렐루)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.5)\nplt.plot(relu(x),'--',color='C0');plt.plot(relu(-x),'--',color='C1')\n\n\n\n\n(선형변환2)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.2)\nplt.plot(relu(x),'--',color='C0',alpha=0.2);plt.plot(relu(-x),'--',color='C1',alpha=0.2)\nplt.plot(-4.5*relu(x)-9.0*relu(-x)+4.5,'--',color='C2')\n\n\n\n\n이제 초록색선에 sig를 취하기만 하면?\n\nplt.plot(sig(-4.5*relu(x)-9.0*relu(-x)+4.5),'--',color='C2')\n\n\n\n\n정리하면!\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title('x'); ax1.plot(x,'--',color='C0')\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title('-x'); ax2.plot(-x,'--',color='C1')\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title('relu(x)'); ax3.plot(relu(x),'--',color='C0')\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title('relu(-x)'); ax4.plot(relu(-x),'--',color='C1')\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title('u'); ax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('yhat'); ax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n이런느낌으로 \\(\\hat{\\boldsymbol y}\\)을 만들면 된다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#torch.nn.linear를-이용한-꺽인-그래프-구현",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#torch.nn.linear를-이용한-꺽인-그래프-구현",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "torch.nn.Linear()를 이용한 꺽인 그래프 구현",
    "text": "torch.nn.Linear()를 이용한 꺽인 그래프 구현\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=1,out_features=2,bias=True) \na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(in_features=2,out_features=1,bias=True) \na2 = torch.nn.Sigmoid() \n\n\nnet = torch.nn.Sequential(l1,a1,l2,a2) \n\n\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[-0.3467],\n         [-0.8470]], requires_grad=True),\n Parameter containing:\n tensor([0.3604, 0.9336], requires_grad=True),\n Parameter containing:\n tensor([[ 0.2880, -0.6282]], requires_grad=True),\n Parameter containing:\n tensor([0.2304], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0, 0.0])\nl2.weight.data = torch.tensor([[ -4.5, -9.0]])\nl2.bias.data= torch.tensor([4.5])\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[ 1.],\n         [-1.]], requires_grad=True),\n Parameter containing:\n tensor([0., 0.], requires_grad=True),\n Parameter containing:\n tensor([[-4.5000, -9.0000]], requires_grad=True),\n Parameter containing:\n tensor([4.5000], requires_grad=True))\n\n\n\nplt.plot(l1(x).data)\n\n\n\n\n\nplt.plot(a1(l1(x)).data)\n\n\n\n\n\nplt.plot(l2(a1(l1(x))).data,color='C2')\n\n\n\n\n\nplt.plot(a2(l2(a1(l1(x)))).data,color='C2')\n#plt.plot(net(x).data,color='C2')\n\n\n\n\n- 수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\)\n\\(\\quad =\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}\\)\n- 차원만 따지자\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#step1-step4",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#step1-step4",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "Step1 ~ Step4",
    "text": "Step1 ~ Step4\n- 준비\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2), #u1=l1(x), x:(n,1) --> u1:(n,2) \n    torch.nn.ReLU(), # v1=a1(u1), u1:(n,2) --> v1:(n,2) \n    torch.nn.Linear(in_features=2,out_features=1), # u2=l2(v1), v1:(n,2) --> u2:(n,1) \n    torch.nn.Sigmoid() # v2=a2(u2), u2:(n,1) --> v2:(n,1) \n) \n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters()) # lr은 디폴트값으로..\n\n- 반복\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\nplt.title(\"before\")\n\nText(0.5, 1.0, 'before')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 3000 epochs\")\n\nText(0.5, 1.0, 'after 3000 epochs')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 6000 epochs\")\n\nText(0.5, 1.0, 'after 6000 epochs')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#예제1",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#예제1",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "예제1",
    "text": "예제1\n- 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. \\(\\to\\) 그래서 이 역시 표현력이 부족할 듯 하다. \\(\\to\\) 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/posts/II.%20DNN/2022-10-04-dnnex1.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n이거 시그모이드 취하기 직전은 step이 포함된 듯 \\(\\to\\) 그래서 꺽은선으로는 표현할 수 없는 구조임 \\(\\to\\) 그런데 사실 대충은 표현가능\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=16), # x:(n,1) --> u1:(n,16) \n    torch.nn.ReLU(), # u1:(n,16) --> v1:(n,16)\n    torch.nn.Linear(in_features=16,out_features=1), # v1:(n,16) --> u2:(n,1) \n    torch.nn.Sigmoid() # u2:(n,1) --> v2:(n,1) \n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(6000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#예제2",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#예제2",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "예제2",
    "text": "예제2\n- 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? \\(\\to\\) 심지어 곡선도 대충 맞게 적합된다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/posts/II.%20DNN/2022-10-04-dnnex2.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\nx=torch.tensor(df.x).float().reshape(-1,1)\ny=torch.tensor(df.y).float().reshape(-1,1)\n\n(풀이1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --> u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --> v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --> u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n(풀이2) – 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운)\n\ntorch.manual_seed(5)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --> u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --> v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --> u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n\n풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? –> 안나옴!! (local min에 빠졌다)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-04-5wk-2.html#예제3",
    "href": "posts/II. DNN/2022-10-04-5wk-2.html#예제3",
    "title": "05wk-2: 딥러닝의 기초 (5)",
    "section": "예제3",
    "text": "예제3\n\nimport seaborn as sns\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/posts/II.%20DNN/2022-10-04-dnnex3.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      x1\n      x2\n      y\n    \n  \n  \n    \n      0\n      -0.874139\n      0.210035\n      0.0\n    \n    \n      1\n      -1.143622\n      -0.835728\n      1.0\n    \n    \n      2\n      -0.383906\n      -0.027954\n      0.0\n    \n    \n      3\n      2.131652\n      0.748879\n      1.0\n    \n    \n      4\n      2.411805\n      0.925588\n      1.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      -0.002797\n      -0.040410\n      0.0\n    \n    \n      1996\n      -1.003506\n      1.182736\n      0.0\n    \n    \n      1997\n      1.388121\n      0.079317\n      0.0\n    \n    \n      1998\n      0.080463\n      0.816024\n      1.0\n    \n    \n      1999\n      -0.416859\n      0.067907\n      0.0\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)})\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n\nx1 = torch.tensor(df.x1).float().reshape(-1,1) \nx2 = torch.tensor(df.x2).float().reshape(-1,1) \nX = torch.concat([x1,x2],axis=1) \ny = torch.tensor(df.y).float().reshape(-1,1) \n\n\nX.shape\n\ntorch.Size([2000, 2])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(3000):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ndf2 = df.assign(yhat=yhat.reshape(-1).detach().tolist())\ndf2\n\n\n\n\n\n  \n    \n      \n      x1\n      x2\n      y\n      yhat\n    \n  \n  \n    \n      0\n      -0.874139\n      0.210035\n      0.0\n      0.345833\n    \n    \n      1\n      -1.143622\n      -0.835728\n      1.0\n      0.605130\n    \n    \n      2\n      -0.383906\n      -0.027954\n      0.0\n      0.111915\n    \n    \n      3\n      2.131652\n      0.748879\n      1.0\n      0.918491\n    \n    \n      4\n      2.411805\n      0.925588\n      1.0\n      0.912608\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      -0.002797\n      -0.040410\n      0.0\n      0.254190\n    \n    \n      1996\n      -1.003506\n      1.182736\n      0.0\n      0.508002\n    \n    \n      1997\n      1.388121\n      0.079317\n      0.0\n      0.410099\n    \n    \n      1998\n      0.080463\n      0.816024\n      1.0\n      0.262315\n    \n    \n      1999\n      -0.416859\n      0.067907\n      0.0\n      0.107903\n    \n  \n\n2000 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow')\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n- 결과시각화\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)},ax=ax[0])\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow',ax=ax[1])\n\n<AxesSubplot:xlabel='x1', ylabel='x2'>\n\n\n\n\n\n- 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "",
    "text": "회귀분석(1)– 회귀모형의 소개, 회귀모형에서 데이터생성, 회귀모형에서 학습이란? 파라메터를 학습하는 방법, 파라메터의 학습과정 음미, 학습률\n- 강의노트가 약간 수정되었습니다 (loss.backward()의 계산결과 검증에서 편미분의 간단한 구현을 통한 검증이 추가되었습니다)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#stage1-첫번째-점선-임의의-선을-일단-그어보자",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#stage1-첫번째-점선-임의의-선을-일단-그어보자",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "Stage1: 첫번째 점선 – 임의의 선을 일단 그어보자",
    "text": "Stage1: 첫번째 점선 – 임의의 선을 일단 그어보자\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\nWhat = torch.tensor([-5.0,10.0],requires_grad=True)\nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\n처음에는 \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}=\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\) 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#stage2-첫번째-수정-최초의-점선에-대한-적당한-정도를-판단하고-더-적당한-점선으로-업데이트-한다.",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#stage2-첫번째-수정-최초의-점선에-대한-적당한-정도를-판단하고-더-적당한-점선으로-업데이트-한다.",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "Stage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.",
    "text": "Stage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터를 학습 하라 = 손실함수를 최소화 하라”\n- 우리의 무기: 경사하강법, 벡터미분\n\n\n# Stage2를 위한 경사하강법 복습\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) <– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) <– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- $수정값 원래값 - 기울어진크기(=미분계수) $\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nloss\n\ntensor(8587.6875, grad_fn=<SumBackward0>)\n\n\n\nloss.backward() \n\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\nWhat,What.grad\n\n(tensor([-5., 10.], requires_grad=True), tensor([-1342.2522,  1188.9305]))\n\n\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2522,  1188.9308], grad_fn=<AddBackward0>)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad))\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')\nplt.plot(x,X@Wafter,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#stage3-learn-estimate-bfhatw",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#stage3-learn-estimate-bfhatw",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "Stage3: Learn (=estimate \\(\\bf\\hat{W})\\)",
    "text": "Stage3: Learn (=estimate \\(\\bf\\hat{W})\\)\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) #\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() \n    What.data = What.data-alpha * What.grad\n    What.grad=None\n\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#학습과정의-기록",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#학습과정의-기록",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "학습과정의 기록",
    "text": "학습과정의 기록\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811716079712, 7.861191749572754],\n [-1.649186372756958, 7.101552963256836],\n [-0.9060714244842529, 6.49347448348999],\n [-0.29667872190475464, 6.006272315979004],\n [0.2027742564678192, 5.615575313568115],\n [0.6119104623794556, 5.302003860473633],\n [0.9469034075737, 5.0501298904418945],\n [1.2210698127746582, 4.847658157348633],\n [1.4453644752502441, 4.684779644012451],\n [1.6287914514541626, 4.553659915924072],\n [1.7787461280822754, 4.448036193847656],\n [1.9012980461120605, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nplt.plot(loss_history)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#학습과정을-animation으로-시각화",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#학습과정을-animation으로-시각화",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "학습과정을 animation으로 시각화",
    "text": "학습과정을 animation으로 시각화\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 <- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7ffa9199ce90>\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n\n<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7ffa78c2ba10>\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0001-alpha-가-너무-작다면-to-비효율적이다.",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0001-alpha-가-너무-작다면-to-비효율적이다.",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.",
    "text": "(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0083-alpha가-너무-크다면-to-다른의미에서-비효율적이다-위험하다..",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0083-alpha가-너무-크다면-to-다른의미에서-비효율적이다-위험하다..",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..",
    "text": "(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0085",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.0085",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "(3) \\(\\alpha=0.0085\\)",
    "text": "(3) \\(\\alpha=0.0085\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.01",
    "href": "posts/II. DNN/2022-09-20-3wk-2.html#alpha0.01",
    "title": "03wk-2: 딥러닝의 기초 (1)",
    "section": "(4) \\(\\alpha=0.01\\)",
    "text": "(4) \\(\\alpha=0.01\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "",
    "text": "깊은신경망(4)– 지난시간리뷰, 드랍아웃"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html#데이터",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html#데이터",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "데이터",
    "text": "데이터\n- model: \\(y_i = (0\\times x_i) + \\epsilon_i\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html#모든-데이터를-사용하여-적합-512-relu-1000-epochs",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html#모든-데이터를-사용하여-적합-512-relu-1000-epochs",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "모든 데이터를 사용하여 적합 (512, relu, 1000 epochs)",
    "text": "모든 데이터를 사용하여 적합 (512, relu, 1000 epochs)\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data, '--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html#전체데이터를-82로-나누어서-8만을-학습",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html#전체데이터를-82로-나누어서-8만을-학습",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "전체데이터를 8:2로 나누어서 8만을 학습",
    "text": "전체데이터를 8:2로 나누어서 8만을 학습\n- 데이터를 8:2로 나눈다\n\nxtr = x[:80]\nytr = y[:80] \nxtest = x[80:] \nytest = y[80:] \n\n\nx.shape, xtr.shape, xtest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\ny.shape, ytr.shape, ytest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n\n\n\n\n- (xtr,ytr) 만 가지고 net를 학습시킨다.\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html#오버피팅의-해결",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html#오버피팅의-해결",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "오버피팅의 해결",
    "text": "오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in training mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in training mode')\n\n\n\n\n\n- 올바른 사용법\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in evaluation mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in evaluation mode')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-13-7wk-1.html#드랍아웃-레이어",
    "href": "posts/II. DNN/2022-10-13-7wk-1.html#드랍아웃-레이어",
    "title": "07wk-1: 딥러닝의 기초 (8)",
    "section": "드랍아웃 레이어",
    "text": "드랍아웃 레이어\n\n_x = torch.linspace(0,1,101) \n_x \n\ntensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n        0.9900, 1.0000])\n\n\n\ndout = torch.nn.Dropout(0.9)\ndout(_x)\n\ntensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 2.1000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.2000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 4.7000, 0.0000, 4.9000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 5.8000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 7.5000, 7.6000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 8.5000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n        0.0000, 0.0000])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리\n\n구조: 입력 -> 드랍아웃레이어 -> 출력\n역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정\n효과: 오버피팅을 억제하는 효과가 있음 (왜??)\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 로테이션으로 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "",
    "text": "회귀분석(2)– SSE와 MSE, step1의 다른버전 (torch.nn.Linear)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#강의영상",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#강의영상",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "강의영상",
    "text": "강의영상\nhttps://youtube.com/playlist?list=PLQqh36zP38-wezS4h765Rs5mQFoSjrLMk\n\n강의영상 재업로드 하였습니다."
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#ver1-loss-sum-of-squares-error",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#ver1-loss-sum-of-squares-error",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "ver1: loss = sum of squares error",
    "text": "ver1: loss = sum of squares error\n\nalpha = 1/1000\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nnote: 왜 What = What - alpha*What.grad 는 안되는지?"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#ver2-loss-mean-squared-error-mse",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#ver2-loss-mean-squared-error-mse",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "ver2: loss = mean squared error = MSE",
    "text": "ver2: loss = mean squared error = MSE\n\nalpha = 1/10\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.mean((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#ver1-biastrue",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#ver1-biastrue",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "ver1: bias=True",
    "text": "ver1: bias=True\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- net에서 \\(\\hat{w}_0, \\hat{w}_1\\) 의 값은?\n\nnet.weight # w1 \n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nnet.bias # w0 \n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\n_yhat = -0.8470 + -0.3467*x \n\n\nplt.plot(x,y,'o')\nplt.plot(x, _yhat,'--')\nplt.plot(x,net(x).data,'-.')\n\n\n\n\n- 수식표현: \\(\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1 x_i = \\hat{b} + \\hat{w}x_i = -0.8470 + -0.3467 x_i\\) for all \\(i=1,2,\\dots,100\\)."
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#ver2",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#ver2",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "ver2",
    "text": "ver2\n- 입력이 x가 아닌 X를 넣고 싶다면? (보통 잘 안하긴 해요, 왜? bias=False로 주는게 귀찮거든요) - X는 바이어스가 고려된 상황\n\nnet(X) ## 그대로 쓰면 당연히 에러\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2, out_features=1, bias=False) \n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\n\nplt.plot(x,y,'o') \nplt.plot(x,net(X).data, '--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]), '-.')\n\n\n\n\n- 수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#잘못된사용1",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#잘못된사용1",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "잘못된사용1",
    "text": "잘못된사용1\n\n_x = x.reshape(-1)\n\n\n_x\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1,out_features=1) \n\n\nnet(_x)\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (1x100 and 1x1)"
  },
  {
    "objectID": "posts/II. DNN/2022-09-22-4wk-1.html#잘못된사용2",
    "href": "posts/II. DNN/2022-09-22-4wk-1.html#잘못된사용2",
    "title": "04wk-1: 딥러닝의 기초 (2)",
    "section": "잘못된사용2",
    "text": "잘못된사용2\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2,out_features=1) # bias=False를 깜빡..\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.2549], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]])+0.2549,'-.')\n\n\n\n\n\n수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} + \\hat{b}= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix} + 0.2549\\)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "",
    "text": "깊은신경망(3)– 신경망의표현, 시벤코정리증명, CPU vs GPU, 확률적경사하강법(+배치,에폭의 개념), 오버피팅"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xₙ\" -> \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xₙ*ŵ₁,    bias=False\" -> \"ŷₙ\"[label=\"sigmoid\"]\n\n    \".\" -> \"....................................\"[label=\"* ŵ₀\"]\n    \"..\" -> \"....................................\"[label=\"* ŵ₁\"]\n    \"....................................\" -> \"...\"[label=\" \"]\n\n    \"1 \" -> \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₂\" -> \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₂*ŵ₁,    bias=False\" -> \"ŷ₂\"[label=\"sigmoid\"]\n    \n    \"1  \" -> \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₁\" -> \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₁*ŵ₁,    bias=False\" -> \"ŷ₁\"[label=\"sigmoid\"]\n''')\n\n\n\n\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xᵢ\" -> \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xᵢ*ŵ₁,    bias=False\" -> \"ŷᵢ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n\nCode\ngv(''' \n    \"1\" -> \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x\" -> \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x*ŵ₁,    bias=False\" -> \"ŷ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n\nCode\ngv('''\n\"x\" -> \"x*ŵ₁,    bias=True\"[label=\"*ŵ₁\"] ;\n\"x*ŵ₁,    bias=True\" -> \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n\nCode\ngv('''\n\"x\" -> \"x*ŵ,    bias=True\"[label=\"*ŵ\"] ;\n\"x*ŵ,    bias=True\" -> \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\nCode\ngv('''\n\"x\" -> \"u\";\n\"u\" -> \"y\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 10월4일 강의노트에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n\nCode\ngv('''\n\"x\" -> \" -x\"[label=\"*(-1)\"];\n\"x\" -> \" x\"[label=\"*1\"]\n\" x\" -> \"rlu(x)\"[label=\"relu\"] \n\" -x\" -> \"rlu(-x)\"[label=\"relu\"] \n\"rlu(x)\" -> \"u\"[label=\"*(-4.5)\"] \n\"rlu(-x)\" -> \"u\"[label=\"*(-9.0)\"] \n\"u\" -> \"sig(u)=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n(좀 더 일반화된 표현) 10월4일 강의노트 상황을 일반화하면 아래와 같다.\n\n\nCode\ngv('''\n\"x\" -> \"u1[:,0]\"[label=\"*(-1)\"];\n\"x\" -> \"u1[:,1]\"[label=\"*1\"]\n\"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"] \n\"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"] \n\"v1[:,0]\" -> \"u2\"[label=\"*(-9.0)\"] \n\"v1[:,1]\" -> \"u2\"[label=\"*(-4.5)\"] \n\"u2\" -> \"v2=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"u1[:,0]\"\n    \"X\" -> \"u1[:,1]\"\n    \"u1[:,0]\" -> \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -> \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -> \"u2\"\n    \"v1[:,1]\" -> \"u2\"\n    \"u2\" -> \"v2=yhat\"[label=\"sigmoid\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\nLayer를 세는 방법\n\n정석: 학습가능한 파라메터가 몇층으로 있는지…\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음.\n위의 예제의 경우 number of layer = 2 이다.\n\n\n사실 input layer, activation layer 등의 표현을 자주 사용해서 layer를 세는 방법이 처음에는 헷갈립니다..\n\nHidden Layer의 수를 세는 방법\n\nLayer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"node1\"\n    \"X\" -> \"node2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -> \"yhat \"\n    \"node2\" -> \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -> \"feature1\"\n    \"X\" -> \"feature2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"feature1\" -> \"yhat \"\n    \"feature2\" -> \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Input Layer\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -> \"node1\"\n    \"x2\" -> \"node1\"\n    \"..\" -> \"node1\"\n    \n    \"x784\" -> \"node1\"\n    \"x1\" -> \"node2\"\n    \"x2\" -> \"node2\"\n    \"..\" -> \"node2\"\n    \"x784\" -> \"node2\"\n    \n    \"x1\" -> \"...\"\n    \"x2\" -> \"...\"\n    \"..\" -> \"...\"\n    \"x784\" -> \"...\"\n\n    \"x1\" -> \"node32\"\n    \"x2\" -> \"node32\"\n    \"..\" -> \"node32\"\n    \"x784\" -> \"node32\"\n\n\n    label = \"Hidden Layer: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -> \"yhat\"\n    \"node2\" -> \"yhat\"\n    \"...\" -> \"yhat\"\n    \"node32\" -> \"yhat\"\n    \n    label = \"Outplut Layer: sigmoid\"\n}\n''')\n\n\n\n\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#그림으로-보는-증명과정",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#그림으로-보는-증명과정",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "그림으로 보는 증명과정",
    "text": "그림으로 보는 증명과정\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자.\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,color='C2'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ \\\\l_1)(x)$')\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data,'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+0.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nax[0].plot(x,l1(x).data,'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nfig\n\n\n\n\n- 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data)\n\n\n\n\n- 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n- 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- \\(h(x)\\)를 활성화함수로 가지는 네트워크를 설계하여 보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) # activation 의 출력 \n\n\na1=MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n\nplt.plot(x,a1(x)) \n\n\n\n\n히든레이어가 1개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1),\n            MyActivation(),\n            torch.nn.Linear(1,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 2개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,2),\n            MyActivation(),\n            torch.nn.Linear(2,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 3개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,3),\n            MyActivation(),\n            torch.nn.Linear(3,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 1024개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1024),\n            MyActivation(),\n            torch.nn.Linear(1024,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#하나의-은닉층에-많은-노드수가-있는-신경망",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#하나의-은닉층에-많은-노드수가-있는-신경망",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "하나의 은닉층에 많은 노드수가 있는 신경망",
    "text": "하나의 은닉층에 많은 노드수가 있는 신경망\n- 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(예시1)\n\ntorch.manual_seed(43052)\nx = torch.linspace(-10,10,200).reshape(-1,1)\nunderlying = torch.sin(2*x) + torch.sin(0.5*x) + torch.exp(-0.2*x)\neps = torch.randn(200).reshape(-1,1)*0.1\ny = underlying + eps \nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(x,underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(x,underlying,lw=3)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n(예시2)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/posts/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n  \n    \n      \n      x\n      underlying\n      y\n    \n  \n  \n    \n      0\n      -1.000000\n      0.000045\n      0.0\n    \n    \n      1\n      -0.998999\n      0.000046\n      0.0\n    \n    \n      2\n      -0.997999\n      0.000047\n      0.0\n    \n    \n      3\n      -0.996998\n      0.000047\n      0.0\n    \n    \n      4\n      -0.995998\n      0.000048\n      0.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      1995\n      0.995998\n      0.505002\n      0.0\n    \n    \n      1996\n      0.996998\n      0.503752\n      0.0\n    \n    \n      1997\n      0.997999\n      0.502501\n      0.0\n    \n    \n      1998\n      0.998999\n      0.501251\n      1.0\n    \n    \n      1999\n      1.000000\n      0.500000\n      1.0\n    \n  \n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).reshape(-1,1).float()\ny = torch.tensor(df.y).reshape(-1,1).float()\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(df.x,df.underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(df.x,df.underlying,lw=3)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#gpu-사용방법",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#gpu-사용방법",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "GPU 사용방법",
    "text": "GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=<AddmmBackward0>)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=<MeanBackward0>)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#시간측정-예비학습",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#시간측정-예비학습",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "시간측정 (예비학습)",
    "text": "시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n0.18881630897521973"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-512",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-512",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "CPU (512)",
    "text": "CPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\n- for문 준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.33724379539489746"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#gpu-512",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#gpu-512",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "GPU (512)",
    "text": "GPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\n- for문돌릴준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5184829235076904\n\n\n\n!! CPU가 더 빠르다?"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-vs-gpu-20480",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-vs-gpu-20480",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "CPU vs GPU (20480)",
    "text": "CPU vs GPU (20480)\n- CPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.642850875854492\n\n\n- GPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5183775424957275\n\n\n- 왜 이런 차이가 나는가? 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-vs-gpu-204800",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#cpu-vs-gpu-204800",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "CPU vs GPU (204800)",
    "text": "CPU vs GPU (204800)\n- CPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n59.693639039993286\n\n\n- GPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3976879119873047"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#좀-이상하지-않아요",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#좀-이상하지-않아요",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "좀 이상하지 않아요?",
    "text": "좀 이상하지 않아요?\n- 우리가 쓰는 GPU: 다나와 PC견적\n\nGPU 메모리 끽해봐야 24GB\n\n- 우리가 분석하는 데이터: 빅데이터..?\n- 데이터의 크기가 커지는순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n- ver1: 모든 샘플을 이용하여 slope 계산\n(epoch1) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n(epoch2) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n…\n- ver2: 하나의 샘플만을 이용하여 slope 계산\n(epoch1) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…\n- ver3: \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch1) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#용어의-정리",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#용어의-정리",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "용어의 정리",
    "text": "용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#ds-dl",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#ds-dl",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "ds, dl",
    "text": "ds, dl\n- ds\n\nx=torch.tensor(range(10)).float()#.reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5)#.reshape(-1,1)\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n<torch.utils.data.dataset.TensorDataset at 0x7f0788b59c50>\n\n\n\nds.tensors # 그냥 (x,y)의 튜플\n\n(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))\n\n\n- dl\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\n#set(dir(dl)) & {'__iter__'}\n\n\nfor xx,yy in dl:\n    print(xx,yy)\n\ntensor([0., 1., 2.]) tensor([1., 1., 1.])\ntensor([3., 4., 5.]) tensor([1., 1., 0.])\ntensor([6., 7., 8.]) tensor([0., 0., 0.])\ntensor([9.]) tensor([0.])"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#ds-dl을-이용한-mnist-구현",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#ds-dl을-이용한-mnist-구현",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "ds, dl을 이용한 MNIST 구현",
    "text": "ds, dl을 이용한 MNIST 구현\n- 데이터정리\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n- ds \\(\\to\\) dl\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048) \n\n\n12665/2048\n\n6.18408203125\n\n\n\ni = 0 \nfor xx,yy in dl: # 총 7번 돌아가는 for문 \n    print(i)\n    i=i+1\n\n0\n1\n2\n3\n4\n5\n6\n\n\n- 미니배치 안쓰는 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(70): \n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss= loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ntorch.sum((yhat>0.5) == y) / len(y) \n\ntensor(0.9981)\n\n\n- 미니배치 쓰는 학습 (GPU 올리고 내리는 과정은 생략)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10):\n    for xx,yy in dl: ## 7번\n        ## 1\n        #yhat = net(xx)\n        ## 2 \n        loss = loss_fn(net(xx),yy) \n        ## 3 \n        loss.backward() \n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\ntorch.mean(((net(X)>0.5) == y)*1.0)\n\ntensor(0.9950)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#오버피팅-예시",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#오버피팅-예시",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "오버피팅 예시",
    "text": "오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\nmodel: \\(y_i = (0\\times x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0,0.01^2)\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)\n\n\n\n\n\ny는 그냥 정규분포에서 생성한 오차이므로 \\(X \\to y\\) 로 항햐는 규칙따위는 없음\n\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat=net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    net.zero_grad() \n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 \\(\\to\\) 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)"
  },
  {
    "objectID": "posts/II. DNN/2022-10-11-6wk-2.html#오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/II. DNN/2022-10-11-6wk-2.html#오버피팅이라는-뚜렷한-증거-train-test",
    "title": "06wk-2: 딥러닝의 기초 (7)",
    "section": "오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nxtr = x[:80] \nytr = y[:80]\nxtest = x[80:]\nytest = y[80:]\nplt.plot(xtr,ytr)\nplt.plot(xtest,ytest)\nplt.title('train: blue / test: orange');\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    # net(xtr) \n    ## 2 \n    loss=loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,net(xtr).data,'--') # prediction (train) \n\n\n\n\n\ntrain에서는 잘 맞추는듯이 보인다.\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,net(xtr).data,'--') # prediction (train) \nplt.plot(xtest,net(xtest).data,'--') # prediction with unseen data (test) \n\n\n\n\n\ntrain은 그럭저럭 따라가지만 test에서는 엉망이다. \\(\\to\\) overfit"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "",
    "text": "회귀분석(3)– step1의 다른버전 (복습+\\(\\alpha\\)) // 로지스틱(1)– step4의 다른버전, 로지스틱 motive"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#numpy-torch는-엄청-비슷해요",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#numpy-torch는-엄청-비슷해요",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "numpy, torch는 엄청 비슷해요",
    "text": "numpy, torch는 엄청 비슷해요\n- torch.tensor() = np.array() 처럼 생각해도 무방\n\nnp.array([1,2,3]), torch.tensor([1,2,3])\n\n(array([1, 2, 3]), tensor([1, 2, 3]))\n\n\n- 소수점의 정밀도에서 차이가 있음 (torch가 좀 더 쪼잔함)\n\nnp.array([3.123456789])\n\narray([3.12345679])\n\n\n\ntorch.tensor([3.123456789])\n\ntensor([3.1235])\n\n\n- 기본적인 numpy 문법은 np 대신에 torch를 써도 무방 // 완전 같지는 않음\n\nnp.arange(10), torch.arange(10)\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n\n\nnp.linspace(0,1,10), torch.linspace(0,1,10)\n\n(array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n         1.0000]))\n\n\n\nnp.random.randn(10)\n\narray([-0.36178915, -0.07674959,  0.30418196,  0.92197998,  2.17699807,\n       -0.67051237,  0.64369007,  1.16643216,  0.49921069, -1.53722202])\n\n\n\ntorch.randn(10)\n\ntensor([-0.2795,  0.0139,  0.9181,  1.8570, -0.4213,  0.0173, -1.1933,  0.4933,\n         0.2827, -0.8889])"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#length-n-vector-n-times-1-col-vector-1-times-n-row-vector",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#length-n-vector-n-times-1-col-vector-1-times-n-row-vector",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "length \\(n\\) vector, \\(n \\times 1\\) col-vector, \\(1 \\times n\\) row-vector",
    "text": "length \\(n\\) vector, \\(n \\times 1\\) col-vector, \\(1 \\times n\\) row-vector\n- 길이가 3인 벡터 선언방법\n\na = torch.tensor([1,2,3])\na.shape\n\ntorch.Size([3])\n\n\n- 3x1 col-vec 선언방법\n(방법1)\n\na = torch.tensor([[1],[2],[3]])\na.shape\n\ntorch.Size([3, 1])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(3,1)\na.shape\n\ntorch.Size([3, 1])\n\n\n- 1x3 row-vec 선언방법\n(방법1)\n\na = torch.tensor([[1,2,3]])\na.shape\n\ntorch.Size([1, 3])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(1,3)\na.shape\n\ntorch.Size([1, 3])\n\n\n- 3x1 col-vec 선언방법, 1x3 row-vec 선언방법에서 [[1],[2],[3]] 혹은 [[1,2,3]] 와 같은 표현이 이해안되면 아래링크로 가셔서\nhttps://guebin.github.io/STBDA2022/2022/03/14/(2주차)-3월14일.html\n첫번째 동영상 12:15 - 22:45 에 해당하는 분량을 학습하시길 바랍니다."
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#torch의-dtype",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#torch의-dtype",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "torch의 dtype",
    "text": "torch의 dtype\n- 기본적으로 torch는 소수점으로 저장되면 dtype=torch.float32 가 된다. (이걸로 맞추는게 편리함)\n\ntsr = torch.tensor([1.23,2.34])\ntsr\n\ntensor([1.2300, 2.3400])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 정수로 선언하더라도 dtype를 torch.float32로 바꾸는게 유리함\n(안 좋은 선언예시)\n\ntsr = torch.tensor([1,2])\ntsr \n\ntensor([1, 2])\n\n\n\ntsr.dtype\n\ntorch.int64\n\n\n(좋은 선언예시1)\n\ntsr = torch.tensor([1,2],dtype=torch.float32)\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(좋은 선언예시2)\n\ntsr = torch.tensor([1,2.0])\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(사실 int로 선언해도 나중에 float으로 바꾸면 큰 문제없음)\n\ntsr = torch.tensor([1,2]).float()\ntsr\n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 왜 정수만으로 torch.tensor를 만들때에도 torch.float32로 바꾸는게 유리할까? \\(\\to\\) torch.tensor끼리의 연산에서 문제가 될 수 있음\n별 문제 없을수도 있지만\n\ntorch.tensor([1,2])-torch.tensor([1.0,2.0]) \n\ntensor([0., 0.])\n\n\n아래와 같이 에러가 날수도 있다\n(에러1)\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1],[2]]) \n\nRuntimeError: expected scalar type Float but found Long\n\n\n(에러2)\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1.0],[2.0]])\n\nRuntimeError: expected scalar type Long but found Float\n\n\n(해결1) 둘다 정수로 통일\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1],[2]])\n\ntensor([[1],\n        [2]])\n\n\n(해결2) 둘다 소수로 통일 <– 더 좋은 방법임\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1.0],[2.0]])\n\ntensor([[1.],\n        [2.]])"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#shape-of-vector",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#shape-of-vector",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "shape of vector",
    "text": "shape of vector\n- 행렬곱셈에 대한 shape 조심\n\nA = torch.tensor([[2.00,0.00],[0.00,3.00]]) \nb1 = torch.tensor([[-1.0,-5.0]])\nb2 = torch.tensor([[-1.0],[-5.0]])\nb3 = torch.tensor([-1.0,-5.0])\n\n\nA.shape,b1.shape,b2.shape,b3.shape\n\n(torch.Size([2, 2]), torch.Size([1, 2]), torch.Size([2, 1]), torch.Size([2]))\n\n\n- A@b1: 계산불가, b1@A: 계산가능\n\nA@b1\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2 and 1x2)\n\n\n\nb1@A\n\ntensor([[ -2., -15.]])\n\n\n- A@b2: 계산가능, b2@A: 계산불가\n\nA@b2\n\ntensor([[ -2.],\n        [-15.]])\n\n\n\nb2@A\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)\n\n\n- A@b3: 계산가능, b3@A: 계산가능\n\n(A@b3).shape ## b3를 마치 col-vec 처럼 해석\n\ntorch.Size([2])\n\n\n\n(b3@A).shape ## b3를 마지 row-vec 처럼 해석\n\ntorch.Size([2])\n\n\n- 브로드캐스팅\n\na = torch.tensor([1,2,3])\na - 1\n\ntensor([0, 1, 2])\n\n\n\nb = torch.tensor([[1],[2],[3]])\nb - 1\n\ntensor([[0],\n        [1],\n        [2]])\n\n\n\na - b # a를 row-vec 로 해석\n\ntensor([[ 0,  1,  2],\n        [-1,  0,  1],\n        [-2, -1,  0]])"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#read-data",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#read-data",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "read data",
    "text": "read data\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/posts/II.%20DNN/2022-09-22-regression.csv\") \ndf\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -2.482113\n      -8.542024\n    \n    \n      1\n      -2.362146\n      -6.576713\n    \n    \n      2\n      -1.997295\n      -5.949576\n    \n    \n      3\n      -1.623936\n      -4.479364\n    \n    \n      4\n      -1.479192\n      -4.251570\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      95\n      2.244400\n      10.325987\n    \n    \n      96\n      2.393501\n      12.266493\n    \n    \n      97\n      2.605604\n      13.098280\n    \n    \n      98\n      2.605658\n      12.546793\n    \n    \n      99\n      2.663240\n      13.834002\n    \n  \n\n100 rows × 2 columns\n\n\n\n\nx=torch.tensor(df.x).float().reshape(100,1)\ny=torch.tensor(df.y).float().reshape(100,1)\n_1 = torch.ones([100,1])\nX = torch.concat([_1,x],axis=1)\n\n\nplt.plot(x,y,'o')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#ver1-net-torch.nn.linear11biastrue",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#ver1-net-torch.nn.linear11biastrue",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "ver1: net = torch.nn.Linear(1,1,bias=True)",
    "text": "ver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1,bias=True)\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\nnet.weight,net.bias\n\n(Parameter containing:\n tensor([[10.]], requires_grad=True),\n Parameter containing:\n tensor([-5.], requires_grad=True))\n\n\n- step1\n\nyhat = net(x) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad,net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n- step4\n(업데이트전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n(업데이트)\n\nnet.bias.data = net.bias.data - 0.1*net.bias.grad \nnet.weight.data = net.weight.data - 0.1*net.weight.grad \n\n\nnet.bias.grad = None \nnet.weight.grad = None \n\n(업데이트후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-3.6577], requires_grad=True),\n Parameter containing:\n tensor([[8.8111]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n- 반복\n\nfor epoc in range(30):\n    yhat = net(x) \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.bias.data = net.bias.data - 0.1*net.bias.grad\n    net.weight.grad = None\n    net.bias.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#ver2-net-torch.nn.linear21biasfalse",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#ver2-net-torch.nn.linear21biasfalse",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "ver2: net = torch.nn.Linear(2,1,bias=False)",
    "text": "ver2: net = torch.nn.Linear(2,1,bias=False)\n- 준비\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n- step1\n\nyhat = net(X)\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n- step4\n(업데이트전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n(업데이트)\n\nnet.weight.data = net.weight.data - 0.1*net.weight.grad\n\n\nnet.weight.grad = None\n\n(업데이트후)\n\nnet.weight\n\nParameter containing:\ntensor([[-3.6577,  8.8111]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n- 반복\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = net(X) \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#ver1-net-torch.nn.linear11biastrue-1",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#ver1-net-torch.nn.linear11biastrue-1",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "ver1: net = torch.nn.Linear(1,1,bias=True)",
    "text": "ver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]]) \nnet.bias.data = torch.tensor([[-5.0]]) \n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n- step1~3\n\nyhat = net(x)     \n\n\nloss = torch.mean((y-yhat)**2) \n\n\nloss.backward() \n\n- step4\n(update 전)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 전\n\n(tensor([[10.]]), tensor([[-5.]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 청소전 \n\n(tensor([[11.8893]]), tensor([[-13.4225]]))\n\n\n(update)\n\noptimizr.step() \noptimizr.zero_grad() \n\n(update 후)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 되었음 \n\n(tensor([[8.8111]]), tensor([[-3.6577]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 0으로 초기화하였음 \n\n(tensor([[0.]]), tensor([[0.]]))\n\n\n- 반복\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nfor epoc in range(30): \n    yhat = net(x)\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#ver2-net-torch.nn.linear21biasfalse-1",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#ver2-net-torch.nn.linear21biasfalse-1",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "ver2: net = torch.nn.Linear(2,1,bias=False)",
    "text": "ver2: net = torch.nn.Linear(2,1,bias=False)\n- 바로 반복하겠습니다..\n\nnet = torch.nn.Linear(2,1,bias=False) \nnet.weight.data = torch.tensor([[-5.0, 10.0]])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nfor epoc in range(30): \n    yhat = net(X)\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#motive",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#motive",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "motive",
    "text": "motive\n- 현실에서 이런 경우가 많음\n\n\\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 증가함.\n\n- (X,y)는 어떤모양?\n\n_df = pd.DataFrame({'x':range(-6,7),'y':[0,0,0,0,0,0,1,0,1,1,1,1,1]})\n_df \n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      -6\n      0\n    \n    \n      1\n      -5\n      0\n    \n    \n      2\n      -4\n      0\n    \n    \n      3\n      -3\n      0\n    \n    \n      4\n      -2\n      0\n    \n    \n      5\n      -1\n      0\n    \n    \n      6\n      0\n      1\n    \n    \n      7\n      1\n      0\n    \n    \n      8\n      2\n      1\n    \n    \n      9\n      3\n      1\n    \n    \n      10\n      4\n      1\n    \n    \n      11\n      5\n      1\n    \n    \n      12\n      6\n      1\n    \n  \n\n\n\n\n\nplt.plot(_df.x,_df.y,'o')\n\n\n\n\n- (예비학습) 시그모이드라는 함수가 있음\n\nxx = torch.linspace(-6,6,100)\ndef f(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(_df.x,_df.y,'o')\nplt.plot(xx,f(xx))"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#model",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#model",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "model",
    "text": "model\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 <— 외우세요!!!\n\n\\(y_i \\sim Ber(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) <— 외우세요!!"
  },
  {
    "objectID": "posts/II. DNN/2022-09-27-4wk-2.html#toy-example",
    "href": "posts/II. DNN/2022-09-27-4wk-2.html#toy-example",
    "title": "04wk-2: 딥러닝의 기초 (3)",
    "section": "toy example",
    "text": "toy example\n- 예제시작\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\n\n\n\n\n\n우리의 목적: \\(x\\)가 들어가면 빨간선 \\(\\hat{y}\\)의 값을 만들어주는 mapping을 학습해보자."
  },
  {
    "objectID": "posts/2022-09-01-1wk-1.html",
    "href": "posts/2022-09-01-1wk-1.html",
    "title": "Introduction",
    "section": "",
    "text": "수업목표, 강의교재 및 참고자료, 선수과목, 강의범위, 주의사항\n\n\n수업목표\n- 다양한 딥러닝 분석기법의 원리를 이해한다.\n- 파이토치 사용방법을 익힌다.\n\n\n강의교재 및 참고자료\n- 강의교재: 강의노트\n- 참고자료:\n\n2021년 빅데이터분석 강의노트 (본 수업은 2021년 빅데이터분석 수업과 유사한 콘텐츠로 진행할 예정임)\n2022년 파이썬입문 강의노트 (numpy, class 부분이 약하다고 생각하면 참고 할 것)\nfastai, Deep Learning for Coders with fastai & PyTorch, Deep Learning for Coders with fastai & PyTorch (번역판)\n\n\n\n선수과목\n- 필수: 파이썬입문 (수업시간에 별도로 파이썬을 리뷰하는 시간을 갖지 않음)\n- 선택: 수리통계학, 회귀분석, 선형대수학 (수업이해에 필요한 최소한의 지식은 리뷰함)\n\n\n강의범위\n- 딥러닝의 기초: DNN, 손실함수, 옵티마이저, 역전파, universal approximation thm\n- 이미지 자료 분석: CNN, Class Activation Map (CAM) and XAI\n- 추천시스템: SVD, Collaborative Filtering …\n- 텍스트와 시퀀스 자료 분석: RNN, LSTM, GRU, Attention…\n- 생성모형: 식별모형과 생성모형, GAN\n\n\n주의사항\n- 출석을 모두 하고 과제를 모두 제출하였더라도 중간고사와 기말고사 합산점수가 매우 낮을 경우 F 혹은 D 학점이 나갈 수 있음.\n- 2022년 1학기 데이터과학 수업과 내용이 일부 겹칠 수 있음 (다만 2022년 1학기 데이터과학 수업은 텐서플로우로 본 수업은 파이토치로 진행하는 차이점은 있음)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝(2022)",
    "section": "",
    "text": "final\n\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12wk-2: 순환신경망 (7)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12wk-1: 순환신경망 (6)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11wk-2: 순환신경망 (5)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11wk-1: 순환신경망 (4)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10wk-2: 순환신경망 (3)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10wk-1: 순환신경망 (2)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n09wk-2: 순환신경망 (1)\n\n\n\n\n\n\n\n순환신경망\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmid\n\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 3\n\n\n\n\n\n\n\n이미지분석\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 2\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n08wk-2: 이미지분석 (3)\n\n\n\n\n\n\n\n이미지분석\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n08wk-1: 이미지분석 (2)\n\n\n\n\n\n\n\n이미지분석\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-2: 이미지분석 (1)\n\n\n\n\n\n\n\n이미지분석\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n07wk-1: 딥러닝의 기초 (8)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2022\n\n\n최규빈\n\n\n\n\n\n\n  \n\n\n\n\n06wk-2: 딥러닝의 기초 (7)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n06wk-1: 딥러닝의 기초 (6)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05wk-2: 딥러닝의 기초 (5)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n05wk-1: 딥러닝의 기초 (4)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04wk-2: 딥러닝의 기초 (3)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nSep 27, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n04wk-1: 딥러닝의 기초 (2)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n03wk-2: 딥러닝의 기초 (1)\n\n\n\n\n\n\n\n딥러닝의 기초\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment 1\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2022\n\n\n최규빈\n\n\n\n\n\n\n  \n\n\n\n\n02wk-1: Overview (4)\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02wk-1: Overview (3)\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n02wk-1: Overview (2)\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n01wk-2: Overview (1)\n\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\n\n\n\n\n\nSep 6, 2022\n\n\n최규빈\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\n최규빈\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "딥러닝2022\nguebin@jbnu.ac.kr\n자연과학대학 본관 205호"
  }
]